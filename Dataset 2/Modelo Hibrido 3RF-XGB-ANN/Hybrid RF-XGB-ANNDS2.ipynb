{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJyg8xgbBD2"
      },
      "source": [
        "Importación y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tJA_xfxpbAlp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Importaciones correctas\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import optuna\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = pd.read_csv('Telco Churn dataset 2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3B405XRbMm_"
      },
      "source": [
        "Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuTS-4Da1iq",
        "outputId": "64269792-651b-47fc-a2aa-3a22c056507f"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocesamiento\n",
        "# a. Crear la columna 'Churn' y asignar 1 si 'Churn' es 'Yes', de lo contrario 0\n",
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# b. Eliminar columnas con más del 50% de datos faltantes\n",
        "threshold = int(0.5 * len(df))\n",
        "df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "# c. Reemplazar valores atípicos por la media\n",
        "for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "    if col != 'Churn':  # Asegurarse de no modificar la columna 'Churn'\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df[col] = df[col].apply(lambda x: df[col].mean() if (x < (Q1 - 1.5 * IQR)) or (x > (Q3 + 1.5 * IQR)) else x)\n",
        "\n",
        "# d. Convertir variables categóricas a numéricas y llenar valores faltantes\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object' and column != 'Churn':\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "    elif df[column].dtype in ['int64', 'float64']:\n",
        "        df[column].fillna(df[column].median(), inplace=True)\n",
        "\n",
        "# e. Normalización\n",
        "cols_to_scale = df.columns.tolist()\n",
        "cols_to_scale.remove('Churn')\n",
        "scaler = StandardScaler()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# f. Asegurarse de que 'Churn' sea int\n",
        "df['Churn'] = df['Churn'].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selección de características"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características seleccionadas: ['customerID', 'SeniorCitizen', 'tenure', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'InternationalPlan', 'VoiceMailPlan', 'NumbervMailMessages', 'TotalDayMinutes', 'TotalEveMinutes', 'TotalNightMinutes', 'TotalIntlMinutes', 'TotalIntlCalls', 'CustomerServiceCalls']\n"
          ]
        }
      ],
      "source": [
        "# 2. Selección de características\n",
        "xgb_for_feature_selection = XGBClassifier(\n",
        "    objective='binary:logistic', \n",
        "    random_state=42, \n",
        "    use_label_encoder=False, \n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_for_feature_selection.fit(df.drop('Churn', axis=1), df['Churn'])\n",
        "threshold = 0.01  \n",
        "selected_features = df.drop('Churn', axis=1).columns[(xgb_for_feature_selection.feature_importances_ > threshold)].tolist()\n",
        "print(\"Características seleccionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed-WLhQ4bPiM"
      },
      "source": [
        "Balanceo con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i8PrZ1K8bP7s"
      },
      "outputs": [],
      "source": [
        "# 3. Balanceo con SMOTE\n",
        "X = df[selected_features]\n",
        "y = df['Churn']\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiFgAaybheu"
      },
      "source": [
        "División de Conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. División de Conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definición de la función para crear el modelo ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Definición de la función para crear el modelo ANN\n",
        "def create_ann_model(learning_rate=0.001):  # Added learning_rate argument with a default value\n",
        "    ann_model = Sequential()\n",
        "    ann_model.add(Dense(48, activation='relu', input_dim=len(selected_features)))\n",
        "    ann_model.add(Dense(1, activation='sigmoid'))  # salida binaria\n",
        "    ann_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])  # Used learning_rate argument\n",
        "    return ann_model\n",
        "\n",
        "ann_model = KerasClassifier(build_fn=create_ann_model, epochs=100, batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGkhCSKbZAy"
      },
      "source": [
        "Inicializar modelos con los hiperparámetros óptimos encontrados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pHoztCgybaO5"
      },
      "outputs": [],
      "source": [
        "# 5. Inicializar modelos con los hiperparámetros óptimos encontrados\n",
        "def objective(trial):\n",
        "    # Hiperparámetros sugeridos\n",
        "    xgb_params = {\n",
        "        'subsample': trial.suggest_float('xgb__subsample', 0.1, 1),\n",
        "        'scale_pos_weight': trial.suggest_float('xgb__scale_pos_weight', 1, 10),\n",
        "        'reg_lambda': trial.suggest_float('xgb__reg_lambda', 0.1, 10),\n",
        "        'n_estimators': trial.suggest_int('xgb__n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('xgb__max_depth', 1, 10),\n",
        "        'learning_rate': trial.suggest_float('xgb__learning_rate', 0.01, 1, log=True),\n",
        "        'gamma': trial.suggest_float('xgb__gamma', 0, 1),\n",
        "        'colsample_bytree': trial.suggest_float('xgb__colsample_bytree', 0.1, 1),\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf__n_estimators', 100, 1000),\n",
        "        'min_samples_split': trial.suggest_int('rf__min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('rf__min_samples_leaf', 1, 20),\n",
        "        'max_depth': trial.suggest_int('rf__max_depth', 1, 10),\n",
        "        'bootstrap': trial.suggest_categorical('rf__bootstrap', [True, False]),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    ann_params = {\n",
        "        'epochs': trial.suggest_int('ann__epochs', 10, 200),\n",
        "        'batch_size': trial.suggest_int('ann__batch_size', 16, 128),\n",
        "        'learning_rate': trial.suggest_float('ann__learning_rate', 1e-5, 1e-1, log=True)\n",
        "    }\n",
        "    xgb_model = XGBClassifier(**xgb_params)\n",
        "    rf_model = RandomForestClassifier(**rf_params)\n",
        "    ann_model = KerasClassifier(build_fn=lambda learning_rate=ann_params['learning_rate']: create_ann_model(learning_rate), **ann_params)\n",
        "\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[('xgb', xgb_model), ('ann', ann_model), ('rf', rf_model)],\n",
        "        voting='soft'\n",
        "    )\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred = voting_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crear un Voting Classifier con soft voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:24:03,719] A new study created in memory with name: no-name-77aa4727-de2b-4044-99fe-802a98e85139\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "2023-11-05 23:24:05.215710: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
            "2023-11-05 23:24:05.215737: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2023-11-05 23:24:05.215755: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2023-11-05 23:24:05.215962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-11-05 23:24:05.215979: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-05 23:24:06.137072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 4s 12ms/step - loss: 0.4484 - accuracy: 0.7893\n",
            "Epoch 2/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4083 - accuracy: 0.8077\n",
            "Epoch 3/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4050 - accuracy: 0.8099\n",
            "Epoch 4/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4084 - accuracy: 0.8101\n",
            "Epoch 5/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4120 - accuracy: 0.8068\n",
            "Epoch 6/132\n",
            "76/76 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8096\n",
            "Epoch 7/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4105 - accuracy: 0.8070\n",
            "Epoch 8/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8033\n",
            "Epoch 9/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8035\n",
            "Epoch 10/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4153 - accuracy: 0.8039\n",
            "Epoch 11/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4101 - accuracy: 0.8079\n",
            "Epoch 12/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4210 - accuracy: 0.8020\n",
            "Epoch 13/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4270 - accuracy: 0.7993\n",
            "Epoch 14/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4144 - accuracy: 0.8081\n",
            "Epoch 15/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4092 - accuracy: 0.8112\n",
            "Epoch 16/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4262 - accuracy: 0.7971\n",
            "Epoch 17/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4142 - accuracy: 0.8077\n",
            "Epoch 18/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.7996\n",
            "Epoch 19/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.7987\n",
            "Epoch 20/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8007\n",
            "Epoch 21/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8029\n",
            "Epoch 22/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8018\n",
            "Epoch 23/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8057\n",
            "Epoch 24/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4221 - accuracy: 0.8035\n",
            "Epoch 25/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4155 - accuracy: 0.8007\n",
            "Epoch 26/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4307 - accuracy: 0.7993\n",
            "Epoch 27/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4331 - accuracy: 0.7965\n",
            "Epoch 28/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4198 - accuracy: 0.8046\n",
            "Epoch 29/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4321 - accuracy: 0.7941\n",
            "Epoch 30/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4167 - accuracy: 0.8105\n",
            "Epoch 31/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4380 - accuracy: 0.7956\n",
            "Epoch 32/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4316 - accuracy: 0.8024\n",
            "Epoch 33/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8024\n",
            "Epoch 34/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.7895\n",
            "Epoch 35/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8046\n",
            "Epoch 36/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4419 - accuracy: 0.7930\n",
            "Epoch 37/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.8024\n",
            "Epoch 38/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4436 - accuracy: 0.7923\n",
            "Epoch 39/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4253 - accuracy: 0.8004\n",
            "Epoch 40/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4458 - accuracy: 0.7910\n",
            "Epoch 41/132\n",
            "76/76 [==============================] - 1s 15ms/step - loss: 0.4567 - accuracy: 0.7868\n",
            "Epoch 42/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4254 - accuracy: 0.7989\n",
            "Epoch 43/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4330 - accuracy: 0.7961\n",
            "Epoch 44/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4268 - accuracy: 0.8004\n",
            "Epoch 45/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4605 - accuracy: 0.7877\n",
            "Epoch 46/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4379 - accuracy: 0.7971\n",
            "Epoch 47/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.7945\n",
            "Epoch 48/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4570 - accuracy: 0.7941\n",
            "Epoch 49/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7897\n",
            "Epoch 50/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7954\n",
            "Epoch 51/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7936\n",
            "Epoch 52/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4286 - accuracy: 0.7998\n",
            "Epoch 53/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4553 - accuracy: 0.7921\n",
            "Epoch 54/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4710 - accuracy: 0.7851\n",
            "Epoch 55/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4298 - accuracy: 0.8035\n",
            "Epoch 56/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4247 - accuracy: 0.8048\n",
            "Epoch 57/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4554 - accuracy: 0.7851\n",
            "Epoch 58/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.7774\n",
            "Epoch 59/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4538 - accuracy: 0.7921\n",
            "Epoch 60/132\n",
            "76/76 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7967\n",
            "Epoch 61/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.7987\n",
            "Epoch 62/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.7985\n",
            "Epoch 63/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.7980\n",
            "Epoch 64/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7809\n",
            "Epoch 65/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.5285 - accuracy: 0.7713\n",
            "Epoch 66/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4478 - accuracy: 0.7941\n",
            "Epoch 67/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4478 - accuracy: 0.7936\n",
            "Epoch 68/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.4430 - accuracy: 0.7921\n",
            "Epoch 69/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.5260 - accuracy: 0.7673\n",
            "Epoch 70/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4644 - accuracy: 0.7950\n",
            "Epoch 71/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4531 - accuracy: 0.7947\n",
            "Epoch 72/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.7989\n",
            "Epoch 73/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4519 - accuracy: 0.7899\n",
            "Epoch 74/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4626 - accuracy: 0.7866\n",
            "Epoch 75/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7886\n",
            "Epoch 76/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7912\n",
            "Epoch 77/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7974\n",
            "Epoch 78/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4609 - accuracy: 0.7877\n",
            "Epoch 79/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4542 - accuracy: 0.7873\n",
            "Epoch 80/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4756 - accuracy: 0.7822\n",
            "Epoch 81/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4487 - accuracy: 0.7985\n",
            "Epoch 82/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4334 - accuracy: 0.8033\n",
            "Epoch 83/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4966 - accuracy: 0.7748\n",
            "Epoch 84/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4856 - accuracy: 0.7794\n",
            "Epoch 85/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8072\n",
            "Epoch 86/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.7912\n",
            "Epoch 87/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4928 - accuracy: 0.7803\n",
            "Epoch 88/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7768\n",
            "Epoch 89/132\n",
            "76/76 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7919\n",
            "Epoch 90/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7904\n",
            "Epoch 91/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8050\n",
            "Epoch 92/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4532 - accuracy: 0.7912\n",
            "Epoch 93/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4863 - accuracy: 0.7855\n",
            "Epoch 94/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4729 - accuracy: 0.7864\n",
            "Epoch 95/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4446 - accuracy: 0.7886\n",
            "Epoch 96/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4722 - accuracy: 0.7890\n",
            "Epoch 97/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4658 - accuracy: 0.7853\n",
            "Epoch 98/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4662 - accuracy: 0.7958\n",
            "Epoch 99/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.7842\n",
            "Epoch 100/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7939\n",
            "Epoch 101/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7818\n",
            "Epoch 102/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4540 - accuracy: 0.7893\n",
            "Epoch 103/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.5062 - accuracy: 0.7814\n",
            "Epoch 104/132\n",
            "76/76 [==============================] - 1s 12ms/step - loss: 0.5014 - accuracy: 0.7825\n",
            "Epoch 105/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4844 - accuracy: 0.7838\n",
            "Epoch 106/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4832 - accuracy: 0.7875\n",
            "Epoch 107/132\n",
            "76/76 [==============================] - 1s 11ms/step - loss: 0.4569 - accuracy: 0.7906\n",
            "Epoch 108/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.7884\n",
            "Epoch 109/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.7923\n",
            "Epoch 110/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.7803\n",
            "Epoch 111/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7954\n",
            "Epoch 112/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7822\n",
            "Epoch 113/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4837 - accuracy: 0.7822\n",
            "Epoch 114/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4929 - accuracy: 0.7772\n",
            "Epoch 115/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4595 - accuracy: 0.7925\n",
            "Epoch 116/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4811 - accuracy: 0.7820\n",
            "Epoch 117/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4867 - accuracy: 0.7884\n",
            "Epoch 118/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.5098 - accuracy: 0.7726\n",
            "Epoch 119/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.4605 - accuracy: 0.7954\n",
            "Epoch 120/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.7866\n",
            "Epoch 121/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7844\n",
            "Epoch 122/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7919\n",
            "Epoch 123/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4742 - accuracy: 0.7879\n",
            "Epoch 124/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4925 - accuracy: 0.7796\n",
            "Epoch 125/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4871 - accuracy: 0.7886\n",
            "Epoch 126/132\n",
            "76/76 [==============================] - 1s 10ms/step - loss: 0.4637 - accuracy: 0.7873\n",
            "Epoch 127/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.5004 - accuracy: 0.7750\n",
            "Epoch 128/132\n",
            "76/76 [==============================] - 1s 9ms/step - loss: 0.4982 - accuracy: 0.7805\n",
            "Epoch 129/132\n",
            "76/76 [==============================] - 1s 7ms/step - loss: 0.5183 - accuracy: 0.7739\n",
            "Epoch 130/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7882\n",
            "Epoch 131/132\n",
            "76/76 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7873\n",
            "Epoch 132/132\n",
            "76/76 [==============================] - 1s 8ms/step - loss: 0.5116 - accuracy: 0.7757\n",
            "19/19 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:25:41,894] Trial 0 finished with value: 0.9298245614035088 and parameters: {'xgb__subsample': 0.8585032378891985, 'xgb__scale_pos_weight': 2.686299663676034, 'xgb__reg_lambda': 9.777372270241651, 'xgb__n_estimators': 541, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.591565643324633, 'xgb__gamma': 0.004041065299798887, 'xgb__colsample_bytree': 0.6693673534860863, 'rf__n_estimators': 508, 'rf__min_samples_split': 12, 'rf__min_samples_leaf': 16, 'rf__max_depth': 8, 'rf__bootstrap': False, 'ann__epochs': 132, 'ann__batch_size': 60, 'ann__learning_rate': 0.005501378205040184}. Best is trial 0 with value: 0.9298245614035088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 6s 24ms/step - loss: 0.6052 - accuracy: 0.6721\n",
            "Epoch 2/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.5184 - accuracy: 0.7533\n",
            "Epoch 3/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.4784 - accuracy: 0.7822\n",
            "Epoch 4/44\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 0.4554 - accuracy: 0.7930\n",
            "Epoch 5/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.4404 - accuracy: 0.8015\n",
            "Epoch 6/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.4303 - accuracy: 0.8088\n",
            "Epoch 7/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.4228 - accuracy: 0.8118\n",
            "Epoch 8/44\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.4175 - accuracy: 0.8147\n",
            "Epoch 9/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.4134 - accuracy: 0.8167\n",
            "Epoch 10/44\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.4101 - accuracy: 0.8180\n",
            "Epoch 11/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.4077 - accuracy: 0.8158\n",
            "Epoch 12/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.4058 - accuracy: 0.8167\n",
            "Epoch 13/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4040 - accuracy: 0.8164\n",
            "Epoch 14/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4028 - accuracy: 0.8173\n",
            "Epoch 15/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.4015 - accuracy: 0.8160\n",
            "Epoch 16/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.4006 - accuracy: 0.8189\n",
            "Epoch 17/44\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.3999 - accuracy: 0.8189\n",
            "Epoch 18/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3993 - accuracy: 0.8173\n",
            "Epoch 19/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3987 - accuracy: 0.8156\n",
            "Epoch 20/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.3981 - accuracy: 0.8167\n",
            "Epoch 21/44\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.3977 - accuracy: 0.8160\n",
            "Epoch 22/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3974 - accuracy: 0.8173\n",
            "Epoch 23/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3970 - accuracy: 0.8164\n",
            "Epoch 24/44\n",
            "127/127 [==============================] - 3s 26ms/step - loss: 0.3969 - accuracy: 0.8178\n",
            "Epoch 25/44\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.3965 - accuracy: 0.8204\n",
            "Epoch 26/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3964 - accuracy: 0.8164\n",
            "Epoch 27/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.3961 - accuracy: 0.8158\n",
            "Epoch 28/44\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.3959 - accuracy: 0.8175\n",
            "Epoch 29/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3960 - accuracy: 0.8162\n",
            "Epoch 30/44\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.3957 - accuracy: 0.8186\n",
            "Epoch 31/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3954 - accuracy: 0.8158\n",
            "Epoch 32/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3954 - accuracy: 0.8189\n",
            "Epoch 33/44\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.3953 - accuracy: 0.8175\n",
            "Epoch 34/44\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3953 - accuracy: 0.8164\n",
            "Epoch 35/44\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.3951 - accuracy: 0.8184\n",
            "Epoch 36/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3950 - accuracy: 0.8171\n",
            "Epoch 37/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3950 - accuracy: 0.8178\n",
            "Epoch 38/44\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.3948 - accuracy: 0.8160\n",
            "Epoch 39/44\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.3948 - accuracy: 0.8180\n",
            "Epoch 40/44\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.3947 - accuracy: 0.8173\n",
            "Epoch 41/44\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.3947 - accuracy: 0.8175\n",
            "Epoch 42/44\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.3945 - accuracy: 0.8191\n",
            "Epoch 43/44\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.3947 - accuracy: 0.8162\n",
            "Epoch 44/44\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.8162\n",
            "32/32 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:26:59,778] Trial 1 finished with value: 0.8903508771929824 and parameters: {'xgb__subsample': 0.4370861069626263, 'xgb__scale_pos_weight': 9.556428757689245, 'xgb__reg_lambda': 7.34674002393291, 'xgb__n_estimators': 639, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.020511104188433976, 'xgb__gamma': 0.05808361216819946, 'xgb__colsample_bytree': 0.8795585311974417, 'rf__n_estimators': 641, 'rf__min_samples_split': 15, 'rf__min_samples_leaf': 1, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 44, 'ann__batch_size': 36, 'ann__learning_rate': 0.00016480446427978953}. Best is trial 0 with value: 0.9298245614035088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - 6s 18ms/step - loss: 0.6223 - accuracy: 0.7592\n",
            "Epoch 2/42\n",
            "199/199 [==============================] - 3s 14ms/step - loss: 0.8289 - accuracy: 0.7572\n",
            "Epoch 3/42\n",
            "199/199 [==============================] - 3s 13ms/step - loss: 1.0061 - accuracy: 0.7395\n",
            "Epoch 4/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 1.2974 - accuracy: 0.7309\n",
            "Epoch 5/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 1.2623 - accuracy: 0.7425\n",
            "Epoch 6/42\n",
            "199/199 [==============================] - 3s 14ms/step - loss: 1.4026 - accuracy: 0.7382\n",
            "Epoch 7/42\n",
            "199/199 [==============================] - 3s 14ms/step - loss: 2.1841 - accuracy: 0.7375\n",
            "Epoch 8/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 2.0352 - accuracy: 0.7421\n",
            "Epoch 9/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 3.2190 - accuracy: 0.7316\n",
            "Epoch 10/42\n",
            "199/199 [==============================] - 2s 12ms/step - loss: 3.0814 - accuracy: 0.7362\n",
            "Epoch 11/42\n",
            "199/199 [==============================] - 3s 14ms/step - loss: 2.9542 - accuracy: 0.7401\n",
            "Epoch 12/42\n",
            "199/199 [==============================] - 2s 11ms/step - loss: 2.8765 - accuracy: 0.7410\n",
            "Epoch 13/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 3.6939 - accuracy: 0.7463\n",
            "Epoch 14/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 3.4687 - accuracy: 0.7441\n",
            "Epoch 15/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 3.6881 - accuracy: 0.7414\n",
            "Epoch 16/42\n",
            "199/199 [==============================] - 2s 9ms/step - loss: 4.0454 - accuracy: 0.7366\n",
            "Epoch 17/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 4.5880 - accuracy: 0.7360\n",
            "Epoch 18/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 5.6424 - accuracy: 0.7397\n",
            "Epoch 19/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 4.5994 - accuracy: 0.7379\n",
            "Epoch 20/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 4.5322 - accuracy: 0.7355\n",
            "Epoch 21/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 5.4379 - accuracy: 0.7401\n",
            "Epoch 22/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 6.7537 - accuracy: 0.7373\n",
            "Epoch 23/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 6.4230 - accuracy: 0.7397\n",
            "Epoch 24/42\n",
            "199/199 [==============================] - 2s 10ms/step - loss: 6.8952 - accuracy: 0.7465\n",
            "Epoch 25/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 5.3968 - accuracy: 0.7393\n",
            "Epoch 26/42\n",
            "199/199 [==============================] - 2s 9ms/step - loss: 7.5447 - accuracy: 0.7346\n",
            "Epoch 27/42\n",
            "199/199 [==============================] - 2s 9ms/step - loss: 6.4554 - accuracy: 0.7467\n",
            "Epoch 28/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 7.8027 - accuracy: 0.7338\n",
            "Epoch 29/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 7.9109 - accuracy: 0.7357\n",
            "Epoch 30/42\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 8.3076 - accuracy: 0.7386\n",
            "Epoch 31/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 6.9627 - accuracy: 0.7410\n",
            "Epoch 32/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 8.2457 - accuracy: 0.7390\n",
            "Epoch 33/42\n",
            "199/199 [==============================] - 2s 11ms/step - loss: 6.2126 - accuracy: 0.7535\n",
            "Epoch 34/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 7.2081 - accuracy: 0.7450\n",
            "Epoch 35/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 7.5757 - accuracy: 0.7425\n",
            "Epoch 36/42\n",
            "199/199 [==============================] - 2s 12ms/step - loss: 8.2344 - accuracy: 0.7480\n",
            "Epoch 37/42\n",
            "199/199 [==============================] - 2s 8ms/step - loss: 8.5565 - accuracy: 0.7397\n",
            "Epoch 38/42\n",
            "199/199 [==============================] - 3s 14ms/step - loss: 8.0453 - accuracy: 0.7430\n",
            "Epoch 39/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 8.9207 - accuracy: 0.7412\n",
            "Epoch 40/42\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 9.5921 - accuracy: 0.7397\n",
            "Epoch 41/42\n",
            "199/199 [==============================] - 2s 9ms/step - loss: 8.5269 - accuracy: 0.7498\n",
            "Epoch 42/42\n",
            "199/199 [==============================] - 2s 9ms/step - loss: 7.3264 - accuracy: 0.7496\n",
            "50/50 [==============================] - 1s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:28:40,546] Trial 2 finished with value: 0.8570175438596491 and parameters: {'xgb__subsample': 0.5722807884690141, 'xgb__scale_pos_weight': 4.887505167779041, 'xgb__reg_lambda': 2.983168487960615, 'xgb__n_estimators': 651, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.03839629299804171, 'xgb__gamma': 0.3663618432936917, 'xgb__colsample_bytree': 0.5104629857953323, 'rf__n_estimators': 807, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 11, 'rf__max_depth': 6, 'rf__bootstrap': False, 'ann__epochs': 42, 'ann__batch_size': 23, 'ann__learning_rate': 0.06245139574743072}. Best is trial 0 with value: 0.9298245614035088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 5s 19ms/step - loss: 0.6313 - accuracy: 0.7627\n",
            "Epoch 2/114\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.8251 - accuracy: 0.7450\n",
            "Epoch 3/114\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.7005 - accuracy: 0.7522\n",
            "Epoch 4/114\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.8466 - accuracy: 0.7463\n",
            "Epoch 5/114\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.8943 - accuracy: 0.7524\n",
            "Epoch 6/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4640 - accuracy: 0.7379\n",
            "Epoch 7/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 1.5099 - accuracy: 0.7393\n",
            "Epoch 8/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 2.3434 - accuracy: 0.7371\n",
            "Epoch 9/114\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 2.0485 - accuracy: 0.7364\n",
            "Epoch 10/114\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 1.7913 - accuracy: 0.7443\n",
            "Epoch 11/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 2.0253 - accuracy: 0.7390\n",
            "Epoch 12/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 2.5336 - accuracy: 0.7377\n",
            "Epoch 13/114\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.3542 - accuracy: 0.7397\n",
            "Epoch 14/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 2.5534 - accuracy: 0.7386\n",
            "Epoch 15/114\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 2.5470 - accuracy: 0.7487\n",
            "Epoch 16/114\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 4.4037 - accuracy: 0.7346\n",
            "Epoch 17/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 3.3108 - accuracy: 0.7489\n",
            "Epoch 18/114\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 3.5791 - accuracy: 0.7298\n",
            "Epoch 19/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 3.5618 - accuracy: 0.7395\n",
            "Epoch 20/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 4.1650 - accuracy: 0.7360\n",
            "Epoch 21/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 3.7605 - accuracy: 0.7465\n",
            "Epoch 22/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 3.4277 - accuracy: 0.7401\n",
            "Epoch 23/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 5.7136 - accuracy: 0.7443\n",
            "Epoch 24/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 4.5236 - accuracy: 0.7463\n",
            "Epoch 25/114\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 5.8139 - accuracy: 0.7377\n",
            "Epoch 26/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 5.4378 - accuracy: 0.7447\n",
            "Epoch 27/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 4.7853 - accuracy: 0.7513\n",
            "Epoch 28/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 4.2715 - accuracy: 0.7526\n",
            "Epoch 29/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 4.2457 - accuracy: 0.7434\n",
            "Epoch 30/114\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 6.2832 - accuracy: 0.7439\n",
            "Epoch 31/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 6.6015 - accuracy: 0.7412\n",
            "Epoch 32/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 5.6125 - accuracy: 0.7537\n",
            "Epoch 33/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 4.3907 - accuracy: 0.7434\n",
            "Epoch 34/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 6.7824 - accuracy: 0.7417\n",
            "Epoch 35/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 5.6045 - accuracy: 0.7469\n",
            "Epoch 36/114\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 9.6424 - accuracy: 0.7325\n",
            "Epoch 37/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 7.1461 - accuracy: 0.7515\n",
            "Epoch 38/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 6.4427 - accuracy: 0.7518\n",
            "Epoch 39/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 6.1526 - accuracy: 0.7454\n",
            "Epoch 40/114\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 7.0789 - accuracy: 0.7408\n",
            "Epoch 41/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 8.3125 - accuracy: 0.7421\n",
            "Epoch 42/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 9.0823 - accuracy: 0.7434\n",
            "Epoch 43/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 7.2411 - accuracy: 0.7377\n",
            "Epoch 44/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 6.5656 - accuracy: 0.7535\n",
            "Epoch 45/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 5.1921 - accuracy: 0.7443\n",
            "Epoch 46/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 5.8695 - accuracy: 0.7539\n",
            "Epoch 47/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 6.6484 - accuracy: 0.7375\n",
            "Epoch 48/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 8.5387 - accuracy: 0.7360\n",
            "Epoch 49/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 10.3678 - accuracy: 0.7410\n",
            "Epoch 50/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 7.8699 - accuracy: 0.7362\n",
            "Epoch 51/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 11.5290 - accuracy: 0.7362\n",
            "Epoch 52/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 8.3492 - accuracy: 0.7423\n",
            "Epoch 53/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 8.8415 - accuracy: 0.7515\n",
            "Epoch 54/114\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 9.1212 - accuracy: 0.7526\n",
            "Epoch 55/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 7.6674 - accuracy: 0.7375\n",
            "Epoch 56/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 7.2040 - accuracy: 0.7487\n",
            "Epoch 57/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 8.1382 - accuracy: 0.7452\n",
            "Epoch 58/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 9.8392 - accuracy: 0.7329\n",
            "Epoch 59/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 9.5206 - accuracy: 0.7340\n",
            "Epoch 60/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 10.6351 - accuracy: 0.7382\n",
            "Epoch 61/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 10.4726 - accuracy: 0.7419\n",
            "Epoch 62/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 8.0507 - accuracy: 0.7476\n",
            "Epoch 63/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 8.1539 - accuracy: 0.7430\n",
            "Epoch 64/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 12.5268 - accuracy: 0.7285\n",
            "Epoch 65/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 9.0708 - accuracy: 0.7546\n",
            "Epoch 66/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 11.1845 - accuracy: 0.7327\n",
            "Epoch 67/114\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 9.3471 - accuracy: 0.7575\n",
            "Epoch 68/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 9.3054 - accuracy: 0.7544\n",
            "Epoch 69/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 10.0293 - accuracy: 0.7487\n",
            "Epoch 70/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 10.3648 - accuracy: 0.7384\n",
            "Epoch 71/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 8.7956 - accuracy: 0.7485\n",
            "Epoch 72/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 10.9484 - accuracy: 0.7357\n",
            "Epoch 73/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 12.4679 - accuracy: 0.7414\n",
            "Epoch 74/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 8.6525 - accuracy: 0.7511\n",
            "Epoch 75/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 9.1840 - accuracy: 0.7434\n",
            "Epoch 76/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 12.6937 - accuracy: 0.7425\n",
            "Epoch 77/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 10.7940 - accuracy: 0.7443\n",
            "Epoch 78/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 14.9243 - accuracy: 0.7338\n",
            "Epoch 79/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 11.2718 - accuracy: 0.7487\n",
            "Epoch 80/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 12.2301 - accuracy: 0.7502\n",
            "Epoch 81/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 10.2993 - accuracy: 0.7518\n",
            "Epoch 82/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 11.5236 - accuracy: 0.7439\n",
            "Epoch 83/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 9.7150 - accuracy: 0.7601\n",
            "Epoch 84/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 11.9424 - accuracy: 0.7368\n",
            "Epoch 85/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 12.4375 - accuracy: 0.7515\n",
            "Epoch 86/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 14.0157 - accuracy: 0.7502\n",
            "Epoch 87/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 11.8063 - accuracy: 0.7526\n",
            "Epoch 88/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 16.7414 - accuracy: 0.7399\n",
            "Epoch 89/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 11.0005 - accuracy: 0.7491\n",
            "Epoch 90/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 12.8529 - accuracy: 0.7384\n",
            "Epoch 91/114\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 12.1710 - accuracy: 0.7489\n",
            "Epoch 92/114\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 14.8204 - accuracy: 0.7414\n",
            "Epoch 93/114\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 9.3545 - accuracy: 0.7570\n",
            "Epoch 94/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 13.7073 - accuracy: 0.7373\n",
            "Epoch 95/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 15.4927 - accuracy: 0.7443\n",
            "Epoch 96/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 13.2008 - accuracy: 0.7408\n",
            "Epoch 97/114\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 14.9547 - accuracy: 0.7445\n",
            "Epoch 98/114\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 12.0371 - accuracy: 0.7487\n",
            "Epoch 99/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 14.4396 - accuracy: 0.7445\n",
            "Epoch 100/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 11.4341 - accuracy: 0.7529\n",
            "Epoch 101/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 12.0385 - accuracy: 0.7498\n",
            "Epoch 102/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 16.4553 - accuracy: 0.7325\n",
            "Epoch 103/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 17.1683 - accuracy: 0.7441\n",
            "Epoch 104/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 14.2979 - accuracy: 0.7520\n",
            "Epoch 105/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 15.1737 - accuracy: 0.7425\n",
            "Epoch 106/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 12.1006 - accuracy: 0.7550\n",
            "Epoch 107/114\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 9.9765 - accuracy: 0.7454\n",
            "Epoch 108/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 14.5884 - accuracy: 0.7305\n",
            "Epoch 109/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 14.0812 - accuracy: 0.7487\n",
            "Epoch 110/114\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 13.8404 - accuracy: 0.7406\n",
            "Epoch 111/114\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 14.3798 - accuracy: 0.7355\n",
            "Epoch 112/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 17.8233 - accuracy: 0.7417\n",
            "Epoch 113/114\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 14.6021 - accuracy: 0.7445\n",
            "Epoch 114/114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 12.3291 - accuracy: 0.7502\n",
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:31:19,328] Trial 3 finished with value: 0.9254385964912281 and parameters: {'xgb__subsample': 0.9690688297671034, 'xgb__scale_pos_weight': 8.275576133048151, 'xgb__reg_lambda': 3.11567631481637, 'xgb__n_estimators': 188, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.07591104805282695, 'xgb__gamma': 0.12203823484477883, 'xgb__colsample_bytree': 0.5456592191001431, 'rf__n_estimators': 130, 'rf__min_samples_split': 19, 'rf__min_samples_leaf': 6, 'rf__max_depth': 7, 'rf__bootstrap': False, 'ann__epochs': 114, 'ann__batch_size': 36, 'ann__learning_rate': 0.07556810141274425}. Best is trial 0 with value: 0.9298245614035088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "148/148 [==============================] - 6s 26ms/step - loss: 0.4415 - accuracy: 0.7928\n",
            "Epoch 2/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.7987\n",
            "Epoch 3/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.4564 - accuracy: 0.7838\n",
            "Epoch 4/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.4340 - accuracy: 0.8000\n",
            "Epoch 5/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.4654 - accuracy: 0.7910\n",
            "Epoch 6/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.4846 - accuracy: 0.7807\n",
            "Epoch 7/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.4941 - accuracy: 0.7849\n",
            "Epoch 8/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5057 - accuracy: 0.7857\n",
            "Epoch 9/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5569 - accuracy: 0.7691\n",
            "Epoch 10/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.5650 - accuracy: 0.7737\n",
            "Epoch 11/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.5128 - accuracy: 0.7809\n",
            "Epoch 12/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5288 - accuracy: 0.7768\n",
            "Epoch 13/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.6516 - accuracy: 0.7555\n",
            "Epoch 14/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5604 - accuracy: 0.7686\n",
            "Epoch 15/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.5945 - accuracy: 0.7713\n",
            "Epoch 16/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.5460 - accuracy: 0.7748\n",
            "Epoch 17/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5572 - accuracy: 0.7693\n",
            "Epoch 18/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5993 - accuracy: 0.7689\n",
            "Epoch 19/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.5998 - accuracy: 0.7697\n",
            "Epoch 20/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.5964 - accuracy: 0.7673\n",
            "Epoch 21/113\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.7708 - accuracy: 0.7572\n",
            "Epoch 22/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.7351 - accuracy: 0.7686\n",
            "Epoch 23/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5778 - accuracy: 0.7759\n",
            "Epoch 24/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.5888 - accuracy: 0.7752\n",
            "Epoch 25/113\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.6579 - accuracy: 0.7638\n",
            "Epoch 26/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.9338 - accuracy: 0.7610\n",
            "Epoch 27/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.7268 - accuracy: 0.7614\n",
            "Epoch 28/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.7039 - accuracy: 0.7627\n",
            "Epoch 29/113\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.6133 - accuracy: 0.7654\n",
            "Epoch 30/113\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 0.9056 - accuracy: 0.7412\n",
            "Epoch 31/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.6993 - accuracy: 0.7660\n",
            "Epoch 32/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.7757\n",
            "Epoch 33/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.7822 - accuracy: 0.7518\n",
            "Epoch 34/113\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 0.7390 - accuracy: 0.7561\n",
            "Epoch 35/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.7405 - accuracy: 0.7605\n",
            "Epoch 36/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.7648 - accuracy: 0.7520\n",
            "Epoch 37/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.8114 - accuracy: 0.7596\n",
            "Epoch 38/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.8027 - accuracy: 0.7605\n",
            "Epoch 39/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 0.7970 - accuracy: 0.7555\n",
            "Epoch 40/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.7735 - accuracy: 0.7568\n",
            "Epoch 41/113\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.8689 - accuracy: 0.7507\n",
            "Epoch 42/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9694 - accuracy: 0.7428\n",
            "Epoch 43/113\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.9366 - accuracy: 0.7515\n",
            "Epoch 44/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.7420 - accuracy: 0.7625\n",
            "Epoch 45/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.1309 - accuracy: 0.7504\n",
            "Epoch 46/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.9464 - accuracy: 0.7568\n",
            "Epoch 47/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9005 - accuracy: 0.7544\n",
            "Epoch 48/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.0153 - accuracy: 0.7478\n",
            "Epoch 49/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.0075 - accuracy: 0.7553\n",
            "Epoch 50/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 0.7926 - accuracy: 0.7594\n",
            "Epoch 51/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9108 - accuracy: 0.7546\n",
            "Epoch 52/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.7510 - accuracy: 0.7623\n",
            "Epoch 53/113\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 1.0116 - accuracy: 0.7496\n",
            "Epoch 54/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.1601 - accuracy: 0.7461\n",
            "Epoch 55/113\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.9550 - accuracy: 0.7524\n",
            "Epoch 56/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9537 - accuracy: 0.7461\n",
            "Epoch 57/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 1.1394 - accuracy: 0.7564\n",
            "Epoch 58/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.0934 - accuracy: 0.7526\n",
            "Epoch 59/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.8426 - accuracy: 0.7590\n",
            "Epoch 60/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9489 - accuracy: 0.7489\n",
            "Epoch 61/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.8184 - accuracy: 0.7544\n",
            "Epoch 62/113\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.7723 - accuracy: 0.7632\n",
            "Epoch 63/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.1523 - accuracy: 0.7390\n",
            "Epoch 64/113\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 1.0743 - accuracy: 0.7482\n",
            "Epoch 65/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.0181 - accuracy: 0.7553\n",
            "Epoch 66/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.2179 - accuracy: 0.7476\n",
            "Epoch 67/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.1705 - accuracy: 0.7496\n",
            "Epoch 68/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.9292 - accuracy: 0.7607\n",
            "Epoch 69/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.8962 - accuracy: 0.7518\n",
            "Epoch 70/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.3336 - accuracy: 0.7395\n",
            "Epoch 71/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.0337 - accuracy: 0.7535\n",
            "Epoch 72/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 2.1401 - accuracy: 0.7360\n",
            "Epoch 73/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 1.0275 - accuracy: 0.7535\n",
            "Epoch 74/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.3203 - accuracy: 0.7408\n",
            "Epoch 75/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.2574 - accuracy: 0.7649\n",
            "Epoch 76/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.6295 - accuracy: 0.7344\n",
            "Epoch 77/113\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 1.1426 - accuracy: 0.7581\n",
            "Epoch 78/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.6060 - accuracy: 0.7445\n",
            "Epoch 79/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.0899 - accuracy: 0.7553\n",
            "Epoch 80/113\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 1.0825 - accuracy: 0.7623\n",
            "Epoch 81/113\n",
            "148/148 [==============================] - 2s 14ms/step - loss: 1.4887 - accuracy: 0.7366\n",
            "Epoch 82/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.6487 - accuracy: 0.7518\n",
            "Epoch 83/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.2227 - accuracy: 0.7564\n",
            "Epoch 84/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.1802 - accuracy: 0.7544\n",
            "Epoch 85/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.9956 - accuracy: 0.7518\n",
            "Epoch 86/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.2296 - accuracy: 0.7414\n",
            "Epoch 87/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.2540 - accuracy: 0.7564\n",
            "Epoch 88/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.2482 - accuracy: 0.7441\n",
            "Epoch 89/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.5455 - accuracy: 0.7469\n",
            "Epoch 90/113\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 1.2057 - accuracy: 0.7612\n",
            "Epoch 91/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 1.3946 - accuracy: 0.7333\n",
            "Epoch 92/113\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 1.4375 - accuracy: 0.7493\n",
            "Epoch 93/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.4588 - accuracy: 0.7371\n",
            "Epoch 94/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.5572 - accuracy: 0.7408\n",
            "Epoch 95/113\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 1.4495 - accuracy: 0.7509\n",
            "Epoch 96/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 2.3360 - accuracy: 0.7469\n",
            "Epoch 97/113\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 1.7802 - accuracy: 0.7436\n",
            "Epoch 98/113\n",
            "148/148 [==============================] - 2s 16ms/step - loss: 1.6606 - accuracy: 0.7546\n",
            "Epoch 99/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.4279 - accuracy: 0.7570\n",
            "Epoch 100/113\n",
            "148/148 [==============================] - 2s 15ms/step - loss: 1.8856 - accuracy: 0.7384\n",
            "Epoch 101/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.3146 - accuracy: 0.7522\n",
            "Epoch 102/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.3795 - accuracy: 0.7489\n",
            "Epoch 103/113\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1.5169 - accuracy: 0.7388\n",
            "Epoch 104/113\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 1.5911 - accuracy: 0.7518\n",
            "Epoch 105/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.6836 - accuracy: 0.7493\n",
            "Epoch 106/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.4115 - accuracy: 0.7601\n",
            "Epoch 107/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 1.6146 - accuracy: 0.7436\n",
            "Epoch 108/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1.2598 - accuracy: 0.7612\n",
            "Epoch 109/113\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 1.6365 - accuracy: 0.7377\n",
            "Epoch 110/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.8175 - accuracy: 0.7456\n",
            "Epoch 111/113\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 1.7668 - accuracy: 0.7570\n",
            "Epoch 112/113\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 1.8567 - accuracy: 0.7450\n",
            "Epoch 113/113\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 2.1836 - accuracy: 0.7421\n",
            "37/37 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 23:34:31,752] Trial 4 finished with value: 0.8964912280701754 and parameters: {'xgb__subsample': 0.7976195410250031, 'xgb__scale_pos_weight': 9.455490474077703, 'xgb__reg_lambda': 8.958790769233723, 'xgb__n_estimators': 638, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.015030900645056829, 'xgb__gamma': 0.1959828624191452, 'xgb__colsample_bytree': 0.14070456001948428, 'rf__n_estimators': 393, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 6, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 113, 'ann__batch_size': 31, 'ann__learning_rate': 0.016172900811143146}. Best is trial 0 with value: 0.9298245614035088.\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/73\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.6269 - accuracy: 0.6655"
          ]
        }
      ],
      "source": [
        "# 7. Creación del estudio Optuna\n",
        "initial_params = {\n",
        "    'xgb__subsample': 0.8585032378891985,\n",
        "    'xgb__scale_pos_weight': 2.686299663676034,\n",
        "    'xgb__reg_lambda': 9.777372270241651,\n",
        "    'xgb__n_estimators': 541,\n",
        "    'xgb__max_depth': 6,\n",
        "    'xgb__learning_rate': 0.591565643324633,\n",
        "    'xgb__gamma': 0.004041065299798887,\n",
        "    'xgb__colsample_bytree': 0.6693673534860863,\n",
        "    'rf__n_estimators': 508,\n",
        "    'rf__min_samples_split': 12,\n",
        "    'rf__min_samples_leaf': 16,\n",
        "    'rf__max_depth': 8,\n",
        "    'rf__bootstrap': False,\n",
        "    'ann__epochs': 132,\n",
        "    'ann__batch_size': 60,\n",
        "    'ann__learning_rate': 0.005501378205040184\n",
        "}\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
        "study.enqueue_trial(initial_params)\n",
        "study.optimize(objective, n_trials=50, timeout=None)  # Puede ajustar n_trials y timeout según sus necesidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtención de los mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Obtención de los mejores hiperparámetros\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuuaC5amVQU"
      },
      "source": [
        "Evaluar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        }
      ],
      "source": [
        "# 9. Entrenamiento del modelo con los mejores hiperparámetros\n",
        "xgb_best = XGBClassifier(**{k[5:]: v for k, v in best_params.items() if k.startswith('xgb__')})\n",
        "rf_best = RandomForestClassifier(**{k[4:]: v for k, v in best_params.items() if k.startswith('rf__')})\n",
        "ann_best = KerasClassifier(\n",
        "    build_fn=lambda: create_ann_model(learning_rate=best_params['ann__learning_rate']),\n",
        "    epochs=best_params['ann__epochs'],\n",
        "    batch_size=best_params['ann__batch_size'],\n",
        "    verbose=0  # Asumiendo que quieres mantener el verbose en 0 como en tu código anterior\n",
        ")\n",
        "\n",
        "voting_clf_best = VotingClassifier(\n",
        "    estimators=[('xgb', xgb_best), ('ann', ann_best), ('rf', rf_best)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf_best.fit(X_train, y_train)\n",
        "y_pred_best = voting_clf_best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Evaluación del modelo\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
        "report_best = classification_report(y_test, y_pred_best)\n",
        "acc_best = accuracy_score(y_test, y_pred_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualización de la Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 11. Visualización de la Curva ROC\n",
        "y_pred_proba_best = voting_clf_best.predict_proba(X_test)[:,1]\n",
        "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, y_pred_proba_best)\n",
        "roc_auc_best = auc(fpr_best, tpr_best)\n",
        "plt.figure()\n",
        "plt.plot(fpr_best, tpr_best, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_best)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj8qFfB9b0t1"
      },
      "source": [
        "Imprimir los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNJzas7gb1ND",
        "outputId": "89d1b5bf-f368-43c9-e735-73a6be8d09ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros:  {'xgb__subsample': 0.9427629804456301, 'xgb__scale_pos_weight': 1.0320900158332558, 'xgb__reg_lambda': 0.7010703016048032, 'xgb__n_estimators': 651, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.13680927343211416, 'xgb__gamma': 0.04500991430601001, 'xgb__colsample_bytree': 0.8770206411553205, 'rf__n_estimators': 166, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10, 'rf__bootstrap': False, 'ann__epochs': 10, 'ann__batch_size': 71, 'ann__learning_rate': 0.003320651213411407}\n",
            "Matriz de Confusión:\n",
            "[[815 139]\n",
            " [110 824]]\n",
            "\n",
            "Informe de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87       954\n",
            "           1       0.86      0.88      0.87       934\n",
            "\n",
            "    accuracy                           0.87      1888\n",
            "   macro avg       0.87      0.87      0.87      1888\n",
            "weighted avg       0.87      0.87      0.87      1888\n",
            "\n",
            "\n",
            "Precisión del modelo híbrido: 0.868114406779661\n"
          ]
        }
      ],
      "source": [
        "# 12. Imprimir los resultados\n",
        "print('Mejores hiperparámetros: ', best_params)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(conf_matrix_best)\n",
        "print(\"\\nInforme de Clasificación:\")\n",
        "print(report_best)\n",
        "print(\"\\nPrecisión del modelo híbrido:\", acc_best)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
