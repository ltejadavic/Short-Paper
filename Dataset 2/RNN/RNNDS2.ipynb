{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJyg8xgbBD2"
      },
      "source": [
        "Importación y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tJA_xfxpbAlp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "# Importaciones\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from keras_tuner import Hyperband\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "df = pd.read_csv('Telco Churn dataset 2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3B405XRbMm_"
      },
      "source": [
        "Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuTS-4Da1iq",
        "outputId": "64269792-651b-47fc-a2aa-3a22c056507f"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocesamiento\n",
        "# a. Crear la columna 'Churn' y asignar 1 si 'Churn' es 'Yes', de lo contrario 0\n",
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# b. Eliminar columnas con más del 50% de datos faltantes\n",
        "threshold = int(0.5 * len(df))\n",
        "df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "# c. Reemplazar valores atípicos por la media\n",
        "for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "    if col != 'Churn':  # Asegurarse de no modificar la columna 'Churn'\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df[col] = df[col].apply(lambda x: df[col].mean() if (x < (Q1 - 1.5 * IQR)) or (x > (Q3 + 1.5 * IQR)) else x)\n",
        "\n",
        "# d. Convertir variables categóricas a numéricas y llenar valores faltantes\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object' and column != 'Churn':\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "    elif df[column].dtype in ['int64', 'float64']:\n",
        "        df[column].fillna(df[column].median(), inplace=True)\n",
        "\n",
        "# e. Normalización\n",
        "cols_to_scale = df.columns.tolist()\n",
        "cols_to_scale.remove('Churn')\n",
        "scaler = StandardScaler()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# f. Asegurarse de que 'Churn' sea int\n",
        "df['Churn'] = df['Churn'].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed-WLhQ4bPiM"
      },
      "source": [
        "Selección de características - Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i8PrZ1K8bP7s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características seleccionadas: ['customerID', 'SeniorCitizen', 'tenure', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'InternationalPlan', 'VoiceMailPlan', 'NumbervMailMessages', 'TotalDayMinutes', 'TotalEveMinutes', 'TotalNightMinutes', 'TotalIntlMinutes', 'TotalIntlCalls', 'CustomerServiceCalls']\n"
          ]
        }
      ],
      "source": [
        "# 2. Selección de características\n",
        "xgb_for_feature_selection = XGBClassifier(\n",
        "    objective='binary:logistic', \n",
        "    random_state=42, \n",
        "    use_label_encoder=False, \n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_for_feature_selection.fit(df.drop('Churn', axis=1), df['Churn'])\n",
        "threshold = 0.01  \n",
        "selected_features = df.drop('Churn', axis=1).columns[(xgb_for_feature_selection.feature_importances_ > threshold)].tolist()\n",
        "print(\"Características seleccionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Balanceo con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Balanceo con SMOTE\n",
        "X = df[selected_features]\n",
        "y = df['Churn']\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiFgAaybheu"
      },
      "source": [
        "División de Conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. División de Conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparación de Datos para RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Preparación de Datos para RNN\n",
        "X_train_rnn = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_rnn = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGkhCSKbZAy"
      },
      "source": [
        "Entrenamiento de RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pHoztCgybaO5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 24 Complete [00h 00m 16s]\n",
            "val_accuracy: 0.8870614171028137\n",
            "\n",
            "Best val_accuracy So Far: 0.8980262875556946\n",
            "Total elapsed time: 00h 05m 56s\n",
            "\n",
            "Los mejores hiperparámetros encontrados:\n",
            "Número de unidades: 40\n",
            "Tasa de aprendizaje: 0.01\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6. Entrenamiento de RNN con búsqueda de hiperparámetros usando Keras Tuner\n",
        "def build_rnn_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=8, max_value=64, step=8), \n",
        "                   input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), \n",
        "                   return_sequences=True))\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=8, max_value=64, step=8), return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.01, 0.1]))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "tuner_rnn = Hyperband(\n",
        "    build_rnn_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=100,\n",
        "    hyperband_iterations=2,\n",
        "    directory='my_dir',\n",
        "    project_name='keras_tuner_rnn_example'\n",
        ")\n",
        "\n",
        "callbacks_rnn = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
        "    tf.keras.callbacks.ModelCheckpoint('best_rnn_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "tuner_rnn.search(X_train_rnn, y_train, epochs=100, validation_split=0.2, callbacks=callbacks_rnn)\n",
        "\n",
        "best_hps_rnn = tuner_rnn.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Los mejores hiperparámetros encontrados:\n",
        "Número de unidades: {best_hps_rnn.get('units')}\n",
        "Tasa de aprendizaje: {best_hps_rnn.get('learning_rate')}\n",
        "\"\"\")\n",
        "\n",
        "# Obtener el mejor modelo RNN\n",
        "best_rnn_model = tuner_rnn.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuuaC5amVQU"
      },
      "source": [
        "Selección de Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyGhE6ygmYrG",
        "outputId": "1e0e50c0-ba48-4424-f724-6675dfddcaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36/36 [==============================] - 5s 43ms/step - loss: 0.2595 - accuracy: 0.8860\n",
            "Loss: 0.2594653069972992, Accuracy: 0.8859649300575256\n",
            "36/36 [==============================] - 2s 10ms/step\n",
            "[[513  62]\n",
            " [ 68 497]]\n",
            "Reporte de clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       575\n",
            "           1       0.89      0.88      0.88       565\n",
            "\n",
            "    accuracy                           0.89      1140\n",
            "   macro avg       0.89      0.89      0.89      1140\n",
            "weighted avg       0.89      0.89      0.89      1140\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Evaluación del modelo con los mejores hiperparámetros\n",
        "loss_rnn, accuracy_rnn = best_rnn_model.evaluate(X_test_rnn, y_test)\n",
        "print(f'Loss: {loss_rnn}, Accuracy: {accuracy_rnn}')\n",
        "\n",
        "# Obtener las predicciones en forma de clases\n",
        "y_pred_rnn = (best_rnn_model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calcular la matriz de confusión, y generar el reporte de clasificación\n",
        "conf_matrix_rnn = confusion_matrix(y_test, y_pred_rnn)\n",
        "report_rnn = classification_report(y_test, y_pred_rnn)\n",
        "\n",
        "# Imprimir las métricas\n",
        "print(conf_matrix_rnn)\n",
        "print(\"Reporte de clasificación:\\n\", report_rnn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
