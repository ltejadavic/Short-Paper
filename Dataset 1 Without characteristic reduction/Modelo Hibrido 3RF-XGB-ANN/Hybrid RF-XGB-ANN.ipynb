{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJyg8xgbBD2"
      },
      "source": [
        "Importación y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "tJA_xfxpbAlp"
      },
      "outputs": [],
      "source": [
        "# Importaciones correctas\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import optuna\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = pd.read_csv('telecom_customer_churn.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3B405XRbMm_"
      },
      "source": [
        "Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuTS-4Da1iq",
        "outputId": "64269792-651b-47fc-a2aa-3a22c056507f"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocesamiento\n",
        "# a. Eliminar entradas con el estado \"Joined\"\n",
        "df = df[df['Customer Status'] != 'Joined']\n",
        "\n",
        "# b. Crear la columna 'Churn' y asignar 1 si 'Customer Status' es 'Churned', de lo contrario 0\n",
        "df['Churn'] = df['Customer Status'].apply(lambda x: 1 if x == 'Churned' else 0)\n",
        "\n",
        "# c. Eliminar columnas con más del 50% de datos faltantes\n",
        "threshold = int(0.5 * len(df))\n",
        "df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "# d. Imputar valores atípicos usando la mediana (en lugar de la media)\n",
        "for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df[col] = df[col].apply(lambda x: df[col].median() if (x < (Q1 - 1.5 * IQR)) or (x > (Q3 + 1.5 * IQR)) else x)\n",
        "\n",
        "# e. Convertir variables categóricas a numéricas y llenar valores faltantes\n",
        "\n",
        "# Separar variables categóricas y numéricas\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Remover 'Customer Status' y 'Churn' de las listas\n",
        "cat_cols.remove('Customer Status')\n",
        "num_cols.remove('Churn')\n",
        "\n",
        "# Crear un transformador de columnas con OneHotEncoder para categóricas y SimpleImputer para numéricas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='median'), num_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "    ])\n",
        "\n",
        "# Aplicar el preprocesamiento y obtener las columnas generadas por OneHotEncoder\n",
        "df_transformed = preprocessor.fit_transform(df)\n",
        "new_cat_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(input_features=cat_cols)\n",
        "new_cols = num_cols + new_cat_cols.tolist()\n",
        "\n",
        "# Crear DataFrame preprocesado\n",
        "df_preprocessed = pd.DataFrame(df_transformed.toarray(), columns=new_cols)\n",
        "df_preprocessed['Churn'] = df['Churn'].values\n",
        "\n",
        "# f. Normalización\n",
        "# Seleccionar solo las columnas que no son 'Churn' para la normalización\n",
        "cols_to_scale = df_preprocessed.columns.difference(['Churn'])\n",
        "scaler = StandardScaler()\n",
        "df_preprocessed[cols_to_scale] = scaler.fit_transform(df_preprocessed[cols_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selección de características"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Características seleccionadas: ['Age', 'Tenure in Months', 'Monthly Charge', 'City_San Diego', 'City_San Dimas', 'Offer_Offer B', 'Internet Service_No', 'Internet Type_Cable', 'Online Security_No', 'Premium Tech Support_No', 'Streaming Movies_Yes', 'Streaming Music_Yes', 'Contract_Month-to-Month', 'Contract_One Year', 'Contract_Two Year', 'Paperless Billing_No', 'Payment Method_Credit Card']\n"
          ]
        }
      ],
      "source": [
        "# 2. Selección de características\n",
        "xgb_for_feature_selection = XGBClassifier(\n",
        "    objective='binary:logistic', \n",
        "    random_state=42, \n",
        "    use_label_encoder=False, \n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_for_feature_selection.fit(df_preprocessed.drop('Churn', axis=1), df_preprocessed['Churn'])\n",
        "threshold = 0.01  \n",
        "selected_features = df_preprocessed.drop('Churn', axis=1).columns[(xgb_for_feature_selection.feature_importances_ > threshold)].tolist()\n",
        "print(\"Características seleccionadas:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed-WLhQ4bPiM"
      },
      "source": [
        "Balanceo con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "i8PrZ1K8bP7s"
      },
      "outputs": [],
      "source": [
        "# 3. Balanceo con SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(df_preprocessed[selected_features], df['Churn'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiFgAaybheu"
      },
      "source": [
        "División de Conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. División de Conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definición de la función para crear el modelo ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Definición de la función para crear el modelo ANN\n",
        "def create_ann_model(learning_rate=0.001):  # Added learning_rate argument with a default value\n",
        "    ann_model = Sequential()\n",
        "    ann_model.add(Dense(48, activation='relu', input_dim=len(selected_features)))\n",
        "    ann_model.add(Dense(1, activation='sigmoid'))  # salida binaria\n",
        "    ann_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])  # Used learning_rate argument\n",
        "    return ann_model\n",
        "\n",
        "ann_model = KerasClassifier(build_fn=create_ann_model, epochs=100, batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGkhCSKbZAy"
      },
      "source": [
        "Inicializar modelos con los hiperparámetros óptimos encontrados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "pHoztCgybaO5"
      },
      "outputs": [],
      "source": [
        "# 5. Inicializar modelos con los hiperparámetros óptimos encontrados\n",
        "def objective(trial):\n",
        "    # Hiperparámetros sugeridos\n",
        "    xgb_params = {\n",
        "        'subsample': trial.suggest_float('xgb__subsample', 0.1, 1),\n",
        "        'scale_pos_weight': trial.suggest_float('xgb__scale_pos_weight', 1, 10),\n",
        "        'reg_lambda': trial.suggest_float('xgb__reg_lambda', 0.1, 10),\n",
        "        'n_estimators': trial.suggest_int('xgb__n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('xgb__max_depth', 1, 10),\n",
        "        'learning_rate': trial.suggest_float('xgb__learning_rate', 0.01, 1, log=True),\n",
        "        'gamma': trial.suggest_float('xgb__gamma', 0, 1),\n",
        "        'colsample_bytree': trial.suggest_float('xgb__colsample_bytree', 0.1, 1),\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf__n_estimators', 100, 1000),\n",
        "        'min_samples_split': trial.suggest_int('rf__min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('rf__min_samples_leaf', 1, 20),\n",
        "        'max_depth': trial.suggest_int('rf__max_depth', 1, 10),\n",
        "        'bootstrap': trial.suggest_categorical('rf__bootstrap', [True, False]),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    ann_params = {\n",
        "        'epochs': trial.suggest_int('ann__epochs', 10, 200),\n",
        "        'batch_size': trial.suggest_int('ann__batch_size', 16, 128),\n",
        "        'learning_rate': trial.suggest_float('ann__learning_rate', 1e-5, 1e-1, log=True)\n",
        "    }\n",
        "    xgb_model = XGBClassifier(**xgb_params)\n",
        "    rf_model = RandomForestClassifier(**rf_params)\n",
        "    ann_model = KerasClassifier(build_fn=lambda learning_rate=ann_params['learning_rate']: create_ann_model(learning_rate), **ann_params)\n",
        "\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[('xgb', xgb_model), ('ann', ann_model), ('rf', rf_model)],\n",
        "        voting='soft'\n",
        "    )\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred = voting_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crear un Voting Classifier con soft voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:20:49,752] A new study created in memory with name: no-name-ad0ec194-c5b5-403b-b5d5-f767b97d828f\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "236/236 [==============================] - 4s 6ms/step - loss: 0.4439 - accuracy: 0.7983\n",
            "Epoch 2/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8071\n",
            "Epoch 3/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4203 - accuracy: 0.8104\n",
            "Epoch 4/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8106\n",
            "Epoch 5/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.8130\n",
            "Epoch 6/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4218 - accuracy: 0.8096\n",
            "Epoch 7/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.8101\n",
            "Epoch 8/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.8102\n",
            "Epoch 9/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.8109\n",
            "Epoch 10/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8099\n",
            "Epoch 11/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4221 - accuracy: 0.8091\n",
            "Epoch 12/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8096\n",
            "Epoch 13/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.8087\n",
            "Epoch 14/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.8099\n",
            "Epoch 15/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4202 - accuracy: 0.8120\n",
            "Epoch 16/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8099\n",
            "Epoch 17/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4221 - accuracy: 0.8106\n",
            "Epoch 18/100\n",
            "236/236 [==============================] - 2s 6ms/step - loss: 0.4235 - accuracy: 0.8084\n",
            "Epoch 19/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8089\n",
            "Epoch 20/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8087\n",
            "Epoch 21/100\n",
            "236/236 [==============================] - 2s 6ms/step - loss: 0.4208 - accuracy: 0.8081\n",
            "Epoch 22/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4218 - accuracy: 0.8110\n",
            "Epoch 23/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8076\n",
            "Epoch 24/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8104\n",
            "Epoch 25/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4235 - accuracy: 0.8069\n",
            "Epoch 26/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8091\n",
            "Epoch 27/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4232 - accuracy: 0.8101\n",
            "Epoch 28/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4236 - accuracy: 0.8089\n",
            "Epoch 29/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4211 - accuracy: 0.8105\n",
            "Epoch 30/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4218 - accuracy: 0.8102\n",
            "Epoch 31/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4220 - accuracy: 0.8089\n",
            "Epoch 32/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4224 - accuracy: 0.8079\n",
            "Epoch 33/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.8064\n",
            "Epoch 34/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4229 - accuracy: 0.8095\n",
            "Epoch 35/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4236 - accuracy: 0.8068\n",
            "Epoch 36/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4239 - accuracy: 0.8085\n",
            "Epoch 37/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.8079\n",
            "Epoch 38/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4227 - accuracy: 0.8109\n",
            "Epoch 39/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4246 - accuracy: 0.8076\n",
            "Epoch 40/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4256 - accuracy: 0.8063\n",
            "Epoch 41/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.8081\n",
            "Epoch 42/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.8047\n",
            "Epoch 43/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4234 - accuracy: 0.8075\n",
            "Epoch 44/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4247 - accuracy: 0.8093\n",
            "Epoch 45/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4219 - accuracy: 0.8100\n",
            "Epoch 46/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8102\n",
            "Epoch 47/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.8080\n",
            "Epoch 48/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.8079\n",
            "Epoch 49/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4252 - accuracy: 0.8083\n",
            "Epoch 50/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8088\n",
            "Epoch 51/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4313 - accuracy: 0.8076\n",
            "Epoch 52/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4252 - accuracy: 0.8051\n",
            "Epoch 53/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.8073\n",
            "Epoch 54/100\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 0.4247 - accuracy: 0.8118\n",
            "Epoch 55/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.8068\n",
            "Epoch 56/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.8075\n",
            "Epoch 57/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4232 - accuracy: 0.8084\n",
            "Epoch 58/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4252 - accuracy: 0.8055\n",
            "Epoch 59/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8069\n",
            "Epoch 60/100\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 0.4230 - accuracy: 0.8091\n",
            "Epoch 61/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8085\n",
            "Epoch 62/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8075\n",
            "Epoch 63/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4266 - accuracy: 0.8075\n",
            "Epoch 64/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8051\n",
            "Epoch 65/100\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.8047\n",
            "Epoch 66/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.8084\n",
            "Epoch 67/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.8051\n",
            "Epoch 68/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4301 - accuracy: 0.8047\n",
            "Epoch 69/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4253 - accuracy: 0.8075\n",
            "Epoch 70/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4292 - accuracy: 0.8046\n",
            "Epoch 71/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4258 - accuracy: 0.8063\n",
            "Epoch 72/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8051\n",
            "Epoch 73/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4262 - accuracy: 0.8083\n",
            "Epoch 74/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8044\n",
            "Epoch 75/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8031\n",
            "Epoch 76/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8027\n",
            "Epoch 77/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8085\n",
            "Epoch 78/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4272 - accuracy: 0.8085\n",
            "Epoch 79/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4288 - accuracy: 0.8056\n",
            "Epoch 80/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4243 - accuracy: 0.8046\n",
            "Epoch 81/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8093\n",
            "Epoch 82/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8109\n",
            "Epoch 83/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4292 - accuracy: 0.8075\n",
            "Epoch 84/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4281 - accuracy: 0.8043\n",
            "Epoch 85/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4267 - accuracy: 0.8063\n",
            "Epoch 86/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8065\n",
            "Epoch 87/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4283 - accuracy: 0.8061\n",
            "Epoch 88/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4289 - accuracy: 0.8063\n",
            "Epoch 89/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4291 - accuracy: 0.8063\n",
            "Epoch 90/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4283 - accuracy: 0.8039\n",
            "Epoch 91/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4273 - accuracy: 0.8075\n",
            "Epoch 92/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4354 - accuracy: 0.8063\n",
            "Epoch 93/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4291 - accuracy: 0.8030\n",
            "Epoch 94/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4302 - accuracy: 0.8050\n",
            "Epoch 95/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4354 - accuracy: 0.8051\n",
            "Epoch 96/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8065\n",
            "Epoch 97/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4277 - accuracy: 0.8067\n",
            "Epoch 98/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.8038\n",
            "Epoch 99/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8085\n",
            "Epoch 100/100\n",
            "236/236 [==============================] - 1s 6ms/step - loss: 0.4275 - accuracy: 0.8104\n",
            "59/59 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:23:11,467] Trial 0 finished with value: 0.8659957627118644 and parameters: {'xgb__subsample': 1.0, 'xgb__scale_pos_weight': 1.0, 'xgb__reg_lambda': 1.0, 'xgb__n_estimators': 1000, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.0, 'xgb__colsample_bytree': 0.9, 'rf__n_estimators': 300, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 1, 'rf__max_depth': 8, 'rf__bootstrap': False, 'ann__epochs': 100, 'ann__batch_size': 32, 'ann__learning_rate': 0.001}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "210/210 [==============================] - 6s 15ms/step - loss: 0.5942 - accuracy: 0.6800\n",
            "Epoch 2/44\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.4727 - accuracy: 0.7734\n",
            "Epoch 3/44\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.4464 - accuracy: 0.7893\n",
            "Epoch 4/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4357 - accuracy: 0.7954\n",
            "Epoch 5/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4297 - accuracy: 0.8006\n",
            "Epoch 6/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8039\n",
            "Epoch 7/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4237 - accuracy: 0.8063\n",
            "Epoch 8/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4221 - accuracy: 0.8068\n",
            "Epoch 9/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8071\n",
            "Epoch 10/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4202 - accuracy: 0.8109\n",
            "Epoch 11/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4195 - accuracy: 0.8097\n",
            "Epoch 12/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8109\n",
            "Epoch 13/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8118\n",
            "Epoch 14/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8116\n",
            "Epoch 15/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8120\n",
            "Epoch 16/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8117\n",
            "Epoch 17/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8124\n",
            "Epoch 18/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8116\n",
            "Epoch 19/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8110\n",
            "Epoch 20/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8113\n",
            "Epoch 21/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8114\n",
            "Epoch 22/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8124\n",
            "Epoch 23/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8133\n",
            "Epoch 24/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8106\n",
            "Epoch 25/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8122\n",
            "Epoch 26/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8118\n",
            "Epoch 27/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8125\n",
            "Epoch 28/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8120\n",
            "Epoch 29/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4179 - accuracy: 0.8116\n",
            "Epoch 30/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8128\n",
            "Epoch 31/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8121\n",
            "Epoch 32/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8130\n",
            "Epoch 33/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8129\n",
            "Epoch 34/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8121\n",
            "Epoch 35/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8117\n",
            "Epoch 36/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8126\n",
            "Epoch 37/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8122\n",
            "Epoch 38/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8117\n",
            "Epoch 39/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8125\n",
            "Epoch 40/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 41/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 42/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4178 - accuracy: 0.8126\n",
            "Epoch 43/44\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.4179 - accuracy: 0.8132\n",
            "Epoch 44/44\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8130\n",
            "53/53 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:24:24,688] Trial 1 finished with value: 0.8199152542372882 and parameters: {'xgb__subsample': 0.4370861069626263, 'xgb__scale_pos_weight': 9.556428757689245, 'xgb__reg_lambda': 7.34674002393291, 'xgb__n_estimators': 639, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.020511104188433976, 'xgb__gamma': 0.05808361216819946, 'xgb__colsample_bytree': 0.8795585311974417, 'rf__n_estimators': 641, 'rf__min_samples_split': 15, 'rf__min_samples_leaf': 1, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 44, 'ann__batch_size': 36, 'ann__learning_rate': 0.00016480446427978953}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 7s 12ms/step - loss: 0.6122 - accuracy: 0.7575\n",
            "Epoch 2/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.7339 - accuracy: 0.7479\n",
            "Epoch 3/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.7064 - accuracy: 0.7499\n",
            "Epoch 4/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.9610 - accuracy: 0.7368\n",
            "Epoch 5/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.9456 - accuracy: 0.7446\n",
            "Epoch 6/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.0291 - accuracy: 0.7451\n",
            "Epoch 7/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.4360 - accuracy: 0.7331\n",
            "Epoch 8/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.1223 - accuracy: 0.7352\n",
            "Epoch 9/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.1892 - accuracy: 0.7398\n",
            "Epoch 10/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.5461 - accuracy: 0.7324\n",
            "Epoch 11/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.4543 - accuracy: 0.7381\n",
            "Epoch 12/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.9439 - accuracy: 0.7301\n",
            "Epoch 13/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.6081 - accuracy: 0.7358\n",
            "Epoch 14/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.3553 - accuracy: 0.7426\n",
            "Epoch 15/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.6694 - accuracy: 0.7319\n",
            "Epoch 16/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.7916 - accuracy: 0.7341\n",
            "Epoch 17/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.8402 - accuracy: 0.7364\n",
            "Epoch 18/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.8787 - accuracy: 0.7289\n",
            "Epoch 19/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.4505 - accuracy: 0.7428\n",
            "Epoch 20/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.8898 - accuracy: 0.7289\n",
            "Epoch 21/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.1043 - accuracy: 0.7289\n",
            "Epoch 22/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.1007 - accuracy: 0.7321\n",
            "Epoch 23/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.2004 - accuracy: 0.7311\n",
            "Epoch 24/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.9476 - accuracy: 0.7307\n",
            "Epoch 25/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.3568 - accuracy: 0.7320\n",
            "Epoch 26/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.2932 - accuracy: 0.7334\n",
            "Epoch 27/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 3.0276 - accuracy: 0.7258\n",
            "Epoch 28/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.0816 - accuracy: 0.7308\n",
            "Epoch 29/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.2697 - accuracy: 0.7333\n",
            "Epoch 30/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.7423 - accuracy: 0.7337\n",
            "Epoch 31/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 3.0996 - accuracy: 0.7288\n",
            "Epoch 32/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.4351 - accuracy: 0.7332\n",
            "Epoch 33/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.6034 - accuracy: 0.7340\n",
            "Epoch 34/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.0759 - accuracy: 0.7380\n",
            "Epoch 35/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.6235 - accuracy: 0.7301\n",
            "Epoch 36/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.9953 - accuracy: 0.7296\n",
            "Epoch 37/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.6215 - accuracy: 0.7366\n",
            "Epoch 38/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.9774 - accuracy: 0.7275\n",
            "Epoch 39/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.5264 - accuracy: 0.7296\n",
            "Epoch 40/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 3.2646 - accuracy: 0.7246\n",
            "Epoch 41/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.9896 - accuracy: 0.7365\n",
            "Epoch 42/42\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 3.0785 - accuracy: 0.7299\n",
            "83/83 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:26:09,955] Trial 2 finished with value: 0.7913135593220338 and parameters: {'xgb__subsample': 0.5722807884690141, 'xgb__scale_pos_weight': 4.887505167779041, 'xgb__reg_lambda': 2.983168487960615, 'xgb__n_estimators': 651, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.03839629299804171, 'xgb__gamma': 0.3663618432936917, 'xgb__colsample_bytree': 0.5104629857953323, 'rf__n_estimators': 807, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 11, 'rf__max_depth': 6, 'rf__bootstrap': False, 'ann__epochs': 42, 'ann__batch_size': 23, 'ann__learning_rate': 0.06245139574743072}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "210/210 [==============================] - 5s 15ms/step - loss: 0.5891 - accuracy: 0.7648\n",
            "Epoch 2/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.6596 - accuracy: 0.7597\n",
            "Epoch 3/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.7365 - accuracy: 0.7450\n",
            "Epoch 4/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.9054 - accuracy: 0.7440\n",
            "Epoch 5/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.9031 - accuracy: 0.7431\n",
            "Epoch 6/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.9237 - accuracy: 0.7431\n",
            "Epoch 7/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.9352 - accuracy: 0.7468\n",
            "Epoch 8/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.0021 - accuracy: 0.7413\n",
            "Epoch 9/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.0072 - accuracy: 0.7458\n",
            "Epoch 10/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.2744 - accuracy: 0.7311\n",
            "Epoch 11/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.0924 - accuracy: 0.7365\n",
            "Epoch 12/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.0153 - accuracy: 0.7430\n",
            "Epoch 13/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.1938 - accuracy: 0.7341\n",
            "Epoch 14/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.0829 - accuracy: 0.7399\n",
            "Epoch 15/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 1.2338 - accuracy: 0.7350\n",
            "Epoch 16/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.2955 - accuracy: 0.7340\n",
            "Epoch 17/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.1235 - accuracy: 0.7410\n",
            "Epoch 18/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8460 - accuracy: 0.7317\n",
            "Epoch 19/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5923 - accuracy: 0.7365\n",
            "Epoch 20/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5138 - accuracy: 0.7329\n",
            "Epoch 21/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.3237 - accuracy: 0.7399\n",
            "Epoch 22/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0376 - accuracy: 0.7268\n",
            "Epoch 23/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9800 - accuracy: 0.7278\n",
            "Epoch 24/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5118 - accuracy: 0.7452\n",
            "Epoch 25/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.6563 - accuracy: 0.7361\n",
            "Epoch 26/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8393 - accuracy: 0.7284\n",
            "Epoch 27/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.6762 - accuracy: 0.7348\n",
            "Epoch 28/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.3752 - accuracy: 0.7386\n",
            "Epoch 29/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5520 - accuracy: 0.7353\n",
            "Epoch 30/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5815 - accuracy: 0.7389\n",
            "Epoch 31/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5930 - accuracy: 0.7436\n",
            "Epoch 32/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 1.6877 - accuracy: 0.7393\n",
            "Epoch 33/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7115 - accuracy: 0.7364\n",
            "Epoch 34/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1422 - accuracy: 0.7296\n",
            "Epoch 35/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7709 - accuracy: 0.7325\n",
            "Epoch 36/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.5690 - accuracy: 0.7238\n",
            "Epoch 37/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.3285 - accuracy: 0.7348\n",
            "Epoch 38/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.3759 - accuracy: 0.7280\n",
            "Epoch 39/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.2450 - accuracy: 0.7341\n",
            "Epoch 40/114\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 1.8307 - accuracy: 0.7271\n",
            "Epoch 41/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9844 - accuracy: 0.7395\n",
            "Epoch 42/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9943 - accuracy: 0.7329\n",
            "Epoch 43/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0427 - accuracy: 0.7342\n",
            "Epoch 44/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.6247 - accuracy: 0.7313\n",
            "Epoch 45/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 1.7390 - accuracy: 0.7346\n",
            "Epoch 46/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.6763 - accuracy: 0.7328\n",
            "Epoch 47/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7976 - accuracy: 0.7334\n",
            "Epoch 48/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1900 - accuracy: 0.7304\n",
            "Epoch 49/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9665 - accuracy: 0.7308\n",
            "Epoch 50/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1106 - accuracy: 0.7423\n",
            "Epoch 51/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8976 - accuracy: 0.7342\n",
            "Epoch 52/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5635 - accuracy: 0.7413\n",
            "Epoch 53/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.5541 - accuracy: 0.7399\n",
            "Epoch 54/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.5060 - accuracy: 0.7266\n",
            "Epoch 55/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0312 - accuracy: 0.7354\n",
            "Epoch 56/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1685 - accuracy: 0.7260\n",
            "Epoch 57/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1517 - accuracy: 0.7401\n",
            "Epoch 58/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8215 - accuracy: 0.7358\n",
            "Epoch 59/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0139 - accuracy: 0.7287\n",
            "Epoch 60/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7015 - accuracy: 0.7382\n",
            "Epoch 61/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.2924 - accuracy: 0.7411\n",
            "Epoch 62/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8009 - accuracy: 0.7403\n",
            "Epoch 63/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.4455 - accuracy: 0.7325\n",
            "Epoch 64/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7210 - accuracy: 0.7360\n",
            "Epoch 65/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.2405 - accuracy: 0.7291\n",
            "Epoch 66/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8426 - accuracy: 0.7428\n",
            "Epoch 67/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9708 - accuracy: 0.7399\n",
            "Epoch 68/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1011 - accuracy: 0.7254\n",
            "Epoch 69/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9367 - accuracy: 0.7350\n",
            "Epoch 70/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9433 - accuracy: 0.7385\n",
            "Epoch 71/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8737 - accuracy: 0.7390\n",
            "Epoch 72/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0919 - accuracy: 0.7300\n",
            "Epoch 73/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8509 - accuracy: 0.7352\n",
            "Epoch 74/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0743 - accuracy: 0.7398\n",
            "Epoch 75/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0506 - accuracy: 0.7323\n",
            "Epoch 76/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7242 - accuracy: 0.7338\n",
            "Epoch 77/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.2155 - accuracy: 0.7372\n",
            "Epoch 78/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1619 - accuracy: 0.7327\n",
            "Epoch 79/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.4211 - accuracy: 0.7336\n",
            "Epoch 80/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9972 - accuracy: 0.7390\n",
            "Epoch 81/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.3073 - accuracy: 0.7316\n",
            "Epoch 82/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0373 - accuracy: 0.7308\n",
            "Epoch 83/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.3871 - accuracy: 0.7315\n",
            "Epoch 84/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.4363 - accuracy: 0.7382\n",
            "Epoch 85/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0390 - accuracy: 0.7296\n",
            "Epoch 86/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8635 - accuracy: 0.7365\n",
            "Epoch 87/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.2438 - accuracy: 0.7397\n",
            "Epoch 88/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.7218 - accuracy: 0.7407\n",
            "Epoch 89/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.2721 - accuracy: 0.7315\n",
            "Epoch 90/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.0551 - accuracy: 0.7356\n",
            "Epoch 91/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7829 - accuracy: 0.7352\n",
            "Epoch 92/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8950 - accuracy: 0.7462\n",
            "Epoch 93/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.3089 - accuracy: 0.7271\n",
            "Epoch 94/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7746 - accuracy: 0.7417\n",
            "Epoch 95/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.4275 - accuracy: 0.7320\n",
            "Epoch 96/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.1510 - accuracy: 0.7428\n",
            "Epoch 97/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.8551 - accuracy: 0.7319\n",
            "Epoch 98/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 3.0722 - accuracy: 0.7333\n",
            "Epoch 99/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.2007 - accuracy: 0.7345\n",
            "Epoch 100/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.3577 - accuracy: 0.7254\n",
            "Epoch 101/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.6387 - accuracy: 0.7287\n",
            "Epoch 102/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.8808 - accuracy: 0.7305\n",
            "Epoch 103/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.7584 - accuracy: 0.7382\n",
            "Epoch 104/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 2.6434 - accuracy: 0.7324\n",
            "Epoch 105/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.7745 - accuracy: 0.7425\n",
            "Epoch 106/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 1.9928 - accuracy: 0.7334\n",
            "Epoch 107/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 1.8049 - accuracy: 0.7304\n",
            "Epoch 108/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 3.1815 - accuracy: 0.7341\n",
            "Epoch 109/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.3825 - accuracy: 0.7380\n",
            "Epoch 110/114\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 2.2113 - accuracy: 0.7380\n",
            "Epoch 111/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.5821 - accuracy: 0.7369\n",
            "Epoch 112/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.3024 - accuracy: 0.7383\n",
            "Epoch 113/114\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 2.1782 - accuracy: 0.7307\n",
            "Epoch 114/114\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 1.9478 - accuracy: 0.7327\n",
            "53/53 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:29:02,929] Trial 3 finished with value: 0.8532838983050848 and parameters: {'xgb__subsample': 0.9690688297671034, 'xgb__scale_pos_weight': 8.275576133048151, 'xgb__reg_lambda': 3.11567631481637, 'xgb__n_estimators': 188, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.07591104805282695, 'xgb__gamma': 0.12203823484477883, 'xgb__colsample_bytree': 0.5456592191001431, 'rf__n_estimators': 130, 'rf__min_samples_split': 19, 'rf__min_samples_leaf': 6, 'rf__max_depth': 7, 'rf__bootstrap': False, 'ann__epochs': 114, 'ann__batch_size': 36, 'ann__learning_rate': 0.07556810141274425}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "244/244 [==============================] - 6s 14ms/step - loss: 0.4461 - accuracy: 0.8012\n",
            "Epoch 2/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4574 - accuracy: 0.7920\n",
            "Epoch 3/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4599 - accuracy: 0.7920\n",
            "Epoch 4/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4625 - accuracy: 0.7912\n",
            "Epoch 5/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4893 - accuracy: 0.7875\n",
            "Epoch 6/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4821 - accuracy: 0.7840\n",
            "Epoch 7/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5014 - accuracy: 0.7858\n",
            "Epoch 8/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.4765 - accuracy: 0.7852\n",
            "Epoch 9/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4904 - accuracy: 0.7854\n",
            "Epoch 10/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4949 - accuracy: 0.7888\n",
            "Epoch 11/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5277 - accuracy: 0.7786\n",
            "Epoch 12/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5229 - accuracy: 0.7761\n",
            "Epoch 13/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.4906 - accuracy: 0.7860\n",
            "Epoch 14/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5498 - accuracy: 0.7728\n",
            "Epoch 15/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5430 - accuracy: 0.7778\n",
            "Epoch 16/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5491 - accuracy: 0.7695\n",
            "Epoch 17/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5928 - accuracy: 0.7642\n",
            "Epoch 18/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5589 - accuracy: 0.7741\n",
            "Epoch 19/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5171 - accuracy: 0.7812\n",
            "Epoch 20/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5680 - accuracy: 0.7720\n",
            "Epoch 21/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5401 - accuracy: 0.7783\n",
            "Epoch 22/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5481 - accuracy: 0.7738\n",
            "Epoch 23/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5452 - accuracy: 0.7752\n",
            "Epoch 24/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5811 - accuracy: 0.7660\n",
            "Epoch 25/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6122 - accuracy: 0.7590\n",
            "Epoch 26/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5784 - accuracy: 0.7697\n",
            "Epoch 27/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5649 - accuracy: 0.7742\n",
            "Epoch 28/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5948 - accuracy: 0.7663\n",
            "Epoch 29/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6205 - accuracy: 0.7662\n",
            "Epoch 30/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5849 - accuracy: 0.7720\n",
            "Epoch 31/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.5680 - accuracy: 0.7700\n",
            "Epoch 32/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6476 - accuracy: 0.7652\n",
            "Epoch 33/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6188 - accuracy: 0.7632\n",
            "Epoch 34/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6390 - accuracy: 0.7591\n",
            "Epoch 35/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6388 - accuracy: 0.7673\n",
            "Epoch 36/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6348 - accuracy: 0.7659\n",
            "Epoch 37/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6461 - accuracy: 0.7570\n",
            "Epoch 38/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6091 - accuracy: 0.7646\n",
            "Epoch 39/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6432 - accuracy: 0.7639\n",
            "Epoch 40/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6772 - accuracy: 0.7568\n",
            "Epoch 41/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6487 - accuracy: 0.7614\n",
            "Epoch 42/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6661 - accuracy: 0.7598\n",
            "Epoch 43/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7045 - accuracy: 0.7558\n",
            "Epoch 44/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6772 - accuracy: 0.7587\n",
            "Epoch 45/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6705 - accuracy: 0.7610\n",
            "Epoch 46/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6966 - accuracy: 0.7581\n",
            "Epoch 47/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6399 - accuracy: 0.7622\n",
            "Epoch 48/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6217 - accuracy: 0.7598\n",
            "Epoch 49/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7807 - accuracy: 0.7565\n",
            "Epoch 50/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7960 - accuracy: 0.7569\n",
            "Epoch 51/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7433 - accuracy: 0.7507\n",
            "Epoch 52/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6669 - accuracy: 0.7532\n",
            "Epoch 53/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7151 - accuracy: 0.7546\n",
            "Epoch 54/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.6769 - accuracy: 0.7639\n",
            "Epoch 55/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7149 - accuracy: 0.7572\n",
            "Epoch 56/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7615 - accuracy: 0.7475\n",
            "Epoch 57/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7235 - accuracy: 0.7607\n",
            "Epoch 58/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7216 - accuracy: 0.7523\n",
            "Epoch 59/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7832 - accuracy: 0.7524\n",
            "Epoch 60/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7800 - accuracy: 0.7565\n",
            "Epoch 61/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7442 - accuracy: 0.7492\n",
            "Epoch 62/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8897 - accuracy: 0.7436\n",
            "Epoch 63/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9175 - accuracy: 0.7430\n",
            "Epoch 64/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7804 - accuracy: 0.7519\n",
            "Epoch 65/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8719 - accuracy: 0.7471\n",
            "Epoch 66/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7346 - accuracy: 0.7589\n",
            "Epoch 67/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7784 - accuracy: 0.7497\n",
            "Epoch 68/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7166 - accuracy: 0.7533\n",
            "Epoch 69/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8145 - accuracy: 0.7568\n",
            "Epoch 70/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8422 - accuracy: 0.7483\n",
            "Epoch 71/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8209 - accuracy: 0.7489\n",
            "Epoch 72/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8142 - accuracy: 0.7503\n",
            "Epoch 73/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9034 - accuracy: 0.7505\n",
            "Epoch 74/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8901 - accuracy: 0.7480\n",
            "Epoch 75/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8535 - accuracy: 0.7454\n",
            "Epoch 76/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8585 - accuracy: 0.7533\n",
            "Epoch 77/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7850 - accuracy: 0.7523\n",
            "Epoch 78/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8892 - accuracy: 0.7497\n",
            "Epoch 79/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.8718 - accuracy: 0.7456\n",
            "Epoch 80/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.7565 - accuracy: 0.7495\n",
            "Epoch 81/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9201 - accuracy: 0.7431\n",
            "Epoch 82/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7553 - accuracy: 0.7558\n",
            "Epoch 83/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.7940 - accuracy: 0.7541\n",
            "Epoch 84/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0249 - accuracy: 0.7438\n",
            "Epoch 85/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0617 - accuracy: 0.7448\n",
            "Epoch 86/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.8612 - accuracy: 0.7562\n",
            "Epoch 87/113\n",
            "244/244 [==============================] - 2s 8ms/step - loss: 0.9428 - accuracy: 0.7491\n",
            "Epoch 88/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8943 - accuracy: 0.7443\n",
            "Epoch 89/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9099 - accuracy: 0.7480\n",
            "Epoch 90/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0203 - accuracy: 0.7447\n",
            "Epoch 91/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8128 - accuracy: 0.7540\n",
            "Epoch 92/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0442 - accuracy: 0.7462\n",
            "Epoch 93/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7880 - accuracy: 0.7519\n",
            "Epoch 94/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7828 - accuracy: 0.7533\n",
            "Epoch 95/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9490 - accuracy: 0.7436\n",
            "Epoch 96/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9015 - accuracy: 0.7480\n",
            "Epoch 97/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9187 - accuracy: 0.7431\n",
            "Epoch 98/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9529 - accuracy: 0.7556\n",
            "Epoch 99/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8829 - accuracy: 0.7513\n",
            "Epoch 100/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0008 - accuracy: 0.7476\n",
            "Epoch 101/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.7725 - accuracy: 0.7583\n",
            "Epoch 102/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9229 - accuracy: 0.7467\n",
            "Epoch 103/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0589 - accuracy: 0.7385\n",
            "Epoch 104/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9836 - accuracy: 0.7517\n",
            "Epoch 105/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8540 - accuracy: 0.7462\n",
            "Epoch 106/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.1021 - accuracy: 0.7426\n",
            "Epoch 107/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9236 - accuracy: 0.7574\n",
            "Epoch 108/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.0588 - accuracy: 0.7406\n",
            "Epoch 109/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 1.1426 - accuracy: 0.7439\n",
            "Epoch 110/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.9326 - accuracy: 0.7569\n",
            "Epoch 111/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8357 - accuracy: 0.7454\n",
            "Epoch 112/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8587 - accuracy: 0.7548\n",
            "Epoch 113/113\n",
            "244/244 [==============================] - 2s 7ms/step - loss: 0.8257 - accuracy: 0.7552\n",
            "61/61 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:32:20,993] Trial 4 finished with value: 0.7902542372881356 and parameters: {'xgb__subsample': 0.7976195410250031, 'xgb__scale_pos_weight': 9.455490474077703, 'xgb__reg_lambda': 8.958790769233723, 'xgb__n_estimators': 638, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.015030900645056829, 'xgb__gamma': 0.1959828624191452, 'xgb__colsample_bytree': 0.14070456001948428, 'rf__n_estimators': 393, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 6, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 113, 'ann__batch_size': 31, 'ann__learning_rate': 0.016172900811143146}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 6s 11ms/step - loss: 0.5155 - accuracy: 0.7591\n",
            "Epoch 2/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4504 - accuracy: 0.7949\n",
            "Epoch 3/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4321 - accuracy: 0.8030\n",
            "Epoch 4/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4247 - accuracy: 0.8061\n",
            "Epoch 5/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4216 - accuracy: 0.8087\n",
            "Epoch 6/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4200 - accuracy: 0.8100\n",
            "Epoch 7/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4193 - accuracy: 0.8100\n",
            "Epoch 8/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4187 - accuracy: 0.8133\n",
            "Epoch 9/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4186 - accuracy: 0.8114\n",
            "Epoch 10/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8114\n",
            "Epoch 11/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8120\n",
            "Epoch 12/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 13/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8125\n",
            "Epoch 14/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8121\n",
            "Epoch 15/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8118\n",
            "Epoch 16/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 17/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8141\n",
            "Epoch 18/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8137\n",
            "Epoch 19/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8108\n",
            "Epoch 20/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8120\n",
            "Epoch 21/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8109\n",
            "Epoch 22/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8125\n",
            "Epoch 23/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8121\n",
            "Epoch 24/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8116\n",
            "Epoch 25/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8132\n",
            "Epoch 26/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8112\n",
            "Epoch 27/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8122\n",
            "Epoch 28/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8124\n",
            "Epoch 29/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8122\n",
            "Epoch 30/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8130\n",
            "Epoch 31/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8116\n",
            "Epoch 32/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8125\n",
            "Epoch 33/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4179 - accuracy: 0.8118\n",
            "Epoch 34/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8122\n",
            "Epoch 35/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8124\n",
            "Epoch 36/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8120\n",
            "Epoch 37/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8110\n",
            "Epoch 38/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8136\n",
            "Epoch 39/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4178 - accuracy: 0.8122\n",
            "Epoch 40/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8130\n",
            "Epoch 41/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4178 - accuracy: 0.8118\n",
            "Epoch 42/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8120\n",
            "Epoch 43/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 44/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8126\n",
            "Epoch 45/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8117\n",
            "Epoch 46/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8112\n",
            "Epoch 47/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8120\n",
            "Epoch 48/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8117\n",
            "Epoch 49/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8109\n",
            "Epoch 50/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8125\n",
            "Epoch 51/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8128\n",
            "Epoch 52/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8124\n",
            "Epoch 53/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8125\n",
            "Epoch 54/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8118\n",
            "Epoch 55/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8120\n",
            "Epoch 56/73\n",
            "329/329 [==============================] - 5s 16ms/step - loss: 0.4183 - accuracy: 0.8106\n",
            "Epoch 57/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8124\n",
            "Epoch 58/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8124\n",
            "Epoch 59/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8118\n",
            "Epoch 60/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8130\n",
            "Epoch 61/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8118\n",
            "Epoch 62/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8128\n",
            "Epoch 63/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8120\n",
            "Epoch 64/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4180 - accuracy: 0.8110\n",
            "Epoch 65/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8117\n",
            "Epoch 66/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8120\n",
            "Epoch 67/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4181 - accuracy: 0.8117\n",
            "Epoch 68/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8118\n",
            "Epoch 69/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4182 - accuracy: 0.8100\n",
            "Epoch 70/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8113\n",
            "Epoch 71/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8126\n",
            "Epoch 72/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4184 - accuracy: 0.8105\n",
            "Epoch 73/73\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.4185 - accuracy: 0.8112\n",
            "83/83 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:35:13,108] Trial 5 finished with value: 0.7960805084745762 and parameters: {'xgb__subsample': 0.16709557931179375, 'xgb__scale_pos_weight': 9.881982429404655, 'xgb__reg_lambda': 7.7452232160369086, 'xgb__n_estimators': 279, 'xgb__max_depth': 1, 'xgb__learning_rate': 0.4274869455295215, 'xgb__gamma': 0.7068573438476171, 'xgb__colsample_bytree': 0.7561064512368886, 'rf__n_estimators': 794, 'rf__min_samples_split': 3, 'rf__min_samples_leaf': 8, 'rf__max_depth': 2, 'rf__bootstrap': True, 'ann__epochs': 73, 'ann__batch_size': 23, 'ann__learning_rate': 0.00017535949529764417}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "398/398 [==============================] - 7s 11ms/step - loss: 0.4342 - accuracy: 0.8052\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4273 - accuracy: 0.8065\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4320 - accuracy: 0.8055\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4326 - accuracy: 0.8024\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4329 - accuracy: 0.8008\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4368 - accuracy: 0.8019\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4353 - accuracy: 0.8042\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4397 - accuracy: 0.7999\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4413 - accuracy: 0.7959\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4422 - accuracy: 0.8006\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4358 - accuracy: 0.8046\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4435 - accuracy: 0.7974\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4418 - accuracy: 0.7982\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 3s 6ms/step - loss: 0.4489 - accuracy: 0.7997\n",
            "Epoch 15/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4494 - accuracy: 0.7995\n",
            "Epoch 16/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4462 - accuracy: 0.7991\n",
            "Epoch 17/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4516 - accuracy: 0.7949\n",
            "Epoch 18/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4546 - accuracy: 0.7958\n",
            "Epoch 19/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4540 - accuracy: 0.7967\n",
            "Epoch 20/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4487 - accuracy: 0.7944\n",
            "Epoch 21/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4578 - accuracy: 0.7950\n",
            "Epoch 22/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4664 - accuracy: 0.7916\n",
            "Epoch 23/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4680 - accuracy: 0.7917\n",
            "Epoch 24/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4505 - accuracy: 0.7998\n",
            "Epoch 25/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4597 - accuracy: 0.7946\n",
            "Epoch 26/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4548 - accuracy: 0.7965\n",
            "Epoch 27/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4637 - accuracy: 0.7889\n",
            "Epoch 28/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4650 - accuracy: 0.7925\n",
            "Epoch 29/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4687 - accuracy: 0.7885\n",
            "Epoch 30/30\n",
            "398/398 [==============================] - 3s 7ms/step - loss: 0.4827 - accuracy: 0.7867\n",
            "100/100 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:36:41,688] Trial 6 finished with value: 0.8199152542372882 and parameters: {'xgb__subsample': 0.3926649898240724, 'xgb__scale_pos_weight': 7.566455605042576, 'xgb__reg_lambda': 6.41181896641661, 'xgb__n_estimators': 899, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.017345566642360945, 'xgb__gamma': 0.713244787222995, 'xgb__colsample_bytree': 0.7847065437552077, 'rf__n_estimators': 605, 'rf__min_samples_split': 16, 'rf__min_samples_leaf': 10, 'rf__max_depth': 6, 'rf__bootstrap': True, 'ann__epochs': 30, 'ann__batch_size': 19, 'ann__learning_rate': 0.003512704726270845}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "205/205 [==============================] - 6s 15ms/step - loss: 0.4726 - accuracy: 0.7860\n",
            "Epoch 2/163\n",
            "205/205 [==============================] - 2s 7ms/step - loss: 0.5129 - accuracy: 0.7775\n",
            "Epoch 3/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.5412 - accuracy: 0.7778\n",
            "Epoch 4/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.7711\n",
            "Epoch 5/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.5292 - accuracy: 0.7724\n",
            "Epoch 6/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6796 - accuracy: 0.7626\n",
            "Epoch 7/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6149 - accuracy: 0.7662\n",
            "Epoch 8/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6209 - accuracy: 0.7666\n",
            "Epoch 9/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6656 - accuracy: 0.7556\n",
            "Epoch 10/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6365 - accuracy: 0.7577\n",
            "Epoch 11/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6761 - accuracy: 0.7574\n",
            "Epoch 12/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6418 - accuracy: 0.7648\n",
            "Epoch 13/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.7734 - accuracy: 0.7515\n",
            "Epoch 14/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.7075 - accuracy: 0.7585\n",
            "Epoch 15/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.7183 - accuracy: 0.7599\n",
            "Epoch 16/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8898 - accuracy: 0.7447\n",
            "Epoch 17/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8192 - accuracy: 0.7569\n",
            "Epoch 18/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8900 - accuracy: 0.7470\n",
            "Epoch 19/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8336 - accuracy: 0.7508\n",
            "Epoch 20/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.6912 - accuracy: 0.7607\n",
            "Epoch 21/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8446 - accuracy: 0.7479\n",
            "Epoch 22/163\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.8410 - accuracy: 0.7519\n",
            "Epoch 23/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.7093 - accuracy: 0.7574\n",
            "Epoch 24/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0511 - accuracy: 0.7456\n",
            "Epoch 25/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8400 - accuracy: 0.7513\n",
            "Epoch 26/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.9022 - accuracy: 0.7492\n",
            "Epoch 27/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8719 - accuracy: 0.7544\n",
            "Epoch 28/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8677 - accuracy: 0.7513\n",
            "Epoch 29/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0328 - accuracy: 0.7466\n",
            "Epoch 30/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8491 - accuracy: 0.7463\n",
            "Epoch 31/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8213 - accuracy: 0.7553\n",
            "Epoch 32/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0732 - accuracy: 0.7436\n",
            "Epoch 33/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0017 - accuracy: 0.7466\n",
            "Epoch 34/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8658 - accuracy: 0.7443\n",
            "Epoch 35/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.9039 - accuracy: 0.7479\n",
            "Epoch 36/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8948 - accuracy: 0.7564\n",
            "Epoch 37/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0961 - accuracy: 0.7440\n",
            "Epoch 38/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.8393 - accuracy: 0.7562\n",
            "Epoch 39/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.9617 - accuracy: 0.7512\n",
            "Epoch 40/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.1526 - accuracy: 0.7401\n",
            "Epoch 41/163\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 1.3024 - accuracy: 0.7376\n",
            "Epoch 42/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4031 - accuracy: 0.7458\n",
            "Epoch 43/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2860 - accuracy: 0.7350\n",
            "Epoch 44/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3082 - accuracy: 0.7345\n",
            "Epoch 45/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2936 - accuracy: 0.7443\n",
            "Epoch 46/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0949 - accuracy: 0.7391\n",
            "Epoch 47/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3286 - accuracy: 0.7364\n",
            "Epoch 48/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0336 - accuracy: 0.7401\n",
            "Epoch 49/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2432 - accuracy: 0.7467\n",
            "Epoch 50/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0076 - accuracy: 0.7472\n",
            "Epoch 51/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.1712 - accuracy: 0.7474\n",
            "Epoch 52/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2196 - accuracy: 0.7377\n",
            "Epoch 53/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3350 - accuracy: 0.7458\n",
            "Epoch 54/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6430 - accuracy: 0.7418\n",
            "Epoch 55/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.1335 - accuracy: 0.7411\n",
            "Epoch 56/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3412 - accuracy: 0.7472\n",
            "Epoch 57/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2426 - accuracy: 0.7436\n",
            "Epoch 58/163\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 1.2030 - accuracy: 0.7409\n",
            "Epoch 59/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4330 - accuracy: 0.7430\n",
            "Epoch 60/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.0334 - accuracy: 0.7443\n",
            "Epoch 61/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6381 - accuracy: 0.7272\n",
            "Epoch 62/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3595 - accuracy: 0.7466\n",
            "Epoch 63/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2537 - accuracy: 0.7472\n",
            "Epoch 64/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5867 - accuracy: 0.7450\n",
            "Epoch 65/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4377 - accuracy: 0.7394\n",
            "Epoch 66/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2887 - accuracy: 0.7419\n",
            "Epoch 67/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2328 - accuracy: 0.7413\n",
            "Epoch 68/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5824 - accuracy: 0.7447\n",
            "Epoch 69/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4716 - accuracy: 0.7507\n",
            "Epoch 70/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5138 - accuracy: 0.7365\n",
            "Epoch 71/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6394 - accuracy: 0.7300\n",
            "Epoch 72/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.1403 - accuracy: 0.7387\n",
            "Epoch 73/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5735 - accuracy: 0.7324\n",
            "Epoch 74/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3030 - accuracy: 0.7415\n",
            "Epoch 75/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4349 - accuracy: 0.7418\n",
            "Epoch 76/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3916 - accuracy: 0.7386\n",
            "Epoch 77/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9798 - accuracy: 0.7439\n",
            "Epoch 78/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2472 - accuracy: 0.7452\n",
            "Epoch 79/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5282 - accuracy: 0.7364\n",
            "Epoch 80/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4297 - accuracy: 0.7399\n",
            "Epoch 81/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.2770 - accuracy: 0.7470\n",
            "Epoch 82/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4179 - accuracy: 0.7504\n",
            "Epoch 83/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.7511 - accuracy: 0.7374\n",
            "Epoch 84/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4742 - accuracy: 0.7377\n",
            "Epoch 85/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3332 - accuracy: 0.7474\n",
            "Epoch 86/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0685 - accuracy: 0.7323\n",
            "Epoch 87/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3304 - accuracy: 0.7458\n",
            "Epoch 88/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6020 - accuracy: 0.7369\n",
            "Epoch 89/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3835 - accuracy: 0.7376\n",
            "Epoch 90/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4629 - accuracy: 0.7398\n",
            "Epoch 91/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3618 - accuracy: 0.7344\n",
            "Epoch 92/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5130 - accuracy: 0.7443\n",
            "Epoch 93/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9970 - accuracy: 0.7350\n",
            "Epoch 94/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8074 - accuracy: 0.7414\n",
            "Epoch 95/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6392 - accuracy: 0.7365\n",
            "Epoch 96/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.4326 - accuracy: 0.7354\n",
            "Epoch 97/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0963 - accuracy: 0.7289\n",
            "Epoch 98/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.3439 - accuracy: 0.7362\n",
            "Epoch 99/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8030 - accuracy: 0.7401\n",
            "Epoch 100/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.7903 - accuracy: 0.7380\n",
            "Epoch 101/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5660 - accuracy: 0.7323\n",
            "Epoch 102/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.6529 - accuracy: 0.7410\n",
            "Epoch 103/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8059 - accuracy: 0.7427\n",
            "Epoch 104/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8063 - accuracy: 0.7391\n",
            "Epoch 105/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.7826 - accuracy: 0.7334\n",
            "Epoch 106/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.5514 - accuracy: 0.7402\n",
            "Epoch 107/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9165 - accuracy: 0.7410\n",
            "Epoch 108/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9005 - accuracy: 0.7415\n",
            "Epoch 109/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.5435 - accuracy: 0.7389\n",
            "Epoch 110/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0719 - accuracy: 0.7405\n",
            "Epoch 111/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8558 - accuracy: 0.7341\n",
            "Epoch 112/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2528 - accuracy: 0.7341\n",
            "Epoch 113/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9774 - accuracy: 0.7383\n",
            "Epoch 114/163\n",
            "205/205 [==============================] - 2s 7ms/step - loss: 2.3562 - accuracy: 0.7301\n",
            "Epoch 115/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.7373 - accuracy: 0.7389\n",
            "Epoch 116/163\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 2.0858 - accuracy: 0.7291\n",
            "Epoch 117/163\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 1.5425 - accuracy: 0.7456\n",
            "Epoch 118/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.3448 - accuracy: 0.7346\n",
            "Epoch 119/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.9387 - accuracy: 0.7320\n",
            "Epoch 120/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.1071 - accuracy: 0.7349\n",
            "Epoch 121/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8872 - accuracy: 0.7374\n",
            "Epoch 122/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8803 - accuracy: 0.7394\n",
            "Epoch 123/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0747 - accuracy: 0.7381\n",
            "Epoch 124/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0815 - accuracy: 0.7394\n",
            "Epoch 125/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0196 - accuracy: 0.7386\n",
            "Epoch 126/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.4430 - accuracy: 0.7387\n",
            "Epoch 127/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8369 - accuracy: 0.7380\n",
            "Epoch 128/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0710 - accuracy: 0.7423\n",
            "Epoch 129/163\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 1.7869 - accuracy: 0.7304\n",
            "Epoch 130/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0004 - accuracy: 0.7382\n",
            "Epoch 131/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.7508 - accuracy: 0.7386\n",
            "Epoch 132/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8893 - accuracy: 0.7341\n",
            "Epoch 133/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0956 - accuracy: 0.7319\n",
            "Epoch 134/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2924 - accuracy: 0.7425\n",
            "Epoch 135/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2045 - accuracy: 0.7366\n",
            "Epoch 136/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8965 - accuracy: 0.7452\n",
            "Epoch 137/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.3128 - accuracy: 0.7405\n",
            "Epoch 138/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2012 - accuracy: 0.7349\n",
            "Epoch 139/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8836 - accuracy: 0.7425\n",
            "Epoch 140/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.4841 - accuracy: 0.7362\n",
            "Epoch 141/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.1870 - accuracy: 0.7406\n",
            "Epoch 142/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8758 - accuracy: 0.7487\n",
            "Epoch 143/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.1907 - accuracy: 0.7320\n",
            "Epoch 144/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.6228 - accuracy: 0.7362\n",
            "Epoch 145/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.3818 - accuracy: 0.7395\n",
            "Epoch 146/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.4565 - accuracy: 0.7345\n",
            "Epoch 147/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0153 - accuracy: 0.7387\n",
            "Epoch 148/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8478 - accuracy: 0.7407\n",
            "Epoch 149/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.5335 - accuracy: 0.7288\n",
            "Epoch 150/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0908 - accuracy: 0.7368\n",
            "Epoch 151/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.6071 - accuracy: 0.7348\n",
            "Epoch 152/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2144 - accuracy: 0.7389\n",
            "Epoch 153/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.7960 - accuracy: 0.7342\n",
            "Epoch 154/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.5557 - accuracy: 0.7426\n",
            "Epoch 155/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.5758 - accuracy: 0.7407\n",
            "Epoch 156/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.4968 - accuracy: 0.7316\n",
            "Epoch 157/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 1.8666 - accuracy: 0.7458\n",
            "Epoch 158/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.0387 - accuracy: 0.7362\n",
            "Epoch 159/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.4327 - accuracy: 0.7338\n",
            "Epoch 160/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.6048 - accuracy: 0.7393\n",
            "Epoch 161/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.3078 - accuracy: 0.7421\n",
            "Epoch 162/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.6479 - accuracy: 0.7389\n",
            "Epoch 163/163\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 2.2086 - accuracy: 0.7395\n",
            "52/52 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:40:36,246] Trial 7 finished with value: 0.8183262711864406 and parameters: {'xgb__subsample': 0.382920382968694, 'xgb__scale_pos_weight': 5.577136220482325, 'xgb__reg_lambda': 9.084908091868321, 'xgb__n_estimators': 324, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.3244160088734159, 'xgb__gamma': 0.22879816549162246, 'xgb__colsample_bytree': 0.1692819188459137, 'rf__n_estimators': 361, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 19, 'rf__max_depth': 9, 'rf__bootstrap': False, 'ann__epochs': 163, 'ann__batch_size': 37, 'ann__learning_rate': 0.03717371747825049}. Best is trial 0 with value: 0.8659957627118644.\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/74\n",
            "62/62 [==============================] - 5s 35ms/step - loss: 0.7843 - accuracy: 0.4766\n",
            "Epoch 2/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6095 - accuracy: 0.6776\n",
            "Epoch 3/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.7451\n",
            "Epoch 4/74\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.7732\n",
            "Epoch 5/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7852\n",
            "Epoch 6/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.7910\n",
            "Epoch 7/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.7949\n",
            "Epoch 8/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7970\n",
            "Epoch 9/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7989\n",
            "Epoch 10/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7995\n",
            "Epoch 11/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.8016\n",
            "Epoch 12/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8036\n",
            "Epoch 13/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8048\n",
            "Epoch 14/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8064\n",
            "Epoch 15/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8075\n",
            "Epoch 16/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8069\n",
            "Epoch 17/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8102\n",
            "Epoch 18/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8087\n",
            "Epoch 19/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8100\n",
            "Epoch 20/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8109\n",
            "Epoch 21/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8117\n",
            "Epoch 22/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8113\n",
            "Epoch 23/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8125\n",
            "Epoch 24/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8113\n",
            "Epoch 25/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8122\n",
            "Epoch 26/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8118\n",
            "Epoch 27/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8118\n",
            "Epoch 28/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8118\n",
            "Epoch 29/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8128\n",
            "Epoch 30/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8124\n",
            "Epoch 31/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8125\n",
            "Epoch 32/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8125\n",
            "Epoch 33/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8141\n",
            "Epoch 34/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8126\n",
            "Epoch 35/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8132\n",
            "Epoch 36/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8136\n",
            "Epoch 37/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8133\n",
            "Epoch 38/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8128\n",
            "Epoch 39/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8130\n",
            "Epoch 40/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8130\n",
            "Epoch 41/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8130\n",
            "Epoch 42/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8134\n",
            "Epoch 43/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8125\n",
            "Epoch 44/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8129\n",
            "Epoch 45/74\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8128\n",
            "Epoch 46/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8130\n",
            "Epoch 47/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8113\n",
            "Epoch 48/74\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.8117\n",
            "Epoch 49/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8125\n",
            "Epoch 50/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8122\n",
            "Epoch 51/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8128\n",
            "Epoch 52/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8129\n",
            "Epoch 53/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8126\n",
            "Epoch 54/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8125\n",
            "Epoch 55/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8117\n",
            "Epoch 56/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8126\n",
            "Epoch 57/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8121\n",
            "Epoch 58/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8125\n",
            "Epoch 59/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8121\n",
            "Epoch 60/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8122\n",
            "Epoch 61/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8124\n",
            "Epoch 62/74\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8125\n",
            "Epoch 63/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8121\n",
            "Epoch 64/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8117\n",
            "Epoch 65/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8117\n",
            "Epoch 66/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8129\n",
            "Epoch 67/74\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8130\n",
            "Epoch 68/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8124\n",
            "Epoch 69/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8126\n",
            "Epoch 70/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8130\n",
            "Epoch 71/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8128\n",
            "Epoch 72/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8129\n",
            "Epoch 73/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8122\n",
            "Epoch 74/74\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8114\n",
            "16/16 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:41:14,339] Trial 8 finished with value: 0.8082627118644068 and parameters: {'xgb__subsample': 0.5854080177240857, 'xgb__scale_pos_weight': 8.266961396476564, 'xgb__reg_lambda': 8.971303869242583, 'xgb__n_estimators': 386, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.02856737429847189, 'xgb__gamma': 0.4271077886262563, 'xgb__colsample_bytree': 0.8362132893302437, 'rf__n_estimators': 875, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 11, 'rf__max_depth': 5, 'rf__bootstrap': True, 'ann__epochs': 74, 'ann__batch_size': 122, 'ann__learning_rate': 0.00019625093208439862}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "176/176 [==============================] - 5s 16ms/step - loss: 0.6261 - accuracy: 0.6675\n",
            "Epoch 2/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.5679 - accuracy: 0.7153\n",
            "Epoch 3/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.5314 - accuracy: 0.7337\n",
            "Epoch 4/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.5068 - accuracy: 0.7432\n",
            "Epoch 5/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4896 - accuracy: 0.7540\n",
            "Epoch 6/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.7624\n",
            "Epoch 7/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.7685\n",
            "Epoch 8/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.7757\n",
            "Epoch 9/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4538 - accuracy: 0.7794\n",
            "Epoch 10/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.7840\n",
            "Epoch 11/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.7872\n",
            "Epoch 12/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.7917\n",
            "Epoch 13/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.7938\n",
            "Epoch 14/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7981\n",
            "Epoch 15/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4337 - accuracy: 0.8007\n",
            "Epoch 16/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8020\n",
            "Epoch 17/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8026\n",
            "Epoch 18/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8026\n",
            "Epoch 19/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8027\n",
            "Epoch 20/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8039\n",
            "Epoch 21/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8050\n",
            "Epoch 22/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8050\n",
            "Epoch 23/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8055\n",
            "Epoch 24/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8063\n",
            "Epoch 25/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8069\n",
            "Epoch 26/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8073\n",
            "Epoch 27/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8069\n",
            "Epoch 28/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8075\n",
            "Epoch 29/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8081\n",
            "Epoch 30/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4206 - accuracy: 0.8089\n",
            "Epoch 31/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8092\n",
            "Epoch 32/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8093\n",
            "Epoch 33/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8097\n",
            "Epoch 34/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8096\n",
            "Epoch 35/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8097\n",
            "Epoch 36/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8102\n",
            "Epoch 37/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8100\n",
            "Epoch 38/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8104\n",
            "Epoch 39/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8100\n",
            "Epoch 40/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8101\n",
            "Epoch 41/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8101\n",
            "Epoch 42/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8104\n",
            "Epoch 43/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8101\n",
            "Epoch 44/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8100\n",
            "Epoch 45/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8101\n",
            "Epoch 46/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8101\n",
            "Epoch 47/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8102\n",
            "Epoch 48/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8104\n",
            "Epoch 49/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8105\n",
            "Epoch 50/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8109\n",
            "Epoch 51/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8121\n",
            "Epoch 52/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8113\n",
            "Epoch 53/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8114\n",
            "Epoch 54/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8116\n",
            "Epoch 55/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8121\n",
            "Epoch 56/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8117\n",
            "Epoch 57/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8116\n",
            "Epoch 58/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8116\n",
            "Epoch 59/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8117\n",
            "Epoch 60/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8117\n",
            "Epoch 61/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8120\n",
            "Epoch 62/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8118\n",
            "Epoch 63/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8121\n",
            "Epoch 64/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8120\n",
            "Epoch 65/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8125\n",
            "Epoch 66/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8118\n",
            "Epoch 67/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8120\n",
            "Epoch 68/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8120\n",
            "Epoch 69/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8114\n",
            "Epoch 70/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8116\n",
            "Epoch 71/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8118\n",
            "Epoch 72/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8112\n",
            "Epoch 73/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4176 - accuracy: 0.8116\n",
            "Epoch 74/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8116\n",
            "Epoch 75/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8118\n",
            "Epoch 76/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8117\n",
            "Epoch 77/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8120\n",
            "Epoch 78/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 79/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8116\n",
            "Epoch 80/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8114\n",
            "Epoch 81/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8108\n",
            "Epoch 82/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 83/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.8117\n",
            "Epoch 84/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8112\n",
            "Epoch 85/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 86/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 87/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 88/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 89/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 90/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 91/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 92/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8114\n",
            "Epoch 93/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 94/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 95/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 96/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 97/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 98/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 99/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 100/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 101/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 102/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 103/183\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 104/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 105/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8125\n",
            "Epoch 106/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 107/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 108/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 109/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8118\n",
            "Epoch 110/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 111/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 112/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 113/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 114/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 115/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 116/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8132\n",
            "Epoch 117/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 118/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 119/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8125\n",
            "Epoch 120/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 121/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8116\n",
            "Epoch 122/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8121\n",
            "Epoch 123/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 124/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 125/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 126/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 127/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8113\n",
            "Epoch 128/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 129/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 130/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8122\n",
            "Epoch 131/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 132/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 133/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 134/183\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 135/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 136/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8126\n",
            "Epoch 137/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 138/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8121\n",
            "Epoch 139/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8117\n",
            "Epoch 140/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 141/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8114\n",
            "Epoch 142/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 143/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 144/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 145/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 146/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 147/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 148/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 149/183\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.4174 - accuracy: 0.8118\n",
            "Epoch 150/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8118\n",
            "Epoch 151/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 152/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 153/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8120\n",
            "Epoch 154/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8125\n",
            "Epoch 155/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8118\n",
            "Epoch 156/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8129\n",
            "Epoch 157/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 158/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8116\n",
            "Epoch 159/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8116\n",
            "Epoch 160/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 161/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8122\n",
            "Epoch 162/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8117\n",
            "Epoch 163/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8118\n",
            "Epoch 164/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8126\n",
            "Epoch 165/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8128\n",
            "Epoch 166/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8121\n",
            "Epoch 167/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8122\n",
            "Epoch 168/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 169/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8120\n",
            "Epoch 170/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8122\n",
            "Epoch 171/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8124\n",
            "Epoch 172/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8121\n",
            "Epoch 173/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8120\n",
            "Epoch 174/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 175/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8120\n",
            "Epoch 176/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8116\n",
            "Epoch 177/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8120\n",
            "Epoch 178/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8117\n",
            "Epoch 179/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8124\n",
            "Epoch 180/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8124\n",
            "Epoch 181/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8122\n",
            "Epoch 182/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4175 - accuracy: 0.8121\n",
            "Epoch 183/183\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8114\n",
            "44/44 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:45:01,708] Trial 9 finished with value: 0.8501059322033898 and parameters: {'xgb__subsample': 0.5669115595690295, 'xgb__scale_pos_weight': 7.3271706300566, 'xgb__reg_lambda': 3.6999330635550107, 'xgb__n_estimators': 975, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.031883397351001874, 'xgb__gamma': 0.49724850589238545, 'xgb__colsample_bytree': 0.37079047883509275, 'rf__n_estimators': 356, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 13, 'rf__max_depth': 6, 'rf__bootstrap': False, 'ann__epochs': 183, 'ann__batch_size': 43, 'ann__learning_rate': 3.798214508453257e-05}. Best is trial 0 with value: 0.8659957627118644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 5s 23ms/step - loss: 0.4477 - accuracy: 0.7930\n",
            "Epoch 2/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8085\n",
            "Epoch 3/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8092\n",
            "Epoch 4/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8129\n",
            "Epoch 5/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8110\n",
            "Epoch 6/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8113\n",
            "Epoch 7/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8109\n",
            "Epoch 8/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8112\n",
            "Epoch 9/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8110\n",
            "Epoch 10/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8117\n",
            "Epoch 11/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8093\n",
            "Epoch 12/138\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.8102\n",
            "Epoch 13/138\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.4203 - accuracy: 0.8117\n",
            "Epoch 14/138\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8092\n",
            "Epoch 15/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8093\n",
            "Epoch 16/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8100\n",
            "Epoch 17/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8100\n",
            "Epoch 18/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8092\n",
            "Epoch 19/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8106\n",
            "Epoch 20/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8101\n",
            "Epoch 21/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8102\n",
            "Epoch 22/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8076\n",
            "Epoch 23/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8091\n",
            "Epoch 24/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8068\n",
            "Epoch 25/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8091\n",
            "Epoch 26/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8088\n",
            "Epoch 27/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8073\n",
            "Epoch 28/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.8097\n",
            "Epoch 29/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8113\n",
            "Epoch 30/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8068\n",
            "Epoch 31/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8101\n",
            "Epoch 32/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8076\n",
            "Epoch 33/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8083\n",
            "Epoch 34/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8080\n",
            "Epoch 35/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8079\n",
            "Epoch 36/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8075\n",
            "Epoch 37/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8104\n",
            "Epoch 38/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8099\n",
            "Epoch 39/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8096\n",
            "Epoch 40/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8055\n",
            "Epoch 41/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8089\n",
            "Epoch 42/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8084\n",
            "Epoch 43/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4261 - accuracy: 0.8068\n",
            "Epoch 44/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8092\n",
            "Epoch 45/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8072\n",
            "Epoch 46/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8093\n",
            "Epoch 47/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8065\n",
            "Epoch 48/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8055\n",
            "Epoch 49/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8079\n",
            "Epoch 50/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8073\n",
            "Epoch 51/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8046\n",
            "Epoch 52/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8084\n",
            "Epoch 53/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8065\n",
            "Epoch 54/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8104\n",
            "Epoch 55/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8031\n",
            "Epoch 56/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8046\n",
            "Epoch 57/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8089\n",
            "Epoch 58/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8076\n",
            "Epoch 59/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8035\n",
            "Epoch 60/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8079\n",
            "Epoch 61/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8068\n",
            "Epoch 62/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8065\n",
            "Epoch 63/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8085\n",
            "Epoch 64/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8109\n",
            "Epoch 65/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8081\n",
            "Epoch 66/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8084\n",
            "Epoch 67/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8073\n",
            "Epoch 68/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8051\n",
            "Epoch 69/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8053\n",
            "Epoch 70/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4256 - accuracy: 0.8071\n",
            "Epoch 71/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4307 - accuracy: 0.8027\n",
            "Epoch 72/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4267 - accuracy: 0.8050\n",
            "Epoch 73/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8064\n",
            "Epoch 74/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8014\n",
            "Epoch 75/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8075\n",
            "Epoch 76/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8057\n",
            "Epoch 77/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8038\n",
            "Epoch 78/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8034\n",
            "Epoch 79/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8068\n",
            "Epoch 80/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8071\n",
            "Epoch 81/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8099\n",
            "Epoch 82/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8073\n",
            "Epoch 83/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8104\n",
            "Epoch 84/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8061\n",
            "Epoch 85/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8056\n",
            "Epoch 86/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8055\n",
            "Epoch 87/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8069\n",
            "Epoch 88/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8076\n",
            "Epoch 89/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8015\n",
            "Epoch 90/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8084\n",
            "Epoch 91/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8034\n",
            "Epoch 92/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8104\n",
            "Epoch 93/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8095\n",
            "Epoch 94/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4276 - accuracy: 0.8052\n",
            "Epoch 95/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8069\n",
            "Epoch 96/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.8060\n",
            "Epoch 97/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8080\n",
            "Epoch 98/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8050\n",
            "Epoch 99/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4341 - accuracy: 0.8040\n",
            "Epoch 100/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4341 - accuracy: 0.8043\n",
            "Epoch 101/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8060\n",
            "Epoch 102/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8061\n",
            "Epoch 103/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8088\n",
            "Epoch 104/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8055\n",
            "Epoch 105/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8036\n",
            "Epoch 106/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8038\n",
            "Epoch 107/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8057\n",
            "Epoch 108/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.8010\n",
            "Epoch 109/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8069\n",
            "Epoch 110/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8064\n",
            "Epoch 111/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8042\n",
            "Epoch 112/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8057\n",
            "Epoch 113/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8012\n",
            "Epoch 114/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8047\n",
            "Epoch 115/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8055\n",
            "Epoch 116/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8018\n",
            "Epoch 117/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8040\n",
            "Epoch 118/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4288 - accuracy: 0.8034\n",
            "Epoch 119/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8028\n",
            "Epoch 120/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8057\n",
            "Epoch 121/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8051\n",
            "Epoch 122/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8068\n",
            "Epoch 123/138\n",
            "108/108 [==============================] - 1s 12ms/step - loss: 0.4305 - accuracy: 0.8065\n",
            "Epoch 124/138\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.4345 - accuracy: 0.8020\n",
            "Epoch 125/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8003\n",
            "Epoch 126/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4415 - accuracy: 0.7999\n",
            "Epoch 127/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8055\n",
            "Epoch 128/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.7969\n",
            "Epoch 129/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.8006\n",
            "Epoch 130/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8061\n",
            "Epoch 131/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.7979\n",
            "Epoch 132/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8076\n",
            "Epoch 133/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.8031\n",
            "Epoch 134/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8072\n",
            "Epoch 135/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8087\n",
            "Epoch 136/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8056\n",
            "Epoch 137/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4521 - accuracy: 0.7938\n",
            "Epoch 138/138\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8030\n",
            "27/27 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:46:52,393] Trial 10 finished with value: 0.868114406779661 and parameters: {'xgb__subsample': 0.9814934905125248, 'xgb__scale_pos_weight': 1.053974646602354, 'xgb__reg_lambda': 0.17471846123130153, 'xgb__n_estimators': 829, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.16638185017877255, 'xgb__gamma': 0.015165720318569761, 'xgb__colsample_bytree': 0.978843961022449, 'rf__n_estimators': 138, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 1, 'rf__max_depth': 2, 'rf__bootstrap': False, 'ann__epochs': 138, 'ann__batch_size': 70, 'ann__learning_rate': 0.0015964544596507545}. Best is trial 10 with value: 0.868114406779661.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104/104 [==============================] - 5s 24ms/step - loss: 0.4857 - accuracy: 0.7566\n",
            "Epoch 2/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8079\n",
            "Epoch 3/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4211 - accuracy: 0.8104\n",
            "Epoch 4/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8080\n",
            "Epoch 5/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8100\n",
            "Epoch 6/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8130\n",
            "Epoch 7/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8106\n",
            "Epoch 8/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8077\n",
            "Epoch 9/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8110\n",
            "Epoch 10/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8110\n",
            "Epoch 11/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8089\n",
            "Epoch 12/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8102\n",
            "Epoch 13/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8104\n",
            "Epoch 14/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8130\n",
            "Epoch 15/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8109\n",
            "Epoch 16/148\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8083\n",
            "Epoch 17/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8092\n",
            "Epoch 18/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8097\n",
            "Epoch 19/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4227 - accuracy: 0.8109\n",
            "Epoch 20/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8097\n",
            "Epoch 21/148\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.4227 - accuracy: 0.8122\n",
            "Epoch 22/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8077\n",
            "Epoch 23/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8117\n",
            "Epoch 24/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8099\n",
            "Epoch 25/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8100\n",
            "Epoch 26/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8093\n",
            "Epoch 27/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8112\n",
            "Epoch 28/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8063\n",
            "Epoch 29/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8073\n",
            "Epoch 30/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8073\n",
            "Epoch 31/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8081\n",
            "Epoch 32/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8101\n",
            "Epoch 33/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8047\n",
            "Epoch 34/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4237 - accuracy: 0.8061\n",
            "Epoch 35/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8088\n",
            "Epoch 36/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8065\n",
            "Epoch 37/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8068\n",
            "Epoch 38/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4276 - accuracy: 0.8056\n",
            "Epoch 39/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8085\n",
            "Epoch 40/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8081\n",
            "Epoch 41/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8109\n",
            "Epoch 42/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8055\n",
            "Epoch 43/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8081\n",
            "Epoch 44/148\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8065\n",
            "Epoch 45/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8068\n",
            "Epoch 46/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8077\n",
            "Epoch 47/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8044\n",
            "Epoch 48/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8088\n",
            "Epoch 49/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8089\n",
            "Epoch 50/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8100\n",
            "Epoch 51/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8060\n",
            "Epoch 52/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8015\n",
            "Epoch 53/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8064\n",
            "Epoch 54/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8064\n",
            "Epoch 55/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8065\n",
            "Epoch 56/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8068\n",
            "Epoch 57/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8089\n",
            "Epoch 58/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8114\n",
            "Epoch 59/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8028\n",
            "Epoch 60/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8061\n",
            "Epoch 61/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8101\n",
            "Epoch 62/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8089\n",
            "Epoch 63/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4337 - accuracy: 0.8039\n",
            "Epoch 64/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8060\n",
            "Epoch 65/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8084\n",
            "Epoch 66/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8075\n",
            "Epoch 67/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8010\n",
            "Epoch 68/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4328 - accuracy: 0.8039\n",
            "Epoch 69/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8065\n",
            "Epoch 70/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8091\n",
            "Epoch 71/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8061\n",
            "Epoch 72/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8085\n",
            "Epoch 73/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8128\n",
            "Epoch 74/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8024\n",
            "Epoch 75/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8071\n",
            "Epoch 76/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8053\n",
            "Epoch 77/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8073\n",
            "Epoch 78/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8051\n",
            "Epoch 79/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8063\n",
            "Epoch 80/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8030\n",
            "Epoch 81/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.8026\n",
            "Epoch 82/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.7989\n",
            "Epoch 83/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8102\n",
            "Epoch 84/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8071\n",
            "Epoch 85/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4296 - accuracy: 0.8050\n",
            "Epoch 86/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8088\n",
            "Epoch 87/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8040\n",
            "Epoch 88/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.8028\n",
            "Epoch 89/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8073\n",
            "Epoch 90/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8056\n",
            "Epoch 91/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4341 - accuracy: 0.8042\n",
            "Epoch 92/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8079\n",
            "Epoch 93/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4339 - accuracy: 0.8034\n",
            "Epoch 94/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8076\n",
            "Epoch 95/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4315 - accuracy: 0.8036\n",
            "Epoch 96/148\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.4291 - accuracy: 0.8052\n",
            "Epoch 97/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8016\n",
            "Epoch 98/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8057\n",
            "Epoch 99/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8046\n",
            "Epoch 100/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4292 - accuracy: 0.8063\n",
            "Epoch 101/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8053\n",
            "Epoch 102/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8022\n",
            "Epoch 103/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8044\n",
            "Epoch 104/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8028\n",
            "Epoch 105/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8010\n",
            "Epoch 106/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8063\n",
            "Epoch 107/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8022\n",
            "Epoch 108/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8089\n",
            "Epoch 109/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8083\n",
            "Epoch 110/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8038\n",
            "Epoch 111/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.7985\n",
            "Epoch 112/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8063\n",
            "Epoch 113/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4306 - accuracy: 0.8072\n",
            "Epoch 114/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4339 - accuracy: 0.8011\n",
            "Epoch 115/148\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8040\n",
            "Epoch 116/148\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.4336 - accuracy: 0.8005\n",
            "Epoch 117/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8065\n",
            "Epoch 118/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4415 - accuracy: 0.7957\n",
            "Epoch 119/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8026\n",
            "Epoch 120/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8060\n",
            "Epoch 121/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.7997\n",
            "Epoch 122/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8042\n",
            "Epoch 123/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8046\n",
            "Epoch 124/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8027\n",
            "Epoch 125/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4423 - accuracy: 0.8002\n",
            "Epoch 126/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.7971\n",
            "Epoch 127/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.8005\n",
            "Epoch 128/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8085\n",
            "Epoch 129/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4363 - accuracy: 0.8014\n",
            "Epoch 130/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4306 - accuracy: 0.8032\n",
            "Epoch 131/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8007\n",
            "Epoch 132/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8044\n",
            "Epoch 133/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8040\n",
            "Epoch 134/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8092\n",
            "Epoch 135/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8063\n",
            "Epoch 136/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4540 - accuracy: 0.7945\n",
            "Epoch 137/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4335 - accuracy: 0.8061\n",
            "Epoch 138/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8022\n",
            "Epoch 139/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8069\n",
            "Epoch 140/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.7961\n",
            "Epoch 141/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8105\n",
            "Epoch 142/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.8050\n",
            "Epoch 143/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8076\n",
            "Epoch 144/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.8048\n",
            "Epoch 145/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4421 - accuracy: 0.8002\n",
            "Epoch 146/148\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8032\n",
            "Epoch 147/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.8001\n",
            "Epoch 148/148\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8002\n",
            "26/26 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:48:48,942] Trial 11 finished with value: 0.871822033898305 and parameters: {'xgb__subsample': 0.9918536708481084, 'xgb__scale_pos_weight': 1.0704484490101513, 'xgb__reg_lambda': 0.1776051958904159, 'xgb__n_estimators': 820, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.14221808656348645, 'xgb__gamma': 0.03454861691481451, 'xgb__colsample_bytree': 0.9597235316392483, 'rf__n_estimators': 114, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 1, 'rf__max_depth': 1, 'rf__bootstrap': False, 'ann__epochs': 148, 'ann__batch_size': 73, 'ann__learning_rate': 0.001855241654243998}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99/99 [==============================] - 5s 25ms/step - loss: 0.4395 - accuracy: 0.8003\n",
            "Epoch 2/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4234 - accuracy: 0.8091\n",
            "Epoch 3/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8144\n",
            "Epoch 4/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4231 - accuracy: 0.8072\n",
            "Epoch 5/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8080\n",
            "Epoch 6/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4218 - accuracy: 0.8076\n",
            "Epoch 7/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4264 - accuracy: 0.8053\n",
            "Epoch 8/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4269 - accuracy: 0.8065\n",
            "Epoch 9/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8069\n",
            "Epoch 10/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8022\n",
            "Epoch 11/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8080\n",
            "Epoch 12/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8092\n",
            "Epoch 13/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8067\n",
            "Epoch 14/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8039\n",
            "Epoch 15/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8080\n",
            "Epoch 16/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4264 - accuracy: 0.8046\n",
            "Epoch 17/154\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4260 - accuracy: 0.8059\n",
            "Epoch 18/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4311 - accuracy: 0.8060\n",
            "Epoch 19/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8032\n",
            "Epoch 20/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4286 - accuracy: 0.8042\n",
            "Epoch 21/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8028\n",
            "Epoch 22/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8068\n",
            "Epoch 23/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8046\n",
            "Epoch 24/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8053\n",
            "Epoch 25/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.8003\n",
            "Epoch 26/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4333 - accuracy: 0.8035\n",
            "Epoch 27/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8052\n",
            "Epoch 28/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4310 - accuracy: 0.8065\n",
            "Epoch 29/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4363 - accuracy: 0.8011\n",
            "Epoch 30/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8030\n",
            "Epoch 31/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8027\n",
            "Epoch 32/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8099\n",
            "Epoch 33/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4365 - accuracy: 0.8016\n",
            "Epoch 34/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.8018\n",
            "Epoch 35/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.8006\n",
            "Epoch 36/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4337 - accuracy: 0.8034\n",
            "Epoch 37/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.7994\n",
            "Epoch 38/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.7997\n",
            "Epoch 39/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.8069\n",
            "Epoch 40/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8020\n",
            "Epoch 41/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.8019\n",
            "Epoch 42/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8006\n",
            "Epoch 43/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4397 - accuracy: 0.8043\n",
            "Epoch 44/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.7942\n",
            "Epoch 45/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8064\n",
            "Epoch 46/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4375 - accuracy: 0.7985\n",
            "Epoch 47/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.8014\n",
            "Epoch 48/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8031\n",
            "Epoch 49/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4487 - accuracy: 0.7973\n",
            "Epoch 50/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8047\n",
            "Epoch 51/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8081\n",
            "Epoch 52/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.8038\n",
            "Epoch 53/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.8034\n",
            "Epoch 54/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8056\n",
            "Epoch 55/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8056\n",
            "Epoch 56/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.8020\n",
            "Epoch 57/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.7990\n",
            "Epoch 58/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8044\n",
            "Epoch 59/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.8010\n",
            "Epoch 60/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.7932\n",
            "Epoch 61/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.7965\n",
            "Epoch 62/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8032\n",
            "Epoch 63/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4561 - accuracy: 0.7973\n",
            "Epoch 64/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4351 - accuracy: 0.8035\n",
            "Epoch 65/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.7981\n",
            "Epoch 66/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.7997\n",
            "Epoch 67/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.7970\n",
            "Epoch 68/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4454 - accuracy: 0.7983\n",
            "Epoch 69/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8010\n",
            "Epoch 70/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7961\n",
            "Epoch 71/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8060\n",
            "Epoch 72/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8064\n",
            "Epoch 73/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.7950\n",
            "Epoch 74/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4726 - accuracy: 0.7914\n",
            "Epoch 75/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4432 - accuracy: 0.7987\n",
            "Epoch 76/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.7987\n",
            "Epoch 77/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4501 - accuracy: 0.7991\n",
            "Epoch 78/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8055\n",
            "Epoch 79/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.7979\n",
            "Epoch 80/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4639 - accuracy: 0.7924\n",
            "Epoch 81/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8077\n",
            "Epoch 82/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8046\n",
            "Epoch 83/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.8030\n",
            "Epoch 84/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.7997\n",
            "Epoch 85/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.7930\n",
            "Epoch 86/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4484 - accuracy: 0.7979\n",
            "Epoch 87/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8019\n",
            "Epoch 88/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.8016\n",
            "Epoch 89/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8026\n",
            "Epoch 90/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.8001\n",
            "Epoch 91/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.7936\n",
            "Epoch 92/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4495 - accuracy: 0.7961\n",
            "Epoch 93/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.7983\n",
            "Epoch 94/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.7981\n",
            "Epoch 95/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.7961\n",
            "Epoch 96/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4437 - accuracy: 0.8019\n",
            "Epoch 97/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.7944\n",
            "Epoch 98/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.7832\n",
            "Epoch 99/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.7938\n",
            "Epoch 100/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.7954\n",
            "Epoch 101/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.7942\n",
            "Epoch 102/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.8012\n",
            "Epoch 103/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.7995\n",
            "Epoch 104/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.8002\n",
            "Epoch 105/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4609 - accuracy: 0.7934\n",
            "Epoch 106/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.7912\n",
            "Epoch 107/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.8069\n",
            "Epoch 108/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.7993\n",
            "Epoch 109/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4469 - accuracy: 0.7983\n",
            "Epoch 110/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4548 - accuracy: 0.7970\n",
            "Epoch 111/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.7981\n",
            "Epoch 112/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4431 - accuracy: 0.8015\n",
            "Epoch 113/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4415 - accuracy: 0.8014\n",
            "Epoch 114/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4435 - accuracy: 0.8028\n",
            "Epoch 115/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.8015\n",
            "Epoch 116/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4401 - accuracy: 0.8018\n",
            "Epoch 117/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4584 - accuracy: 0.7954\n",
            "Epoch 118/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4493 - accuracy: 0.8020\n",
            "Epoch 119/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.7981\n",
            "Epoch 120/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4588 - accuracy: 0.7928\n",
            "Epoch 121/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.7945\n",
            "Epoch 122/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4709 - accuracy: 0.7952\n",
            "Epoch 123/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4437 - accuracy: 0.8012\n",
            "Epoch 124/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4651 - accuracy: 0.7924\n",
            "Epoch 125/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.7962\n",
            "Epoch 126/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8010\n",
            "Epoch 127/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4428 - accuracy: 0.8010\n",
            "Epoch 128/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4677 - accuracy: 0.7930\n",
            "Epoch 129/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7859\n",
            "Epoch 130/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.7993\n",
            "Epoch 131/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4561 - accuracy: 0.7986\n",
            "Epoch 132/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.7920\n",
            "Epoch 133/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4615 - accuracy: 0.7909\n",
            "Epoch 134/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4526 - accuracy: 0.7983\n",
            "Epoch 135/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.7970\n",
            "Epoch 136/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.7924\n",
            "Epoch 137/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.7848\n",
            "Epoch 138/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4495 - accuracy: 0.8005\n",
            "Epoch 139/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4653 - accuracy: 0.7887\n",
            "Epoch 140/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4448 - accuracy: 0.8001\n",
            "Epoch 141/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.7946\n",
            "Epoch 142/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4595 - accuracy: 0.7962\n",
            "Epoch 143/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4522 - accuracy: 0.8014\n",
            "Epoch 144/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.8014\n",
            "Epoch 145/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4516 - accuracy: 0.7981\n",
            "Epoch 146/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.7910\n",
            "Epoch 147/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.7934\n",
            "Epoch 148/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.7764\n",
            "Epoch 149/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4686 - accuracy: 0.7899\n",
            "Epoch 150/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4802 - accuracy: 0.7856\n",
            "Epoch 151/154\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4457 - accuracy: 0.8018\n",
            "Epoch 152/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.7994\n",
            "Epoch 153/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.7949\n",
            "Epoch 154/154\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.7926\n",
            "25/25 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:50:43,647] Trial 12 finished with value: 0.8532838983050848 and parameters: {'xgb__subsample': 0.833305347104408, 'xgb__scale_pos_weight': 1.1728932911205312, 'xgb__reg_lambda': 0.3572115386561307, 'xgb__n_estimators': 807, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.21062720567129056, 'xgb__gamma': 0.2811625791970913, 'xgb__colsample_bytree': 0.9964152904250919, 'rf__n_estimators': 126, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 4, 'rf__max_depth': 1, 'rf__bootstrap': False, 'ann__epochs': 154, 'ann__batch_size': 77, 'ann__learning_rate': 0.003130345981160326}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "103/103 [==============================] - 6s 23ms/step - loss: 0.4595 - accuracy: 0.7871\n",
            "Epoch 2/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8105\n",
            "Epoch 3/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8108\n",
            "Epoch 4/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8101\n",
            "Epoch 5/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8114\n",
            "Epoch 6/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4197 - accuracy: 0.8114\n",
            "Epoch 7/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4207 - accuracy: 0.8097\n",
            "Epoch 8/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8077\n",
            "Epoch 9/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4204 - accuracy: 0.8091\n",
            "Epoch 10/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4211 - accuracy: 0.8138\n",
            "Epoch 11/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.8097\n",
            "Epoch 12/145\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 0.4207 - accuracy: 0.8130\n",
            "Epoch 13/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4214 - accuracy: 0.8091\n",
            "Epoch 14/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4206 - accuracy: 0.8106\n",
            "Epoch 15/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8095\n",
            "Epoch 16/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8081\n",
            "Epoch 17/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8081\n",
            "Epoch 18/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8095\n",
            "Epoch 19/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4203 - accuracy: 0.8085\n",
            "Epoch 20/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8088\n",
            "Epoch 21/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8097\n",
            "Epoch 22/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4218 - accuracy: 0.8126\n",
            "Epoch 23/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8080\n",
            "Epoch 24/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8092\n",
            "Epoch 25/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8110\n",
            "Epoch 26/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8064\n",
            "Epoch 27/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8091\n",
            "Epoch 28/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8052\n",
            "Epoch 29/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8042\n",
            "Epoch 30/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8097\n",
            "Epoch 31/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8095\n",
            "Epoch 32/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8130\n",
            "Epoch 33/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.8100\n",
            "Epoch 34/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8081\n",
            "Epoch 35/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8050\n",
            "Epoch 36/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8102\n",
            "Epoch 37/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8065\n",
            "Epoch 38/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8036\n",
            "Epoch 39/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8052\n",
            "Epoch 40/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8087\n",
            "Epoch 41/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8087\n",
            "Epoch 42/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8079\n",
            "Epoch 43/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8079\n",
            "Epoch 44/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8079\n",
            "Epoch 45/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8068\n",
            "Epoch 46/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8063\n",
            "Epoch 47/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8087\n",
            "Epoch 48/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8081\n",
            "Epoch 49/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8051\n",
            "Epoch 50/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8075\n",
            "Epoch 51/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8097\n",
            "Epoch 52/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8059\n",
            "Epoch 53/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8112\n",
            "Epoch 54/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8043\n",
            "Epoch 55/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8027\n",
            "Epoch 56/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8097\n",
            "Epoch 57/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8075\n",
            "Epoch 58/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8050\n",
            "Epoch 59/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8126\n",
            "Epoch 60/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8075\n",
            "Epoch 61/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8084\n",
            "Epoch 62/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8079\n",
            "Epoch 63/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8133\n",
            "Epoch 64/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8053\n",
            "Epoch 65/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8104\n",
            "Epoch 66/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8080\n",
            "Epoch 67/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8068\n",
            "Epoch 68/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8068\n",
            "Epoch 69/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8055\n",
            "Epoch 70/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8089\n",
            "Epoch 71/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8099\n",
            "Epoch 72/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8109\n",
            "Epoch 73/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8043\n",
            "Epoch 74/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8092\n",
            "Epoch 75/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8073\n",
            "Epoch 76/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8052\n",
            "Epoch 77/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8023\n",
            "Epoch 78/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8099\n",
            "Epoch 79/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8077\n",
            "Epoch 80/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8065\n",
            "Epoch 81/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8104\n",
            "Epoch 82/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8067\n",
            "Epoch 83/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8091\n",
            "Epoch 84/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8034\n",
            "Epoch 85/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8057\n",
            "Epoch 86/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8101\n",
            "Epoch 87/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8027\n",
            "Epoch 88/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8087\n",
            "Epoch 89/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8052\n",
            "Epoch 90/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8155\n",
            "Epoch 91/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8051\n",
            "Epoch 92/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8059\n",
            "Epoch 93/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8026\n",
            "Epoch 94/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8085\n",
            "Epoch 95/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.8028\n",
            "Epoch 96/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4296 - accuracy: 0.8064\n",
            "Epoch 97/145\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 0.4288 - accuracy: 0.8047\n",
            "Epoch 98/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.7998\n",
            "Epoch 99/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8027\n",
            "Epoch 100/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8084\n",
            "Epoch 101/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8050\n",
            "Epoch 102/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8032\n",
            "Epoch 103/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8083\n",
            "Epoch 104/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8079\n",
            "Epoch 105/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4306 - accuracy: 0.8065\n",
            "Epoch 106/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.8040\n",
            "Epoch 107/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8072\n",
            "Epoch 108/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8081\n",
            "Epoch 109/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8043\n",
            "Epoch 110/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8064\n",
            "Epoch 111/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8076\n",
            "Epoch 112/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8077\n",
            "Epoch 113/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8053\n",
            "Epoch 114/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8016\n",
            "Epoch 115/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8002\n",
            "Epoch 116/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8068\n",
            "Epoch 117/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8053\n",
            "Epoch 118/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8055\n",
            "Epoch 119/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8063\n",
            "Epoch 120/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8053\n",
            "Epoch 121/145\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 0.4312 - accuracy: 0.8036\n",
            "Epoch 122/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8030\n",
            "Epoch 123/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8089\n",
            "Epoch 124/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.8071\n",
            "Epoch 125/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8022\n",
            "Epoch 126/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8064\n",
            "Epoch 127/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8079\n",
            "Epoch 128/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8039\n",
            "Epoch 129/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8014\n",
            "Epoch 130/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8042\n",
            "Epoch 131/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.8006\n",
            "Epoch 132/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8060\n",
            "Epoch 133/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8051\n",
            "Epoch 134/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8063\n",
            "Epoch 135/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8047\n",
            "Epoch 136/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8011\n",
            "Epoch 137/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8059\n",
            "Epoch 138/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8053\n",
            "Epoch 139/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8051\n",
            "Epoch 140/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8027\n",
            "Epoch 141/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8047\n",
            "Epoch 142/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8071\n",
            "Epoch 143/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8100\n",
            "Epoch 144/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8002\n",
            "Epoch 145/145\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.8068\n",
            "26/26 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:52:36,200] Trial 13 finished with value: 0.8649364406779662 and parameters: {'xgb__subsample': 0.8290957749718659, 'xgb__scale_pos_weight': 2.349305431298755, 'xgb__reg_lambda': 1.3835670516098517, 'xgb__n_estimators': 781, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.9006020499939716, 'xgb__gamma': 0.004740119653089181, 'xgb__colsample_bytree': 0.9666877688539538, 'rf__n_estimators': 222, 'rf__min_samples_split': 13, 'rf__min_samples_leaf': 3, 'rf__max_depth': 3, 'rf__bootstrap': False, 'ann__epochs': 145, 'ann__batch_size': 74, 'ann__learning_rate': 0.0015504255306959505}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80/80 [==============================] - 5s 28ms/step - loss: 0.4450 - accuracy: 0.7969\n",
            "Epoch 2/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8071\n",
            "Epoch 3/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8077\n",
            "Epoch 4/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8050\n",
            "Epoch 5/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8056\n",
            "Epoch 6/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4363 - accuracy: 0.8028\n",
            "Epoch 7/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.8030\n",
            "Epoch 8/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8030\n",
            "Epoch 9/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8044\n",
            "Epoch 10/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8002\n",
            "Epoch 11/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8051\n",
            "Epoch 12/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.7977\n",
            "Epoch 13/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.7895\n",
            "Epoch 14/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.7959\n",
            "Epoch 15/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.8010\n",
            "Epoch 16/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8040\n",
            "Epoch 17/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7985\n",
            "Epoch 18/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.8008\n",
            "Epoch 19/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8023\n",
            "Epoch 20/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.7965\n",
            "Epoch 21/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.8039\n",
            "Epoch 22/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4539 - accuracy: 0.7962\n",
            "Epoch 23/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.8011\n",
            "Epoch 24/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4501 - accuracy: 0.7965\n",
            "Epoch 25/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7801\n",
            "Epoch 26/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4655 - accuracy: 0.7933\n",
            "Epoch 27/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4988 - accuracy: 0.7859\n",
            "Epoch 28/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.7904\n",
            "Epoch 29/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4474 - accuracy: 0.7963\n",
            "Epoch 30/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.7918\n",
            "Epoch 31/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4498 - accuracy: 0.7982\n",
            "Epoch 32/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4862 - accuracy: 0.7916\n",
            "Epoch 33/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.7970\n",
            "Epoch 34/193\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.4656 - accuracy: 0.7893\n",
            "Epoch 35/193\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.4716 - accuracy: 0.7946\n",
            "Epoch 36/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4882 - accuracy: 0.7847\n",
            "Epoch 37/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.7823\n",
            "Epoch 38/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.8005\n",
            "Epoch 39/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.7928\n",
            "Epoch 40/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4697 - accuracy: 0.7907\n",
            "Epoch 41/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4778 - accuracy: 0.7893\n",
            "Epoch 42/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4465 - accuracy: 0.8006\n",
            "Epoch 43/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4644 - accuracy: 0.7952\n",
            "Epoch 44/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.7920\n",
            "Epoch 45/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7859\n",
            "Epoch 46/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4599 - accuracy: 0.7959\n",
            "Epoch 47/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.7855\n",
            "Epoch 48/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4754 - accuracy: 0.7896\n",
            "Epoch 49/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5160 - accuracy: 0.7752\n",
            "Epoch 50/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.7865\n",
            "Epoch 51/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4702 - accuracy: 0.7905\n",
            "Epoch 52/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4890 - accuracy: 0.7900\n",
            "Epoch 53/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.7823\n",
            "Epoch 54/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7863\n",
            "Epoch 55/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4865 - accuracy: 0.7840\n",
            "Epoch 56/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.7746\n",
            "Epoch 57/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.7877\n",
            "Epoch 58/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7908\n",
            "Epoch 59/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.7888\n",
            "Epoch 60/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4762 - accuracy: 0.7856\n",
            "Epoch 61/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.7840\n",
            "Epoch 62/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5015 - accuracy: 0.7802\n",
            "Epoch 63/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.7761\n",
            "Epoch 64/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4925 - accuracy: 0.7860\n",
            "Epoch 65/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4823 - accuracy: 0.7892\n",
            "Epoch 66/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.7922\n",
            "Epoch 67/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.7818\n",
            "Epoch 68/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.7861\n",
            "Epoch 69/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7738\n",
            "Epoch 70/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4861 - accuracy: 0.7847\n",
            "Epoch 71/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7887\n",
            "Epoch 72/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5202 - accuracy: 0.7760\n",
            "Epoch 73/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5767 - accuracy: 0.7634\n",
            "Epoch 74/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.7868\n",
            "Epoch 75/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5452 - accuracy: 0.7688\n",
            "Epoch 76/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4781 - accuracy: 0.7859\n",
            "Epoch 77/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.7801\n",
            "Epoch 78/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4839 - accuracy: 0.7799\n",
            "Epoch 79/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.7893\n",
            "Epoch 80/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4936 - accuracy: 0.7818\n",
            "Epoch 81/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7769\n",
            "Epoch 82/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5373 - accuracy: 0.7733\n",
            "Epoch 83/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4808 - accuracy: 0.7892\n",
            "Epoch 84/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7908\n",
            "Epoch 85/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.7835\n",
            "Epoch 86/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7762\n",
            "Epoch 87/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7798\n",
            "Epoch 88/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.7805\n",
            "Epoch 89/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4821 - accuracy: 0.7904\n",
            "Epoch 90/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7883\n",
            "Epoch 91/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5123 - accuracy: 0.7809\n",
            "Epoch 92/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.7798\n",
            "Epoch 93/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5162 - accuracy: 0.7863\n",
            "Epoch 94/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4808 - accuracy: 0.7880\n",
            "Epoch 95/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.7815\n",
            "Epoch 96/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.7717\n",
            "Epoch 97/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5567 - accuracy: 0.7669\n",
            "Epoch 98/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7774\n",
            "Epoch 99/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5312 - accuracy: 0.7717\n",
            "Epoch 100/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.7777\n",
            "Epoch 101/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.7828\n",
            "Epoch 102/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4958 - accuracy: 0.7824\n",
            "Epoch 103/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7737\n",
            "Epoch 104/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5095 - accuracy: 0.7803\n",
            "Epoch 105/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5537 - accuracy: 0.7722\n",
            "Epoch 106/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.7791\n",
            "Epoch 107/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5913 - accuracy: 0.7617\n",
            "Epoch 108/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.7663\n",
            "Epoch 109/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5481 - accuracy: 0.7748\n",
            "Epoch 110/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.7774\n",
            "Epoch 111/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5257 - accuracy: 0.7765\n",
            "Epoch 112/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5222 - accuracy: 0.7789\n",
            "Epoch 113/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5028 - accuracy: 0.7774\n",
            "Epoch 114/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5739 - accuracy: 0.7709\n",
            "Epoch 115/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5777 - accuracy: 0.7695\n",
            "Epoch 116/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5275 - accuracy: 0.7758\n",
            "Epoch 117/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5404 - accuracy: 0.7752\n",
            "Epoch 118/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.7766\n",
            "Epoch 119/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7815\n",
            "Epoch 120/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5672 - accuracy: 0.7687\n",
            "Epoch 121/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5316 - accuracy: 0.7775\n",
            "Epoch 122/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5489 - accuracy: 0.7680\n",
            "Epoch 123/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6288 - accuracy: 0.7591\n",
            "Epoch 124/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4985 - accuracy: 0.7811\n",
            "Epoch 125/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7757\n",
            "Epoch 126/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.7757\n",
            "Epoch 127/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.7656\n",
            "Epoch 128/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4883 - accuracy: 0.7859\n",
            "Epoch 129/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.7771\n",
            "Epoch 130/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.7745\n",
            "Epoch 131/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6769 - accuracy: 0.7540\n",
            "Epoch 132/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5289 - accuracy: 0.7799\n",
            "Epoch 133/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5338 - accuracy: 0.7712\n",
            "Epoch 134/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5583 - accuracy: 0.7705\n",
            "Epoch 135/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7754\n",
            "Epoch 136/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4715 - accuracy: 0.7936\n",
            "Epoch 137/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7638\n",
            "Epoch 138/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5376 - accuracy: 0.7794\n",
            "Epoch 139/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6818 - accuracy: 0.7540\n",
            "Epoch 140/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5413 - accuracy: 0.7750\n",
            "Epoch 141/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5403 - accuracy: 0.7774\n",
            "Epoch 142/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7767\n",
            "Epoch 143/193\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.5638 - accuracy: 0.7664\n",
            "Epoch 144/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.7742\n",
            "Epoch 145/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5946 - accuracy: 0.7631\n",
            "Epoch 146/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5028 - accuracy: 0.7856\n",
            "Epoch 147/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5634 - accuracy: 0.7693\n",
            "Epoch 148/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.7745\n",
            "Epoch 149/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.7717\n",
            "Epoch 150/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6126 - accuracy: 0.7636\n",
            "Epoch 151/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5398 - accuracy: 0.7758\n",
            "Epoch 152/193\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.6779 - accuracy: 0.7489\n",
            "Epoch 153/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6452 - accuracy: 0.7622\n",
            "Epoch 154/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5466 - accuracy: 0.7771\n",
            "Epoch 155/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5658 - accuracy: 0.7704\n",
            "Epoch 156/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5513 - accuracy: 0.7680\n",
            "Epoch 157/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7603 - accuracy: 0.7500\n",
            "Epoch 158/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5754 - accuracy: 0.7711\n",
            "Epoch 159/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5958 - accuracy: 0.7652\n",
            "Epoch 160/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5739 - accuracy: 0.7718\n",
            "Epoch 161/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6695 - accuracy: 0.7602\n",
            "Epoch 162/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5806 - accuracy: 0.7671\n",
            "Epoch 163/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.7810\n",
            "Epoch 164/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6649 - accuracy: 0.7613\n",
            "Epoch 165/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5901 - accuracy: 0.7684\n",
            "Epoch 166/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.7758\n",
            "Epoch 167/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4893 - accuracy: 0.7855\n",
            "Epoch 168/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6960 - accuracy: 0.7557\n",
            "Epoch 169/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7822\n",
            "Epoch 170/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5523 - accuracy: 0.7753\n",
            "Epoch 171/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5623 - accuracy: 0.7711\n",
            "Epoch 172/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7290 - accuracy: 0.7517\n",
            "Epoch 173/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7077 - accuracy: 0.7517\n",
            "Epoch 174/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.7858\n",
            "Epoch 175/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6251 - accuracy: 0.7598\n",
            "Epoch 176/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4893 - accuracy: 0.7858\n",
            "Epoch 177/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5917 - accuracy: 0.7695\n",
            "Epoch 178/193\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.6550 - accuracy: 0.7525\n",
            "Epoch 179/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6460 - accuracy: 0.7632\n",
            "Epoch 180/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6463 - accuracy: 0.7575\n",
            "Epoch 181/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4925 - accuracy: 0.7848\n",
            "Epoch 182/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.7708\n",
            "Epoch 183/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5669 - accuracy: 0.7760\n",
            "Epoch 184/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6502 - accuracy: 0.7605\n",
            "Epoch 185/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5791 - accuracy: 0.7717\n",
            "Epoch 186/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6086 - accuracy: 0.7560\n",
            "Epoch 187/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.7570\n",
            "Epoch 188/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.7774\n",
            "Epoch 189/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.7847\n",
            "Epoch 190/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7869\n",
            "Epoch 191/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6276 - accuracy: 0.7586\n",
            "Epoch 192/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.5461 - accuracy: 0.7705\n",
            "Epoch 193/193\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.6539 - accuracy: 0.7630\n",
            "20/20 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:54:29,080] Trial 14 finished with value: 0.8389830508474576 and parameters: {'xgb__subsample': 0.9876451834239529, 'xgb__scale_pos_weight': 2.65227116375866, 'xgb__reg_lambda': 0.42624425439599856, 'xgb__n_estimators': 489, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.17982068728458964, 'xgb__gamma': 0.1981852080586859, 'xgb__colsample_bytree': 0.7041132706154966, 'rf__n_estimators': 484, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 17, 'rf__max_depth': 4, 'rf__bootstrap': False, 'ann__epochs': 193, 'ann__batch_size': 95, 'ann__learning_rate': 0.009392822547774722}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 5s 19ms/step - loss: 0.4658 - accuracy: 0.7770\n",
            "Epoch 2/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8076\n",
            "Epoch 3/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8125\n",
            "Epoch 4/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8125\n",
            "Epoch 5/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8117\n",
            "Epoch 6/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8122\n",
            "Epoch 7/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8104\n",
            "Epoch 8/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8116\n",
            "Epoch 9/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8133\n",
            "Epoch 10/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8118\n",
            "Epoch 11/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8102\n",
            "Epoch 12/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8100\n",
            "Epoch 13/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8118\n",
            "Epoch 14/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8109\n",
            "Epoch 15/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8120\n",
            "Epoch 16/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8096\n",
            "Epoch 17/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8122\n",
            "Epoch 18/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8101\n",
            "Epoch 19/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8105\n",
            "Epoch 20/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8116\n",
            "Epoch 21/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8113\n",
            "Epoch 22/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8108\n",
            "Epoch 23/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8117\n",
            "Epoch 24/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8130\n",
            "Epoch 25/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8116\n",
            "Epoch 26/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8104\n",
            "Epoch 27/132\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 0.4200 - accuracy: 0.8097\n",
            "Epoch 28/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8108\n",
            "Epoch 29/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8102\n",
            "Epoch 30/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8118\n",
            "Epoch 31/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8122\n",
            "Epoch 32/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8100\n",
            "Epoch 33/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8128\n",
            "Epoch 34/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8108\n",
            "Epoch 35/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8105\n",
            "Epoch 36/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8087\n",
            "Epoch 37/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8105\n",
            "Epoch 38/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8073\n",
            "Epoch 39/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8120\n",
            "Epoch 40/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8116\n",
            "Epoch 41/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8083\n",
            "Epoch 42/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8079\n",
            "Epoch 43/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8110\n",
            "Epoch 44/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8129\n",
            "Epoch 45/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8100\n",
            "Epoch 46/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8116\n",
            "Epoch 47/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8092\n",
            "Epoch 48/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8100\n",
            "Epoch 49/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8092\n",
            "Epoch 50/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8117\n",
            "Epoch 51/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8097\n",
            "Epoch 52/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8114\n",
            "Epoch 53/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8101\n",
            "Epoch 54/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8100\n",
            "Epoch 55/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8104\n",
            "Epoch 56/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8113\n",
            "Epoch 57/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8077\n",
            "Epoch 58/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8106\n",
            "Epoch 59/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8088\n",
            "Epoch 60/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8114\n",
            "Epoch 61/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8072\n",
            "Epoch 62/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8084\n",
            "Epoch 63/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8064\n",
            "Epoch 64/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8102\n",
            "Epoch 65/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8095\n",
            "Epoch 66/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8095\n",
            "Epoch 67/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8069\n",
            "Epoch 68/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8073\n",
            "Epoch 69/132\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 0.4202 - accuracy: 0.8096\n",
            "Epoch 70/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8076\n",
            "Epoch 71/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8121\n",
            "Epoch 72/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8097\n",
            "Epoch 73/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8108\n",
            "Epoch 74/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8121\n",
            "Epoch 75/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8091\n",
            "Epoch 76/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8092\n",
            "Epoch 77/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8105\n",
            "Epoch 78/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8076\n",
            "Epoch 79/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8118\n",
            "Epoch 80/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8073\n",
            "Epoch 81/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8128\n",
            "Epoch 82/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8075\n",
            "Epoch 83/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8104\n",
            "Epoch 84/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8109\n",
            "Epoch 85/132\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8091\n",
            "Epoch 86/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8104\n",
            "Epoch 87/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8109\n",
            "Epoch 88/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8077\n",
            "Epoch 89/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8118\n",
            "Epoch 90/132\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 0.4242 - accuracy: 0.8073\n",
            "Epoch 91/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8105\n",
            "Epoch 92/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8104\n",
            "Epoch 93/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8088\n",
            "Epoch 94/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8101\n",
            "Epoch 95/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8116\n",
            "Epoch 96/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8065\n",
            "Epoch 97/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8079\n",
            "Epoch 98/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8102\n",
            "Epoch 99/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8095\n",
            "Epoch 100/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8095\n",
            "Epoch 101/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8077\n",
            "Epoch 102/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8097\n",
            "Epoch 103/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8095\n",
            "Epoch 104/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8091\n",
            "Epoch 105/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8076\n",
            "Epoch 106/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8112\n",
            "Epoch 107/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8092\n",
            "Epoch 108/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8101\n",
            "Epoch 109/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8099\n",
            "Epoch 110/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8071\n",
            "Epoch 111/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8100\n",
            "Epoch 112/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8089\n",
            "Epoch 113/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8075\n",
            "Epoch 114/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8064\n",
            "Epoch 115/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8108\n",
            "Epoch 116/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8083\n",
            "Epoch 117/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8072\n",
            "Epoch 118/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8099\n",
            "Epoch 119/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8093\n",
            "Epoch 120/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8124\n",
            "Epoch 121/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8100\n",
            "Epoch 122/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8089\n",
            "Epoch 123/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8102\n",
            "Epoch 124/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8088\n",
            "Epoch 125/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8075\n",
            "Epoch 126/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8085\n",
            "Epoch 127/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8083\n",
            "Epoch 128/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8092\n",
            "Epoch 129/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8102\n",
            "Epoch 130/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8108\n",
            "Epoch 131/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8076\n",
            "Epoch 132/132\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8084\n",
            "35/35 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:56:41,624] Trial 15 finished with value: 0.8654661016949152 and parameters: {'xgb__subsample': 0.6950249679974813, 'xgb__scale_pos_weight': 2.7080190363752976, 'xgb__reg_lambda': 1.9992429691787816, 'xgb__n_estimators': 822, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.06613644475520926, 'xgb__gamma': 0.12014161705259714, 'xgb__colsample_bytree': 0.9889032044479069, 'rf__n_estimators': 215, 'rf__min_samples_split': 12, 'rf__min_samples_leaf': 4, 'rf__max_depth': 1, 'rf__bootstrap': False, 'ann__epochs': 132, 'ann__batch_size': 55, 'ann__learning_rate': 0.0008234957558924858}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 5s 21ms/step - loss: 0.4354 - accuracy: 0.7993\n",
            "Epoch 2/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.7985\n",
            "Epoch 3/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.7958\n",
            "Epoch 4/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.7989\n",
            "Epoch 5/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.7959\n",
            "Epoch 6/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.7965\n",
            "Epoch 7/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4655 - accuracy: 0.7887\n",
            "Epoch 8/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.7971\n",
            "Epoch 9/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.7983\n",
            "Epoch 10/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4564 - accuracy: 0.7941\n",
            "Epoch 11/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4799 - accuracy: 0.7851\n",
            "Epoch 12/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4464 - accuracy: 0.7957\n",
            "Epoch 13/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.7912\n",
            "Epoch 14/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4801 - accuracy: 0.7864\n",
            "Epoch 15/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.4769 - accuracy: 0.7850\n",
            "Epoch 16/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.4710 - accuracy: 0.7872\n",
            "Epoch 17/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4724 - accuracy: 0.7896\n",
            "Epoch 18/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7926\n",
            "Epoch 19/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.7777\n",
            "Epoch 20/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4621 - accuracy: 0.7917\n",
            "Epoch 21/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5280 - accuracy: 0.7762\n",
            "Epoch 22/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4753 - accuracy: 0.7859\n",
            "Epoch 23/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.7883\n",
            "Epoch 24/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.4960 - accuracy: 0.7831\n",
            "Epoch 25/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7795\n",
            "Epoch 26/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5000 - accuracy: 0.7778\n",
            "Epoch 27/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5190 - accuracy: 0.7726\n",
            "Epoch 28/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4952 - accuracy: 0.7801\n",
            "Epoch 29/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5649 - accuracy: 0.7699\n",
            "Epoch 30/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7712\n",
            "Epoch 31/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4956 - accuracy: 0.7839\n",
            "Epoch 32/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4940 - accuracy: 0.7836\n",
            "Epoch 33/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5102 - accuracy: 0.7782\n",
            "Epoch 34/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4806 - accuracy: 0.7885\n",
            "Epoch 35/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7842\n",
            "Epoch 36/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.7799\n",
            "Epoch 37/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7692\n",
            "Epoch 38/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.7753\n",
            "Epoch 39/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5113 - accuracy: 0.7856\n",
            "Epoch 40/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7737\n",
            "Epoch 41/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5842 - accuracy: 0.7622\n",
            "Epoch 42/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.7732\n",
            "Epoch 43/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5163 - accuracy: 0.7786\n",
            "Epoch 44/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5118 - accuracy: 0.7786\n",
            "Epoch 45/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.7835\n",
            "Epoch 46/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5247 - accuracy: 0.7830\n",
            "Epoch 47/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.7799\n",
            "Epoch 48/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5126 - accuracy: 0.7809\n",
            "Epoch 49/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5822 - accuracy: 0.7619\n",
            "Epoch 50/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5798 - accuracy: 0.7610\n",
            "Epoch 51/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5772 - accuracy: 0.7703\n",
            "Epoch 52/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.7742\n",
            "Epoch 53/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5891 - accuracy: 0.7605\n",
            "Epoch 54/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7744\n",
            "Epoch 55/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7744\n",
            "Epoch 56/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7689\n",
            "Epoch 57/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.7724\n",
            "Epoch 58/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5015 - accuracy: 0.7834\n",
            "Epoch 59/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5355 - accuracy: 0.7761\n",
            "Epoch 60/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7728\n",
            "Epoch 61/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5750 - accuracy: 0.7656\n",
            "Epoch 62/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.7765\n",
            "Epoch 63/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.7823\n",
            "Epoch 64/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6538 - accuracy: 0.7655\n",
            "Epoch 65/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6157 - accuracy: 0.7656\n",
            "Epoch 66/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7623\n",
            "Epoch 67/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.7721\n",
            "Epoch 68/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7433 - accuracy: 0.7538\n",
            "Epoch 69/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5527 - accuracy: 0.7720\n",
            "Epoch 70/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5292 - accuracy: 0.7794\n",
            "Epoch 71/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7717\n",
            "Epoch 72/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7717\n",
            "Epoch 73/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5286 - accuracy: 0.7775\n",
            "Epoch 74/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6869 - accuracy: 0.7549\n",
            "Epoch 75/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5802 - accuracy: 0.7697\n",
            "Epoch 76/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5257 - accuracy: 0.7801\n",
            "Epoch 77/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5939 - accuracy: 0.7648\n",
            "Epoch 78/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.4999 - accuracy: 0.7865\n",
            "Epoch 79/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.7761\n",
            "Epoch 80/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5789 - accuracy: 0.7644\n",
            "Epoch 81/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.7724\n",
            "Epoch 82/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7757\n",
            "Epoch 83/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7721\n",
            "Epoch 84/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5547 - accuracy: 0.7681\n",
            "Epoch 85/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.7685\n",
            "Epoch 86/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6732 - accuracy: 0.7560\n",
            "Epoch 87/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5801 - accuracy: 0.7730\n",
            "Epoch 88/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7672\n",
            "Epoch 89/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5706 - accuracy: 0.7666\n",
            "Epoch 90/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6443 - accuracy: 0.7630\n",
            "Epoch 91/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5801 - accuracy: 0.7718\n",
            "Epoch 92/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7786\n",
            "Epoch 93/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5588 - accuracy: 0.7676\n",
            "Epoch 94/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6848 - accuracy: 0.7485\n",
            "Epoch 95/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6219 - accuracy: 0.7666\n",
            "Epoch 96/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5708 - accuracy: 0.7647\n",
            "Epoch 97/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6158 - accuracy: 0.7598\n",
            "Epoch 98/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5976 - accuracy: 0.7708\n",
            "Epoch 99/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5921 - accuracy: 0.7664\n",
            "Epoch 100/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6367 - accuracy: 0.7630\n",
            "Epoch 101/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7904 - accuracy: 0.7529\n",
            "Epoch 102/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6442 - accuracy: 0.7562\n",
            "Epoch 103/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5684 - accuracy: 0.7671\n",
            "Epoch 104/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5889 - accuracy: 0.7685\n",
            "Epoch 105/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5751 - accuracy: 0.7684\n",
            "Epoch 106/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6333 - accuracy: 0.7597\n",
            "Epoch 107/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6138 - accuracy: 0.7575\n",
            "Epoch 108/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5783 - accuracy: 0.7691\n",
            "Epoch 109/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5497 - accuracy: 0.7708\n",
            "Epoch 110/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5741 - accuracy: 0.7673\n",
            "Epoch 111/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6275 - accuracy: 0.7615\n",
            "Epoch 112/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5837 - accuracy: 0.7664\n",
            "Epoch 113/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6909 - accuracy: 0.7488\n",
            "Epoch 114/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6256 - accuracy: 0.7603\n",
            "Epoch 115/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5864 - accuracy: 0.7745\n",
            "Epoch 116/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6566 - accuracy: 0.7570\n",
            "Epoch 117/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7225 - accuracy: 0.7533\n",
            "Epoch 118/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6260 - accuracy: 0.7660\n",
            "Epoch 119/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6015 - accuracy: 0.7658\n",
            "Epoch 120/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5804 - accuracy: 0.7736\n",
            "Epoch 121/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6965 - accuracy: 0.7517\n",
            "Epoch 122/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5713 - accuracy: 0.7709\n",
            "Epoch 123/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6064 - accuracy: 0.7704\n",
            "Epoch 124/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6471 - accuracy: 0.7505\n",
            "Epoch 125/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5930 - accuracy: 0.7675\n",
            "Epoch 126/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5932 - accuracy: 0.7597\n",
            "Epoch 127/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6953 - accuracy: 0.7564\n",
            "Epoch 128/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5819 - accuracy: 0.7713\n",
            "Epoch 129/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6108 - accuracy: 0.7642\n",
            "Epoch 130/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.7654\n",
            "Epoch 131/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5457 - accuracy: 0.7748\n",
            "Epoch 132/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5717 - accuracy: 0.7668\n",
            "Epoch 133/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6272 - accuracy: 0.7687\n",
            "Epoch 134/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6638 - accuracy: 0.7598\n",
            "Epoch 135/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7209 - accuracy: 0.7656\n",
            "Epoch 136/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6830 - accuracy: 0.7603\n",
            "Epoch 137/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6829 - accuracy: 0.7556\n",
            "Epoch 138/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6081 - accuracy: 0.7677\n",
            "Epoch 139/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6772 - accuracy: 0.7556\n",
            "Epoch 140/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6236 - accuracy: 0.7656\n",
            "Epoch 141/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7664\n",
            "Epoch 142/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7219 - accuracy: 0.7545\n",
            "Epoch 143/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6987 - accuracy: 0.7573\n",
            "Epoch 144/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7102 - accuracy: 0.7613\n",
            "Epoch 145/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7831 - accuracy: 0.7483\n",
            "Epoch 146/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.7685\n",
            "Epoch 147/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7678 - accuracy: 0.7524\n",
            "Epoch 148/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.7544\n",
            "Epoch 149/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7064 - accuracy: 0.7617\n",
            "Epoch 150/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6694 - accuracy: 0.7572\n",
            "Epoch 151/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6632 - accuracy: 0.7582\n",
            "Epoch 152/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6855 - accuracy: 0.7554\n",
            "Epoch 153/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5633 - accuracy: 0.7725\n",
            "Epoch 154/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6874 - accuracy: 0.7626\n",
            "Epoch 155/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.7055 - accuracy: 0.7569\n",
            "Epoch 156/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6627 - accuracy: 0.7617\n",
            "Epoch 157/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6443 - accuracy: 0.7631\n",
            "Epoch 158/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7338 - accuracy: 0.7511\n",
            "Epoch 159/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7104 - accuracy: 0.7574\n",
            "Epoch 160/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7668 - accuracy: 0.7487\n",
            "Epoch 161/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.8110 - accuracy: 0.7553\n",
            "Epoch 162/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5855 - accuracy: 0.7643\n",
            "Epoch 163/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7092 - accuracy: 0.7611\n",
            "Epoch 164/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6605 - accuracy: 0.7581\n",
            "Epoch 165/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7594 - accuracy: 0.7537\n",
            "Epoch 166/172\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.6451 - accuracy: 0.7607\n",
            "Epoch 167/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7464 - accuracy: 0.7507\n",
            "Epoch 168/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6387 - accuracy: 0.7603\n",
            "Epoch 169/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7603 - accuracy: 0.7467\n",
            "Epoch 170/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.6748 - accuracy: 0.7646\n",
            "Epoch 171/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.7456 - accuracy: 0.7558\n",
            "Epoch 172/172\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5489 - accuracy: 0.7778\n",
            "32/32 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 16:59:15,953] Trial 16 finished with value: 0.8310381355932204 and parameters: {'xgb__subsample': 0.8984831835758813, 'xgb__scale_pos_weight': 3.7463110546781566, 'xgb__reg_lambda': 4.519347751919695, 'xgb__n_estimators': 731, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.15634692717182067, 'xgb__gamma': 0.9585999907324434, 'xgb__colsample_bytree': 0.6662180113904742, 'rf__n_estimators': 112, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 1, 'rf__max_depth': 3, 'rf__bootstrap': False, 'ann__epochs': 172, 'ann__batch_size': 60, 'ann__learning_rate': 0.011404525346809694}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83/83 [==============================] - 5s 27ms/step - loss: 0.5854 - accuracy: 0.7268\n",
            "Epoch 2/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5773 - accuracy: 0.7293\n",
            "Epoch 3/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.7327\n",
            "Epoch 4/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5629 - accuracy: 0.7344\n",
            "Epoch 5/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5566 - accuracy: 0.7369\n",
            "Epoch 6/133\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.5509 - accuracy: 0.7401\n",
            "Epoch 7/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5457 - accuracy: 0.7415\n",
            "Epoch 8/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7451\n",
            "Epoch 9/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7463\n",
            "Epoch 10/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7489\n",
            "Epoch 11/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.7493\n",
            "Epoch 12/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7496\n",
            "Epoch 13/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7503\n",
            "Epoch 14/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5172 - accuracy: 0.7519\n",
            "Epoch 15/133\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.5140 - accuracy: 0.7534\n",
            "Epoch 16/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.5109 - accuracy: 0.7541\n",
            "Epoch 17/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.7557\n",
            "Epoch 18/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5052 - accuracy: 0.7568\n",
            "Epoch 19/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7583\n",
            "Epoch 20/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.5001 - accuracy: 0.7593\n",
            "Epoch 21/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4976 - accuracy: 0.7609\n",
            "Epoch 22/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4953 - accuracy: 0.7622\n",
            "Epoch 23/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.7626\n",
            "Epoch 24/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4909 - accuracy: 0.7638\n",
            "Epoch 25/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4887 - accuracy: 0.7647\n",
            "Epoch 26/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4867 - accuracy: 0.7662\n",
            "Epoch 27/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.7668\n",
            "Epoch 28/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4829 - accuracy: 0.7675\n",
            "Epoch 29/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4811 - accuracy: 0.7679\n",
            "Epoch 30/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4793 - accuracy: 0.7692\n",
            "Epoch 31/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4775 - accuracy: 0.7705\n",
            "Epoch 32/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4758 - accuracy: 0.7705\n",
            "Epoch 33/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4742 - accuracy: 0.7717\n",
            "Epoch 34/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4727 - accuracy: 0.7730\n",
            "Epoch 35/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.7740\n",
            "Epoch 36/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4698 - accuracy: 0.7745\n",
            "Epoch 37/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7758\n",
            "Epoch 38/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4670 - accuracy: 0.7766\n",
            "Epoch 39/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4657 - accuracy: 0.7770\n",
            "Epoch 40/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4644 - accuracy: 0.7775\n",
            "Epoch 41/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4631 - accuracy: 0.7793\n",
            "Epoch 42/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7807\n",
            "Epoch 43/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4607 - accuracy: 0.7822\n",
            "Epoch 44/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4595 - accuracy: 0.7824\n",
            "Epoch 45/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4584 - accuracy: 0.7838\n",
            "Epoch 46/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.7847\n",
            "Epoch 47/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4562 - accuracy: 0.7858\n",
            "Epoch 48/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7867\n",
            "Epoch 49/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.7884\n",
            "Epoch 50/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.7891\n",
            "Epoch 51/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.7900\n",
            "Epoch 52/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.7905\n",
            "Epoch 53/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.7909\n",
            "Epoch 54/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4495 - accuracy: 0.7918\n",
            "Epoch 55/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4487 - accuracy: 0.7922\n",
            "Epoch 56/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7925\n",
            "Epoch 57/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.7929\n",
            "Epoch 58/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.7933\n",
            "Epoch 59/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4455 - accuracy: 0.7936\n",
            "Epoch 60/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4448 - accuracy: 0.7944\n",
            "Epoch 61/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.7952\n",
            "Epoch 62/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.7961\n",
            "Epoch 63/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4428 - accuracy: 0.7963\n",
            "Epoch 64/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.7967\n",
            "Epoch 65/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4415 - accuracy: 0.7978\n",
            "Epoch 66/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.7986\n",
            "Epoch 67/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.7986\n",
            "Epoch 68/133\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.4398 - accuracy: 0.7987\n",
            "Epoch 69/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.7994\n",
            "Epoch 70/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.7998\n",
            "Epoch 71/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.7997\n",
            "Epoch 72/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8001\n",
            "Epoch 73/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.8005\n",
            "Epoch 74/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8003\n",
            "Epoch 75/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4363 - accuracy: 0.8008\n",
            "Epoch 76/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.8005\n",
            "Epoch 77/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4355 - accuracy: 0.8016\n",
            "Epoch 78/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8016\n",
            "Epoch 79/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8019\n",
            "Epoch 80/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4342 - accuracy: 0.8018\n",
            "Epoch 81/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.8022\n",
            "Epoch 82/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.8028\n",
            "Epoch 83/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8034\n",
            "Epoch 84/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4328 - accuracy: 0.8032\n",
            "Epoch 85/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8036\n",
            "Epoch 86/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8035\n",
            "Epoch 87/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8039\n",
            "Epoch 88/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8038\n",
            "Epoch 89/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8038\n",
            "Epoch 90/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8038\n",
            "Epoch 91/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8036\n",
            "Epoch 92/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8042\n",
            "Epoch 93/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8043\n",
            "Epoch 94/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8044\n",
            "Epoch 95/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4294 - accuracy: 0.8044\n",
            "Epoch 96/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8047\n",
            "Epoch 97/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8044\n",
            "Epoch 98/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8040\n",
            "Epoch 99/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8040\n",
            "Epoch 100/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8042\n",
            "Epoch 101/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8040\n",
            "Epoch 102/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8040\n",
            "Epoch 103/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8043\n",
            "Epoch 104/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8046\n",
            "Epoch 105/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8047\n",
            "Epoch 106/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8048\n",
            "Epoch 107/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8050\n",
            "Epoch 108/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8050\n",
            "Epoch 109/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8050\n",
            "Epoch 110/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8046\n",
            "Epoch 111/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8047\n",
            "Epoch 112/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8047\n",
            "Epoch 113/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4255 - accuracy: 0.8051\n",
            "Epoch 114/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4254 - accuracy: 0.8055\n",
            "Epoch 115/133\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.4252 - accuracy: 0.8057\n",
            "Epoch 116/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.8060\n",
            "Epoch 117/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.8060\n",
            "Epoch 118/133\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4247 - accuracy: 0.8061\n",
            "Epoch 119/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8057\n",
            "Epoch 120/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8061\n",
            "Epoch 121/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8060\n",
            "Epoch 122/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8065\n",
            "Epoch 123/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8067\n",
            "Epoch 124/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8068\n",
            "Epoch 125/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8065\n",
            "Epoch 126/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8064\n",
            "Epoch 127/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.8065\n",
            "Epoch 128/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8063\n",
            "Epoch 129/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8064\n",
            "Epoch 130/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8064\n",
            "Epoch 131/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8064\n",
            "Epoch 132/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8068\n",
            "Epoch 133/133\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8075\n",
            "21/21 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:00:40,039] Trial 17 finished with value: 0.8379237288135594 and parameters: {'xgb__subsample': 0.7336242598061354, 'xgb__scale_pos_weight': 1.6946669768022522, 'xgb__reg_lambda': 2.08126594611339, 'xgb__n_estimators': 548, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.055076413726981105, 'xgb__gamma': 0.10345668642311799, 'xgb__colsample_bytree': 0.864783427328954, 'rf__n_estimators': 1000, 'rf__min_samples_split': 11, 'rf__min_samples_leaf': 15, 'rf__max_depth': 2, 'rf__bootstrap': False, 'ann__epochs': 133, 'ann__batch_size': 92, 'ann__learning_rate': 1.1969062590495695e-05}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "81/81 [==============================] - 5s 28ms/step - loss: 0.6856 - accuracy: 0.5934\n",
            "Epoch 2/86\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.5085 - accuracy: 0.7556\n",
            "Epoch 3/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4618 - accuracy: 0.7854\n",
            "Epoch 4/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4430 - accuracy: 0.7933\n",
            "Epoch 5/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4333 - accuracy: 0.8014\n",
            "Epoch 6/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4275 - accuracy: 0.8046\n",
            "Epoch 7/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4240 - accuracy: 0.8069\n",
            "Epoch 8/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.8099\n",
            "Epoch 9/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8084\n",
            "Epoch 10/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4198 - accuracy: 0.8110\n",
            "Epoch 11/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8105\n",
            "Epoch 12/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8114\n",
            "Epoch 13/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8117\n",
            "Epoch 14/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8118\n",
            "Epoch 15/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8122\n",
            "Epoch 16/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8118\n",
            "Epoch 17/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8144\n",
            "Epoch 18/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8120\n",
            "Epoch 19/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4185 - accuracy: 0.8117\n",
            "Epoch 20/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8120\n",
            "Epoch 21/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8125\n",
            "Epoch 22/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8114\n",
            "Epoch 23/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8124\n",
            "Epoch 24/86\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.4179 - accuracy: 0.8109\n",
            "Epoch 25/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4180 - accuracy: 0.8126\n",
            "Epoch 26/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4179 - accuracy: 0.8121\n",
            "Epoch 27/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8121\n",
            "Epoch 28/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4179 - accuracy: 0.8113\n",
            "Epoch 29/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8124\n",
            "Epoch 30/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8117\n",
            "Epoch 31/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8124\n",
            "Epoch 32/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.8110\n",
            "Epoch 33/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8109\n",
            "Epoch 34/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8120\n",
            "Epoch 35/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8106\n",
            "Epoch 36/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4184 - accuracy: 0.8108\n",
            "Epoch 37/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8113\n",
            "Epoch 38/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8116\n",
            "Epoch 39/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8122\n",
            "Epoch 40/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4178 - accuracy: 0.8117\n",
            "Epoch 41/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8126\n",
            "Epoch 42/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8105\n",
            "Epoch 43/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8113\n",
            "Epoch 44/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8109\n",
            "Epoch 45/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8112\n",
            "Epoch 46/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8109\n",
            "Epoch 47/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8112\n",
            "Epoch 48/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8118\n",
            "Epoch 49/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8117\n",
            "Epoch 50/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8132\n",
            "Epoch 51/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8120\n",
            "Epoch 52/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8106\n",
            "Epoch 53/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8121\n",
            "Epoch 54/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8118\n",
            "Epoch 55/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8108\n",
            "Epoch 56/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8140\n",
            "Epoch 57/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8116\n",
            "Epoch 58/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4180 - accuracy: 0.8113\n",
            "Epoch 59/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8106\n",
            "Epoch 60/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4183 - accuracy: 0.8122\n",
            "Epoch 61/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8105\n",
            "Epoch 62/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8128\n",
            "Epoch 63/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8114\n",
            "Epoch 64/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8125\n",
            "Epoch 65/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4181 - accuracy: 0.8106\n",
            "Epoch 66/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8122\n",
            "Epoch 67/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4183 - accuracy: 0.8118\n",
            "Epoch 68/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8117\n",
            "Epoch 69/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8126\n",
            "Epoch 70/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8120\n",
            "Epoch 71/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4180 - accuracy: 0.8113\n",
            "Epoch 72/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8122\n",
            "Epoch 73/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8124\n",
            "Epoch 74/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8128\n",
            "Epoch 75/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8124\n",
            "Epoch 76/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8118\n",
            "Epoch 77/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8124\n",
            "Epoch 78/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8112\n",
            "Epoch 79/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8128\n",
            "Epoch 80/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8112\n",
            "Epoch 81/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8114\n",
            "Epoch 82/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8105\n",
            "Epoch 83/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8112\n",
            "Epoch 84/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8116\n",
            "Epoch 85/86\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8128\n",
            "Epoch 86/86\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.4180 - accuracy: 0.8116\n",
            "21/21 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:01:38,512] Trial 18 finished with value: 0.864406779661017 and parameters: {'xgb__subsample': 0.8934171115567722, 'xgb__scale_pos_weight': 2.009092160742322, 'xgb__reg_lambda': 1.6341148385721318, 'xgb__n_estimators': 859, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.10999325970626125, 'xgb__gamma': 0.32605929290880387, 'xgb__colsample_bytree': 0.6682331818186819, 'rf__n_estimators': 460, 'rf__min_samples_split': 14, 'rf__min_samples_leaf': 6, 'rf__max_depth': 4, 'rf__bootstrap': False, 'ann__epochs': 86, 'ann__batch_size': 94, 'ann__learning_rate': 0.0003564788674411222}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 5s 35ms/step - loss: 0.4593 - accuracy: 0.7843\n",
            "Epoch 2/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4234 - accuracy: 0.8076\n",
            "Epoch 3/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4212 - accuracy: 0.8112\n",
            "Epoch 4/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4218 - accuracy: 0.8108\n",
            "Epoch 5/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4242 - accuracy: 0.8089\n",
            "Epoch 6/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4236 - accuracy: 0.8081\n",
            "Epoch 7/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8091\n",
            "Epoch 8/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8068\n",
            "Epoch 9/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.8092\n",
            "Epoch 10/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4239 - accuracy: 0.8067\n",
            "Epoch 11/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8083\n",
            "Epoch 12/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8083\n",
            "Epoch 13/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.8069\n",
            "Epoch 14/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.8092\n",
            "Epoch 15/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8083\n",
            "Epoch 16/133\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.4247 - accuracy: 0.8095\n",
            "Epoch 17/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4242 - accuracy: 0.8087\n",
            "Epoch 18/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8046\n",
            "Epoch 19/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8061\n",
            "Epoch 20/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4257 - accuracy: 0.8053\n",
            "Epoch 21/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4278 - accuracy: 0.8039\n",
            "Epoch 22/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.8050\n",
            "Epoch 23/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8102\n",
            "Epoch 24/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7998\n",
            "Epoch 25/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8073\n",
            "Epoch 26/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.8076\n",
            "Epoch 27/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4300 - accuracy: 0.8043\n",
            "Epoch 28/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.8020\n",
            "Epoch 29/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8057\n",
            "Epoch 30/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.8042\n",
            "Epoch 31/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8063\n",
            "Epoch 32/133\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.4345 - accuracy: 0.8044\n",
            "Epoch 33/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4363 - accuracy: 0.8019\n",
            "Epoch 34/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4283 - accuracy: 0.8072\n",
            "Epoch 35/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8040\n",
            "Epoch 36/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8020\n",
            "Epoch 37/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8050\n",
            "Epoch 38/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.8038\n",
            "Epoch 39/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8073\n",
            "Epoch 40/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7998\n",
            "Epoch 41/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8081\n",
            "Epoch 42/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8016\n",
            "Epoch 43/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8068\n",
            "Epoch 44/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8051\n",
            "Epoch 45/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8007\n",
            "Epoch 46/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8015\n",
            "Epoch 47/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8064\n",
            "Epoch 48/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.8023\n",
            "Epoch 49/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.8023\n",
            "Epoch 50/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8031\n",
            "Epoch 51/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7973\n",
            "Epoch 52/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8012\n",
            "Epoch 53/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8053\n",
            "Epoch 54/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8060\n",
            "Epoch 55/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7998\n",
            "Epoch 56/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8035\n",
            "Epoch 57/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8024\n",
            "Epoch 58/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8052\n",
            "Epoch 59/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.8022\n",
            "Epoch 60/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8005\n",
            "Epoch 61/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8027\n",
            "Epoch 62/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4374 - accuracy: 0.7986\n",
            "Epoch 63/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4407 - accuracy: 0.8052\n",
            "Epoch 64/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4392 - accuracy: 0.8027\n",
            "Epoch 65/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4389 - accuracy: 0.8030\n",
            "Epoch 66/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.8040\n",
            "Epoch 67/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8059\n",
            "Epoch 68/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7956\n",
            "Epoch 69/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.8030\n",
            "Epoch 70/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8002\n",
            "Epoch 71/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8039\n",
            "Epoch 72/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7993\n",
            "Epoch 73/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8016\n",
            "Epoch 74/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8014\n",
            "Epoch 75/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7975\n",
            "Epoch 76/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7933\n",
            "Epoch 77/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8006\n",
            "Epoch 78/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.8027\n",
            "Epoch 79/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.8059\n",
            "Epoch 80/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.8006\n",
            "Epoch 81/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7979\n",
            "Epoch 82/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8006\n",
            "Epoch 83/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.8003\n",
            "Epoch 84/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8002\n",
            "Epoch 85/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8012\n",
            "Epoch 86/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8072\n",
            "Epoch 87/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7903\n",
            "Epoch 88/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8003\n",
            "Epoch 89/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8010\n",
            "Epoch 90/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8080\n",
            "Epoch 91/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7978\n",
            "Epoch 92/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8023\n",
            "Epoch 93/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7971\n",
            "Epoch 94/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.8016\n",
            "Epoch 95/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7977\n",
            "Epoch 96/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8034\n",
            "Epoch 97/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7961\n",
            "Epoch 98/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.8044\n",
            "Epoch 99/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7994\n",
            "Epoch 100/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7993\n",
            "Epoch 101/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7928\n",
            "Epoch 102/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.7967\n",
            "Epoch 103/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7949\n",
            "Epoch 104/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.8048\n",
            "Epoch 105/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7961\n",
            "Epoch 106/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7977\n",
            "Epoch 107/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.8007\n",
            "Epoch 108/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7908\n",
            "Epoch 109/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7926\n",
            "Epoch 110/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8023\n",
            "Epoch 111/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7989\n",
            "Epoch 112/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8040\n",
            "Epoch 113/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7974\n",
            "Epoch 114/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7975\n",
            "Epoch 115/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.8035\n",
            "Epoch 116/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7987\n",
            "Epoch 117/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8063\n",
            "Epoch 118/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7836\n",
            "Epoch 119/133\n",
            "65/65 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.8034\n",
            "Epoch 120/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7995\n",
            "Epoch 121/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7956\n",
            "Epoch 122/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.8060\n",
            "Epoch 123/133\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.4511 - accuracy: 0.7995\n",
            "Epoch 124/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4857 - accuracy: 0.7861\n",
            "Epoch 125/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7971\n",
            "Epoch 126/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7957\n",
            "Epoch 127/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.8015\n",
            "Epoch 128/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8040\n",
            "Epoch 129/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8022\n",
            "Epoch 130/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7994\n",
            "Epoch 131/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7991\n",
            "Epoch 132/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.8012\n",
            "Epoch 133/133\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7978\n",
            "17/17 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:02:46,934] Trial 19 finished with value: 0.8591101694915254 and parameters: {'xgb__subsample': 0.9028649723799559, 'xgb__scale_pos_weight': 3.2035942993251103, 'xgb__reg_lambda': 0.3178429359348218, 'xgb__n_estimators': 907, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.12027872127535497, 'xgb__gamma': 0.003062622459196262, 'xgb__colsample_bytree': 0.9149744197310914, 'rf__n_estimators': 232, 'rf__min_samples_split': 6, 'rf__min_samples_leaf': 3, 'rf__max_depth': 1, 'rf__bootstrap': False, 'ann__epochs': 133, 'ann__batch_size': 117, 'ann__learning_rate': 0.0037527230694106026}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 5s 21ms/step - loss: 0.5777 - accuracy: 0.6950\n",
            "Epoch 2/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4459 - accuracy: 0.7903\n",
            "Epoch 3/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8010\n",
            "Epoch 4/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8055\n",
            "Epoch 5/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8096\n",
            "Epoch 6/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8092\n",
            "Epoch 7/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8112\n",
            "Epoch 8/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8118\n",
            "Epoch 9/175\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 0.4186 - accuracy: 0.8122\n",
            "Epoch 10/175\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 0.4188 - accuracy: 0.8114\n",
            "Epoch 11/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8128\n",
            "Epoch 12/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8108\n",
            "Epoch 13/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8118\n",
            "Epoch 14/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8130\n",
            "Epoch 15/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8140\n",
            "Epoch 16/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8136\n",
            "Epoch 17/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8112\n",
            "Epoch 18/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8106\n",
            "Epoch 19/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8128\n",
            "Epoch 20/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8102\n",
            "Epoch 21/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8100\n",
            "Epoch 22/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8118\n",
            "Epoch 23/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8080\n",
            "Epoch 24/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8124\n",
            "Epoch 25/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8121\n",
            "Epoch 26/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4193 - accuracy: 0.8114\n",
            "Epoch 27/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8114\n",
            "Epoch 28/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.8137\n",
            "Epoch 29/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8129\n",
            "Epoch 30/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8100\n",
            "Epoch 31/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8114\n",
            "Epoch 32/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8130\n",
            "Epoch 33/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8114\n",
            "Epoch 34/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.8108\n",
            "Epoch 35/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8105\n",
            "Epoch 36/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8116\n",
            "Epoch 37/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8133\n",
            "Epoch 38/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8108\n",
            "Epoch 39/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8099\n",
            "Epoch 40/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8099\n",
            "Epoch 41/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8095\n",
            "Epoch 42/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8114\n",
            "Epoch 43/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8096\n",
            "Epoch 44/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8108\n",
            "Epoch 45/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8128\n",
            "Epoch 46/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8109\n",
            "Epoch 47/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8116\n",
            "Epoch 48/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4188 - accuracy: 0.8132\n",
            "Epoch 49/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4188 - accuracy: 0.8108\n",
            "Epoch 50/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8118\n",
            "Epoch 51/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8108\n",
            "Epoch 52/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8125\n",
            "Epoch 53/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8113\n",
            "Epoch 54/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8122\n",
            "Epoch 55/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4192 - accuracy: 0.8136\n",
            "Epoch 56/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8121\n",
            "Epoch 57/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4197 - accuracy: 0.8117\n",
            "Epoch 58/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4192 - accuracy: 0.8121\n",
            "Epoch 59/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8120\n",
            "Epoch 60/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4194 - accuracy: 0.8124\n",
            "Epoch 61/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4188 - accuracy: 0.8088\n",
            "Epoch 62/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8122\n",
            "Epoch 63/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4196 - accuracy: 0.8118\n",
            "Epoch 64/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8101\n",
            "Epoch 65/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.8142\n",
            "Epoch 66/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8106\n",
            "Epoch 67/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8118\n",
            "Epoch 68/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8114\n",
            "Epoch 69/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8092\n",
            "Epoch 70/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8105\n",
            "Epoch 71/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8117\n",
            "Epoch 72/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8099\n",
            "Epoch 73/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8120\n",
            "Epoch 74/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8108\n",
            "Epoch 75/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8105\n",
            "Epoch 76/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4193 - accuracy: 0.8095\n",
            "Epoch 77/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8118\n",
            "Epoch 78/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8120\n",
            "Epoch 79/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4194 - accuracy: 0.8124\n",
            "Epoch 80/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8124\n",
            "Epoch 81/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8138\n",
            "Epoch 82/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8092\n",
            "Epoch 83/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8088\n",
            "Epoch 84/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8109\n",
            "Epoch 85/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8104\n",
            "Epoch 86/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8120\n",
            "Epoch 87/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4215 - accuracy: 0.8080\n",
            "Epoch 88/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4198 - accuracy: 0.8118\n",
            "Epoch 89/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4201 - accuracy: 0.8102\n",
            "Epoch 90/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4204 - accuracy: 0.8104\n",
            "Epoch 91/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8106\n",
            "Epoch 92/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8100\n",
            "Epoch 93/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4199 - accuracy: 0.8117\n",
            "Epoch 94/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8112\n",
            "Epoch 95/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4200 - accuracy: 0.8092\n",
            "Epoch 96/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8091\n",
            "Epoch 97/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8120\n",
            "Epoch 98/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4203 - accuracy: 0.8122\n",
            "Epoch 99/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4199 - accuracy: 0.8097\n",
            "Epoch 100/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8110\n",
            "Epoch 101/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8124\n",
            "Epoch 102/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8105\n",
            "Epoch 103/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8106\n",
            "Epoch 104/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8109\n",
            "Epoch 105/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8145\n",
            "Epoch 106/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8096\n",
            "Epoch 107/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8105\n",
            "Epoch 108/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8105\n",
            "Epoch 109/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8121\n",
            "Epoch 110/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8125\n",
            "Epoch 111/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8096\n",
            "Epoch 112/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8128\n",
            "Epoch 113/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8099\n",
            "Epoch 114/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8105\n",
            "Epoch 115/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8129\n",
            "Epoch 116/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8102\n",
            "Epoch 117/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8100\n",
            "Epoch 118/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8108\n",
            "Epoch 119/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8102\n",
            "Epoch 120/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8112\n",
            "Epoch 121/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8105\n",
            "Epoch 122/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8108\n",
            "Epoch 123/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8097\n",
            "Epoch 124/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8101\n",
            "Epoch 125/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8112\n",
            "Epoch 126/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8099\n",
            "Epoch 127/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8109\n",
            "Epoch 128/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8092\n",
            "Epoch 129/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8093\n",
            "Epoch 130/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8134\n",
            "Epoch 131/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8112\n",
            "Epoch 132/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8110\n",
            "Epoch 133/175\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.4198 - accuracy: 0.8116\n",
            "Epoch 134/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8136\n",
            "Epoch 135/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8097\n",
            "Epoch 136/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8113\n",
            "Epoch 137/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8133\n",
            "Epoch 138/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8120\n",
            "Epoch 139/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8091\n",
            "Epoch 140/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8083\n",
            "Epoch 141/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8095\n",
            "Epoch 142/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8120\n",
            "Epoch 143/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8106\n",
            "Epoch 144/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8089\n",
            "Epoch 145/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8100\n",
            "Epoch 146/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8100\n",
            "Epoch 147/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8095\n",
            "Epoch 148/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8121\n",
            "Epoch 149/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8117\n",
            "Epoch 150/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8108\n",
            "Epoch 151/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8097\n",
            "Epoch 152/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8113\n",
            "Epoch 153/175\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.4202 - accuracy: 0.8100\n",
            "Epoch 154/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8091\n",
            "Epoch 155/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8105\n",
            "Epoch 156/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8096\n",
            "Epoch 157/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8114\n",
            "Epoch 158/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8069\n",
            "Epoch 159/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8113\n",
            "Epoch 160/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8067\n",
            "Epoch 161/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8085\n",
            "Epoch 162/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8124\n",
            "Epoch 163/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8095\n",
            "Epoch 164/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8088\n",
            "Epoch 165/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8084\n",
            "Epoch 166/175\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 0.4209 - accuracy: 0.8133\n",
            "Epoch 167/175\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8104\n",
            "Epoch 168/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8108\n",
            "Epoch 169/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8106\n",
            "Epoch 170/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8092\n",
            "Epoch 171/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8128\n",
            "Epoch 172/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8109\n",
            "Epoch 173/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8089\n",
            "Epoch 174/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8121\n",
            "Epoch 175/175\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8128\n",
            "31/31 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:05:26,507] Trial 20 finished with value: 0.864406779661017 and parameters: {'xgb__subsample': 0.7394018087175276, 'xgb__scale_pos_weight': 1.5546975471929407, 'xgb__reg_lambda': 2.7190765595914996, 'xgb__n_estimators': 723, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.2919593000885767, 'xgb__gamma': 0.16493840981581026, 'xgb__colsample_bytree': 0.7735585519204902, 'rf__n_estimators': 269, 'rf__min_samples_split': 17, 'rf__min_samples_leaf': 8, 'rf__max_depth': 2, 'rf__bootstrap': False, 'ann__epochs': 175, 'ann__batch_size': 61, 'ann__learning_rate': 0.0005688216921709183}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 5s 25ms/step - loss: 0.4720 - accuracy: 0.7764\n",
            "Epoch 2/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4221 - accuracy: 0.8068\n",
            "Epoch 3/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4200 - accuracy: 0.8116\n",
            "Epoch 4/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8117\n",
            "Epoch 5/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8141\n",
            "Epoch 6/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8105\n",
            "Epoch 7/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8113\n",
            "Epoch 8/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8104\n",
            "Epoch 9/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8114\n",
            "Epoch 10/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8105\n",
            "Epoch 11/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8118\n",
            "Epoch 12/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8099\n",
            "Epoch 13/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8091\n",
            "Epoch 14/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8113\n",
            "Epoch 15/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8120\n",
            "Epoch 16/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4215 - accuracy: 0.8087\n",
            "Epoch 17/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8093\n",
            "Epoch 18/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8092\n",
            "Epoch 19/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8113\n",
            "Epoch 20/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8124\n",
            "Epoch 21/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8108\n",
            "Epoch 22/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8122\n",
            "Epoch 23/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8088\n",
            "Epoch 24/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8122\n",
            "Epoch 25/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8088\n",
            "Epoch 26/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8060\n",
            "Epoch 27/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8102\n",
            "Epoch 28/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8101\n",
            "Epoch 29/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8113\n",
            "Epoch 30/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8085\n",
            "Epoch 31/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8118\n",
            "Epoch 32/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8100\n",
            "Epoch 33/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8132\n",
            "Epoch 34/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8101\n",
            "Epoch 35/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.8132\n",
            "Epoch 36/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8071\n",
            "Epoch 37/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8072\n",
            "Epoch 38/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8087\n",
            "Epoch 39/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8056\n",
            "Epoch 40/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8130\n",
            "Epoch 41/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8118\n",
            "Epoch 42/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8080\n",
            "Epoch 43/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8091\n",
            "Epoch 44/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4224 - accuracy: 0.8122\n",
            "Epoch 45/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.8096\n",
            "Epoch 46/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8102\n",
            "Epoch 47/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8088\n",
            "Epoch 48/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8071\n",
            "Epoch 49/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8120\n",
            "Epoch 50/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.8081\n",
            "Epoch 51/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8093\n",
            "Epoch 52/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8116\n",
            "Epoch 53/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8072\n",
            "Epoch 54/96\n",
            "93/93 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8104\n",
            "Epoch 55/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8068\n",
            "Epoch 56/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8072\n",
            "Epoch 57/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8100\n",
            "Epoch 58/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8069\n",
            "Epoch 59/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8083\n",
            "Epoch 60/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8052\n",
            "Epoch 61/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8092\n",
            "Epoch 62/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8075\n",
            "Epoch 63/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8101\n",
            "Epoch 64/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8068\n",
            "Epoch 65/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8080\n",
            "Epoch 66/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8088\n",
            "Epoch 67/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8108\n",
            "Epoch 68/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8099\n",
            "Epoch 69/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8083\n",
            "Epoch 70/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8117\n",
            "Epoch 71/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8076\n",
            "Epoch 72/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8100\n",
            "Epoch 73/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8071\n",
            "Epoch 74/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8129\n",
            "Epoch 75/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8105\n",
            "Epoch 76/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8091\n",
            "Epoch 77/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8056\n",
            "Epoch 78/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8101\n",
            "Epoch 79/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8088\n",
            "Epoch 80/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8069\n",
            "Epoch 81/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8083\n",
            "Epoch 82/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8067\n",
            "Epoch 83/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8120\n",
            "Epoch 84/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8061\n",
            "Epoch 85/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8073\n",
            "Epoch 86/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8083\n",
            "Epoch 87/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.8093\n",
            "Epoch 88/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8075\n",
            "Epoch 89/96\n",
            "93/93 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.8046\n",
            "Epoch 90/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8048\n",
            "Epoch 91/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8102\n",
            "Epoch 92/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8002\n",
            "Epoch 93/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8047\n",
            "Epoch 94/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8065\n",
            "Epoch 95/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8076\n",
            "Epoch 96/96\n",
            "93/93 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8121\n",
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:06:34,247] Trial 21 finished with value: 0.8649364406779662 and parameters: {'xgb__subsample': 0.9901186929167496, 'xgb__scale_pos_weight': 1.0519915193224583, 'xgb__reg_lambda': 1.1266829754359176, 'xgb__n_estimators': 998, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.10814519313221996, 'xgb__gamma': 0.005223177926466182, 'xgb__colsample_bytree': 0.912185596091546, 'rf__n_estimators': 295, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 1, 'rf__max_depth': 7, 'rf__bootstrap': False, 'ann__epochs': 96, 'ann__batch_size': 82, 'ann__learning_rate': 0.0013818406565172863}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - 6s 21ms/step - loss: 0.4755 - accuracy: 0.7700\n",
            "Epoch 2/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4230 - accuracy: 0.8077\n",
            "Epoch 3/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8102\n",
            "Epoch 4/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8108\n",
            "Epoch 5/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4203 - accuracy: 0.8125\n",
            "Epoch 6/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8113\n",
            "Epoch 7/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8087\n",
            "Epoch 8/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4206 - accuracy: 0.8106\n",
            "Epoch 9/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8093\n",
            "Epoch 10/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4211 - accuracy: 0.8105\n",
            "Epoch 11/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8109\n",
            "Epoch 12/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8077\n",
            "Epoch 13/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8102\n",
            "Epoch 14/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8101\n",
            "Epoch 15/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8116\n",
            "Epoch 16/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8091\n",
            "Epoch 17/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8121\n",
            "Epoch 18/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8113\n",
            "Epoch 19/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4209 - accuracy: 0.8092\n",
            "Epoch 20/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8087\n",
            "Epoch 21/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8088\n",
            "Epoch 22/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8095\n",
            "Epoch 23/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8053\n",
            "Epoch 24/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8118\n",
            "Epoch 25/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8089\n",
            "Epoch 26/115\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.4272 - accuracy: 0.8068\n",
            "Epoch 27/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8095\n",
            "Epoch 28/115\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.4267 - accuracy: 0.8072\n",
            "Epoch 29/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.8057\n",
            "Epoch 30/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8036\n",
            "Epoch 31/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8089\n",
            "Epoch 32/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8083\n",
            "Epoch 33/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8069\n",
            "Epoch 34/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8079\n",
            "Epoch 35/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8084\n",
            "Epoch 36/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8060\n",
            "Epoch 37/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8093\n",
            "Epoch 38/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8036\n",
            "Epoch 39/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8071\n",
            "Epoch 40/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8091\n",
            "Epoch 41/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8067\n",
            "Epoch 42/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8035\n",
            "Epoch 43/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8096\n",
            "Epoch 44/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8079\n",
            "Epoch 45/115\n",
            "152/152 [==============================] - 1s 9ms/step - loss: 0.4338 - accuracy: 0.8056\n",
            "Epoch 46/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4266 - accuracy: 0.8044\n",
            "Epoch 47/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4240 - accuracy: 0.8083\n",
            "Epoch 48/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4285 - accuracy: 0.8076\n",
            "Epoch 49/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4261 - accuracy: 0.8056\n",
            "Epoch 50/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4252 - accuracy: 0.8088\n",
            "Epoch 51/115\n",
            "152/152 [==============================] - 1s 10ms/step - loss: 0.4242 - accuracy: 0.8079\n",
            "Epoch 52/115\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.4262 - accuracy: 0.8060\n",
            "Epoch 53/115\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 0.4237 - accuracy: 0.8117\n",
            "Epoch 54/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4275 - accuracy: 0.8060\n",
            "Epoch 55/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4265 - accuracy: 0.8102\n",
            "Epoch 56/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4232 - accuracy: 0.8075\n",
            "Epoch 57/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8020\n",
            "Epoch 58/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4243 - accuracy: 0.8102\n",
            "Epoch 59/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8050\n",
            "Epoch 60/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8053\n",
            "Epoch 61/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4263 - accuracy: 0.8081\n",
            "Epoch 62/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8080\n",
            "Epoch 63/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8053\n",
            "Epoch 64/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8027\n",
            "Epoch 65/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8102\n",
            "Epoch 66/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8060\n",
            "Epoch 67/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8052\n",
            "Epoch 68/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8065\n",
            "Epoch 69/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8106\n",
            "Epoch 70/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8095\n",
            "Epoch 71/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8068\n",
            "Epoch 72/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8073\n",
            "Epoch 73/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8053\n",
            "Epoch 74/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8068\n",
            "Epoch 75/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8071\n",
            "Epoch 76/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8073\n",
            "Epoch 77/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8059\n",
            "Epoch 78/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8080\n",
            "Epoch 79/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4311 - accuracy: 0.8014\n",
            "Epoch 80/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8028\n",
            "Epoch 81/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.8057\n",
            "Epoch 82/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8089\n",
            "Epoch 83/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8055\n",
            "Epoch 84/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8043\n",
            "Epoch 85/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8040\n",
            "Epoch 86/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8084\n",
            "Epoch 87/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8084\n",
            "Epoch 88/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8026\n",
            "Epoch 89/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4482 - accuracy: 0.7966\n",
            "Epoch 90/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8022\n",
            "Epoch 91/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8088\n",
            "Epoch 92/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8024\n",
            "Epoch 93/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8044\n",
            "Epoch 94/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8083\n",
            "Epoch 95/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.7998\n",
            "Epoch 96/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8083\n",
            "Epoch 97/115\n",
            "152/152 [==============================] - 1s 9ms/step - loss: 0.4420 - accuracy: 0.8028\n",
            "Epoch 98/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8069\n",
            "Epoch 99/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4374 - accuracy: 0.8057\n",
            "Epoch 100/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8052\n",
            "Epoch 101/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8081\n",
            "Epoch 102/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4282 - accuracy: 0.8052\n",
            "Epoch 103/115\n",
            "152/152 [==============================] - 2s 10ms/step - loss: 0.4287 - accuracy: 0.8046\n",
            "Epoch 104/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4318 - accuracy: 0.8044\n",
            "Epoch 105/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4329 - accuracy: 0.8060\n",
            "Epoch 106/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4309 - accuracy: 0.8044\n",
            "Epoch 107/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4336 - accuracy: 0.8008\n",
            "Epoch 108/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8044\n",
            "Epoch 109/115\n",
            "152/152 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8064\n",
            "Epoch 110/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4370 - accuracy: 0.8022\n",
            "Epoch 111/115\n",
            "152/152 [==============================] - 1s 8ms/step - loss: 0.4328 - accuracy: 0.8061\n",
            "Epoch 112/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8007\n",
            "Epoch 113/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8053\n",
            "Epoch 114/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8001\n",
            "Epoch 115/115\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8052\n",
            "38/38 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:08:47,448] Trial 22 finished with value: 0.8649364406779662 and parameters: {'xgb__subsample': 0.9800943552417504, 'xgb__scale_pos_weight': 1.2277936305834807, 'xgb__reg_lambda': 0.9113463377988336, 'xgb__n_estimators': 954, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.08472542983160036, 'xgb__gamma': 0.09058238367592827, 'xgb__colsample_bytree': 0.9245450239079204, 'rf__n_estimators': 178, 'rf__min_samples_split': 4, 'rf__min_samples_leaf': 3, 'rf__max_depth': 8, 'rf__bootstrap': False, 'ann__epochs': 115, 'ann__batch_size': 50, 'ann__learning_rate': 0.0014614105526395303}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 5s 35ms/step - loss: 0.4488 - accuracy: 0.7926\n",
            "Epoch 2/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4207 - accuracy: 0.8085\n",
            "Epoch 3/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4208 - accuracy: 0.8104\n",
            "Epoch 4/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4209 - accuracy: 0.8105\n",
            "Epoch 5/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8113\n",
            "Epoch 6/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8104\n",
            "Epoch 7/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8130\n",
            "Epoch 8/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4205 - accuracy: 0.8116\n",
            "Epoch 9/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8108\n",
            "Epoch 10/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8087\n",
            "Epoch 11/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8080\n",
            "Epoch 12/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8120\n",
            "Epoch 13/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4224 - accuracy: 0.8087\n",
            "Epoch 14/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8077\n",
            "Epoch 15/150\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4266 - accuracy: 0.8081\n",
            "Epoch 16/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4211 - accuracy: 0.8089\n",
            "Epoch 17/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8036\n",
            "Epoch 18/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8051\n",
            "Epoch 19/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8095\n",
            "Epoch 20/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8091\n",
            "Epoch 21/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8079\n",
            "Epoch 22/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8096\n",
            "Epoch 23/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8073\n",
            "Epoch 24/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8093\n",
            "Epoch 25/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8071\n",
            "Epoch 26/150\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8079\n",
            "Epoch 27/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.8055\n",
            "Epoch 28/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8059\n",
            "Epoch 29/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8106\n",
            "Epoch 30/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.8055\n",
            "Epoch 31/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8068\n",
            "Epoch 32/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8109\n",
            "Epoch 33/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.8053\n",
            "Epoch 34/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8072\n",
            "Epoch 35/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.8046\n",
            "Epoch 36/150\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.8047\n",
            "Epoch 37/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8096\n",
            "Epoch 38/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8102\n",
            "Epoch 39/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8099\n",
            "Epoch 40/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.7994\n",
            "Epoch 41/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8100\n",
            "Epoch 42/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8093\n",
            "Epoch 43/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8112\n",
            "Epoch 44/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8046\n",
            "Epoch 45/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.8032\n",
            "Epoch 46/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8048\n",
            "Epoch 47/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.8046\n",
            "Epoch 48/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8031\n",
            "Epoch 49/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8044\n",
            "Epoch 50/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.8081\n",
            "Epoch 51/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.8064\n",
            "Epoch 52/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003\n",
            "Epoch 53/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8056\n",
            "Epoch 54/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8059\n",
            "Epoch 55/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8019\n",
            "Epoch 56/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8060\n",
            "Epoch 57/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.8030\n",
            "Epoch 58/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4230 - accuracy: 0.8106\n",
            "Epoch 59/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8057\n",
            "Epoch 60/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4414 - accuracy: 0.7962\n",
            "Epoch 61/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8089\n",
            "Epoch 62/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8057\n",
            "Epoch 63/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8044\n",
            "Epoch 64/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.7994\n",
            "Epoch 65/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8076\n",
            "Epoch 66/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.8081\n",
            "Epoch 67/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8095\n",
            "Epoch 68/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8010\n",
            "Epoch 69/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8016\n",
            "Epoch 70/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.8046\n",
            "Epoch 71/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4386 - accuracy: 0.8030\n",
            "Epoch 72/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4292 - accuracy: 0.8055\n",
            "Epoch 73/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4355 - accuracy: 0.8056\n",
            "Epoch 74/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8022\n",
            "Epoch 75/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4424 - accuracy: 0.7981\n",
            "Epoch 76/150\n",
            "69/69 [==============================] - 1s 19ms/step - loss: 0.4368 - accuracy: 0.8028\n",
            "Epoch 77/150\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4323 - accuracy: 0.8024\n",
            "Epoch 78/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4381 - accuracy: 0.8032\n",
            "Epoch 79/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4266 - accuracy: 0.8099\n",
            "Epoch 80/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.8060\n",
            "Epoch 81/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8043\n",
            "Epoch 82/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.8008\n",
            "Epoch 83/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4295 - accuracy: 0.8056\n",
            "Epoch 84/150\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4292 - accuracy: 0.8039\n",
            "Epoch 85/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4285 - accuracy: 0.8030\n",
            "Epoch 86/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8027\n",
            "Epoch 87/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.8035\n",
            "Epoch 88/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8011\n",
            "Epoch 89/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8014\n",
            "Epoch 90/150\n",
            "69/69 [==============================] - 1s 10ms/step - loss: 0.4337 - accuracy: 0.7981\n",
            "Epoch 91/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8057\n",
            "Epoch 92/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4297 - accuracy: 0.8069\n",
            "Epoch 93/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4272 - accuracy: 0.8072\n",
            "Epoch 94/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4262 - accuracy: 0.8091\n",
            "Epoch 95/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.8016\n",
            "Epoch 96/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7994\n",
            "Epoch 97/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4295 - accuracy: 0.8032\n",
            "Epoch 98/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4291 - accuracy: 0.8042\n",
            "Epoch 99/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4300 - accuracy: 0.8043\n",
            "Epoch 100/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8057\n",
            "Epoch 101/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8052\n",
            "Epoch 102/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8010\n",
            "Epoch 103/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8038\n",
            "Epoch 104/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8031\n",
            "Epoch 105/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8047\n",
            "Epoch 106/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8087\n",
            "Epoch 107/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8034\n",
            "Epoch 108/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8081\n",
            "Epoch 109/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8036\n",
            "Epoch 110/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4267 - accuracy: 0.8065\n",
            "Epoch 111/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8043\n",
            "Epoch 112/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.7990\n",
            "Epoch 113/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.7993\n",
            "Epoch 114/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8035\n",
            "Epoch 115/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8057\n",
            "Epoch 116/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4315 - accuracy: 0.8019\n",
            "Epoch 117/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4255 - accuracy: 0.8102\n",
            "Epoch 118/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4317 - accuracy: 0.8077\n",
            "Epoch 119/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4395 - accuracy: 0.7957\n",
            "Epoch 120/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.8010\n",
            "Epoch 121/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4261 - accuracy: 0.8091\n",
            "Epoch 122/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4314 - accuracy: 0.8051\n",
            "Epoch 123/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4324 - accuracy: 0.8055\n",
            "Epoch 124/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8056\n",
            "Epoch 125/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4444 - accuracy: 0.8005\n",
            "Epoch 126/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7963\n",
            "Epoch 127/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8032\n",
            "Epoch 128/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8002\n",
            "Epoch 129/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8026\n",
            "Epoch 130/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8014\n",
            "Epoch 131/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4544 - accuracy: 0.7969\n",
            "Epoch 132/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.8008\n",
            "Epoch 133/150\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4315 - accuracy: 0.8038\n",
            "Epoch 134/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4305 - accuracy: 0.8027\n",
            "Epoch 135/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7978\n",
            "Epoch 136/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8055\n",
            "Epoch 137/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.8026\n",
            "Epoch 138/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4352 - accuracy: 0.8044\n",
            "Epoch 139/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4438 - accuracy: 0.7981\n",
            "Epoch 140/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4486 - accuracy: 0.7956\n",
            "Epoch 141/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8080\n",
            "Epoch 142/150\n",
            "69/69 [==============================] - 1s 17ms/step - loss: 0.4322 - accuracy: 0.8046\n",
            "Epoch 143/150\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.4277 - accuracy: 0.8077\n",
            "Epoch 144/150\n",
            "69/69 [==============================] - 1s 10ms/step - loss: 0.4329 - accuracy: 0.8050\n",
            "Epoch 145/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.7969\n",
            "Epoch 146/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8011\n",
            "Epoch 147/150\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8005\n",
            "Epoch 148/150\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4379 - accuracy: 0.8024\n",
            "Epoch 149/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8038\n",
            "Epoch 150/150\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7999\n",
            "18/18 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:10:10,772] Trial 23 finished with value: 0.8564618644067796 and parameters: {'xgb__subsample': 0.9964616040885025, 'xgb__scale_pos_weight': 2.073312127336292, 'xgb__reg_lambda': 0.1525096217381634, 'xgb__n_estimators': 894, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.14754171871364666, 'xgb__gamma': 0.2435145544787718, 'xgb__colsample_bytree': 0.9895130568829145, 'rf__n_estimators': 320, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 1, 'rf__max_depth': 3, 'rf__bootstrap': False, 'ann__epochs': 150, 'ann__batch_size': 110, 'ann__learning_rate': 0.002544235702830974}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118/118 [==============================] - 3s 8ms/step - loss: 0.5611 - accuracy: 0.6903\n",
            "Epoch 2/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4400 - accuracy: 0.7921\n",
            "Epoch 3/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4272 - accuracy: 0.8024\n",
            "Epoch 4/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8067\n",
            "Epoch 5/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.8088\n",
            "Epoch 6/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4198 - accuracy: 0.8132\n",
            "Epoch 7/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4193 - accuracy: 0.8106\n",
            "Epoch 8/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8106\n",
            "Epoch 9/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8118\n",
            "Epoch 10/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8116\n",
            "Epoch 11/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4187 - accuracy: 0.8106\n",
            "Epoch 12/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8113\n",
            "Epoch 13/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8117\n",
            "Epoch 14/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8121\n",
            "Epoch 15/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8112\n",
            "Epoch 16/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8130\n",
            "Epoch 17/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8124\n",
            "Epoch 18/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8116\n",
            "Epoch 19/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8134\n",
            "Epoch 20/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8133\n",
            "Epoch 21/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8104\n",
            "Epoch 22/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.8120\n",
            "Epoch 23/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4189 - accuracy: 0.8124\n",
            "Epoch 24/93\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.4189 - accuracy: 0.8109\n",
            "Epoch 25/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8122\n",
            "Epoch 26/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4191 - accuracy: 0.8114\n",
            "Epoch 27/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.8100\n",
            "Epoch 28/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8118\n",
            "Epoch 29/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.8121\n",
            "Epoch 30/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8109\n",
            "Epoch 31/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4187 - accuracy: 0.8120\n",
            "Epoch 32/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8132\n",
            "Epoch 33/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8112\n",
            "Epoch 34/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4193 - accuracy: 0.8095\n",
            "Epoch 35/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8125\n",
            "Epoch 36/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8112\n",
            "Epoch 37/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.8116\n",
            "Epoch 38/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8117\n",
            "Epoch 39/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8122\n",
            "Epoch 40/93\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.4188 - accuracy: 0.8114\n",
            "Epoch 41/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4187 - accuracy: 0.8100\n",
            "Epoch 42/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8100\n",
            "Epoch 43/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4187 - accuracy: 0.8099\n",
            "Epoch 44/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4196 - accuracy: 0.8101\n",
            "Epoch 45/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4191 - accuracy: 0.8108\n",
            "Epoch 46/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8114\n",
            "Epoch 47/93\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.4196 - accuracy: 0.8099\n",
            "Epoch 48/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4191 - accuracy: 0.8113\n",
            "Epoch 49/93\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.4194 - accuracy: 0.8125\n",
            "Epoch 50/93\n",
            "118/118 [==============================] - 1s 10ms/step - loss: 0.4196 - accuracy: 0.8132\n",
            "Epoch 51/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4191 - accuracy: 0.8102\n",
            "Epoch 52/93\n",
            "118/118 [==============================] - 1s 10ms/step - loss: 0.4184 - accuracy: 0.8114\n",
            "Epoch 53/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8130\n",
            "Epoch 54/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8101\n",
            "Epoch 55/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8118\n",
            "Epoch 56/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4185 - accuracy: 0.8102\n",
            "Epoch 57/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8118\n",
            "Epoch 58/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8112\n",
            "Epoch 59/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.8105\n",
            "Epoch 60/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8096\n",
            "Epoch 61/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4187 - accuracy: 0.8133\n",
            "Epoch 62/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4199 - accuracy: 0.8099\n",
            "Epoch 63/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.8124\n",
            "Epoch 64/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4193 - accuracy: 0.8128\n",
            "Epoch 65/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4190 - accuracy: 0.8130\n",
            "Epoch 66/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4194 - accuracy: 0.8142\n",
            "Epoch 67/93\n",
            "118/118 [==============================] - 1s 10ms/step - loss: 0.4197 - accuracy: 0.8130\n",
            "Epoch 68/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8110\n",
            "Epoch 69/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8109\n",
            "Epoch 70/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.8121\n",
            "Epoch 71/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4202 - accuracy: 0.8120\n",
            "Epoch 72/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8105\n",
            "Epoch 73/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8126\n",
            "Epoch 74/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4198 - accuracy: 0.8113\n",
            "Epoch 75/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4192 - accuracy: 0.8108\n",
            "Epoch 76/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8096\n",
            "Epoch 77/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.8106\n",
            "Epoch 78/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.8097\n",
            "Epoch 79/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4194 - accuracy: 0.8116\n",
            "Epoch 80/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8118\n",
            "Epoch 81/93\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4203 - accuracy: 0.8114\n",
            "Epoch 82/93\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.8112\n",
            "Epoch 83/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.8113\n",
            "Epoch 84/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4197 - accuracy: 0.8109\n",
            "Epoch 85/93\n",
            "118/118 [==============================] - 1s 11ms/step - loss: 0.4209 - accuracy: 0.8109\n",
            "Epoch 86/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4212 - accuracy: 0.8109\n",
            "Epoch 87/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.8128\n",
            "Epoch 88/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8120\n",
            "Epoch 89/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.8108\n",
            "Epoch 90/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4200 - accuracy: 0.8105\n",
            "Epoch 91/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4204 - accuracy: 0.8113\n",
            "Epoch 92/93\n",
            "118/118 [==============================] - 1s 9ms/step - loss: 0.4197 - accuracy: 0.8113\n",
            "Epoch 93/93\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8073\n",
            "30/30 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:11:41,194] Trial 24 finished with value: 0.8479872881355932 and parameters: {'xgb__subsample': 0.9025214791436944, 'xgb__scale_pos_weight': 1.0578353867912549, 'xgb__reg_lambda': 1.089776833302456, 'xgb__n_estimators': 739, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.010123622038071494, 'xgb__gamma': 0.07712536580552301, 'xgb__colsample_bytree': 0.8387789425643264, 'rf__n_estimators': 167, 'rf__min_samples_split': 12, 'rf__min_samples_leaf': 5, 'rf__max_depth': 4, 'rf__bootstrap': False, 'ann__epochs': 93, 'ann__batch_size': 64, 'ann__learning_rate': 0.0005942786246809006}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 7s 39ms/step - loss: 0.4382 - accuracy: 0.7979\n",
            "Epoch 2/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4222 - accuracy: 0.8079\n",
            "Epoch 3/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4280 - accuracy: 0.8069\n",
            "Epoch 4/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4244 - accuracy: 0.8101\n",
            "Epoch 5/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4313 - accuracy: 0.8068\n",
            "Epoch 6/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4339 - accuracy: 0.8003\n",
            "Epoch 7/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4293 - accuracy: 0.8068\n",
            "Epoch 8/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4274 - accuracy: 0.8081\n",
            "Epoch 9/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4478 - accuracy: 0.7958\n",
            "Epoch 10/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4296 - accuracy: 0.8036\n",
            "Epoch 11/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4336 - accuracy: 0.8053\n",
            "Epoch 12/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4395 - accuracy: 0.8020\n",
            "Epoch 13/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4395 - accuracy: 0.8008\n",
            "Epoch 14/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4299 - accuracy: 0.8053\n",
            "Epoch 15/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4352 - accuracy: 0.8034\n",
            "Epoch 16/122\n",
            "90/90 [==============================] - 1s 13ms/step - loss: 0.4402 - accuracy: 0.7985\n",
            "Epoch 17/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4467 - accuracy: 0.7958\n",
            "Epoch 18/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4376 - accuracy: 0.7998\n",
            "Epoch 19/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4460 - accuracy: 0.7990\n",
            "Epoch 20/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4333 - accuracy: 0.8068\n",
            "Epoch 21/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4465 - accuracy: 0.8018\n",
            "Epoch 22/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4369 - accuracy: 0.8027\n",
            "Epoch 23/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4402 - accuracy: 0.8015\n",
            "Epoch 24/122\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4536 - accuracy: 0.7950\n",
            "Epoch 25/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4630 - accuracy: 0.7908\n",
            "Epoch 26/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4546 - accuracy: 0.7958\n",
            "Epoch 27/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4727 - accuracy: 0.7912\n",
            "Epoch 28/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4427 - accuracy: 0.7981\n",
            "Epoch 29/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4438 - accuracy: 0.7989\n",
            "Epoch 30/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4483 - accuracy: 0.8005\n",
            "Epoch 31/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.7933\n",
            "Epoch 32/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4632 - accuracy: 0.7954\n",
            "Epoch 33/122\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4519 - accuracy: 0.8020\n",
            "Epoch 34/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4578 - accuracy: 0.7983\n",
            "Epoch 35/122\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4716 - accuracy: 0.7895\n",
            "Epoch 36/122\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4675 - accuracy: 0.7929\n",
            "Epoch 37/122\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4487 - accuracy: 0.7970\n",
            "Epoch 38/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4490 - accuracy: 0.7979\n",
            "Epoch 39/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4402 - accuracy: 0.7975\n",
            "Epoch 40/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4538 - accuracy: 0.7946\n",
            "Epoch 41/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7940\n",
            "Epoch 42/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4509 - accuracy: 0.7970\n",
            "Epoch 43/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.7978\n",
            "Epoch 44/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4624 - accuracy: 0.7921\n",
            "Epoch 45/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4756 - accuracy: 0.7867\n",
            "Epoch 46/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.7945\n",
            "Epoch 47/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.7983\n",
            "Epoch 48/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4632 - accuracy: 0.7952\n",
            "Epoch 49/122\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4486 - accuracy: 0.8022\n",
            "Epoch 50/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.7879\n",
            "Epoch 51/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7901\n",
            "Epoch 52/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4907 - accuracy: 0.7819\n",
            "Epoch 53/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.7887\n",
            "Epoch 54/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.7977\n",
            "Epoch 55/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4743 - accuracy: 0.7887\n",
            "Epoch 56/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7932\n",
            "Epoch 57/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7934\n",
            "Epoch 58/122\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4829 - accuracy: 0.7850\n",
            "Epoch 59/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4578 - accuracy: 0.7929\n",
            "Epoch 60/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.7979\n",
            "Epoch 61/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.7895\n",
            "Epoch 62/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4724 - accuracy: 0.7904\n",
            "Epoch 63/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4468 - accuracy: 0.7925\n",
            "Epoch 64/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.7858\n",
            "Epoch 65/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4759 - accuracy: 0.7867\n",
            "Epoch 66/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4556 - accuracy: 0.7974\n",
            "Epoch 67/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.7871\n",
            "Epoch 68/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4732 - accuracy: 0.7920\n",
            "Epoch 69/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4846 - accuracy: 0.7864\n",
            "Epoch 70/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.7938\n",
            "Epoch 71/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.7827\n",
            "Epoch 72/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4476 - accuracy: 0.7974\n",
            "Epoch 73/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4469 - accuracy: 0.8020\n",
            "Epoch 74/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4779 - accuracy: 0.7865\n",
            "Epoch 75/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5250 - accuracy: 0.7775\n",
            "Epoch 76/122\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4642 - accuracy: 0.7928\n",
            "Epoch 77/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.7920\n",
            "Epoch 78/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.7779\n",
            "Epoch 79/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.7835\n",
            "Epoch 80/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4752 - accuracy: 0.7913\n",
            "Epoch 81/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7876\n",
            "Epoch 82/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4799 - accuracy: 0.7897\n",
            "Epoch 83/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.7760\n",
            "Epoch 84/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.7981\n",
            "Epoch 85/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.7933\n",
            "Epoch 86/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4690 - accuracy: 0.7998\n",
            "Epoch 87/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7844\n",
            "Epoch 88/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4627 - accuracy: 0.7949\n",
            "Epoch 89/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5208 - accuracy: 0.7831\n",
            "Epoch 90/122\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4773 - accuracy: 0.7922\n",
            "Epoch 91/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5043 - accuracy: 0.7843\n",
            "Epoch 92/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4766 - accuracy: 0.7864\n",
            "Epoch 93/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5262 - accuracy: 0.7793\n",
            "Epoch 94/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4797 - accuracy: 0.7861\n",
            "Epoch 95/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4975 - accuracy: 0.7799\n",
            "Epoch 96/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4893 - accuracy: 0.7921\n",
            "Epoch 97/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4704 - accuracy: 0.7879\n",
            "Epoch 98/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.7787\n",
            "Epoch 99/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.7908\n",
            "Epoch 100/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.7826\n",
            "Epoch 101/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5250 - accuracy: 0.7749\n",
            "Epoch 102/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7812\n",
            "Epoch 103/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.7806\n",
            "Epoch 104/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.7736\n",
            "Epoch 105/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4985 - accuracy: 0.7843\n",
            "Epoch 106/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5049 - accuracy: 0.7812\n",
            "Epoch 107/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4936 - accuracy: 0.7828\n",
            "Epoch 108/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4927 - accuracy: 0.7859\n",
            "Epoch 109/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4752 - accuracy: 0.7913\n",
            "Epoch 110/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7832\n",
            "Epoch 111/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.7860\n",
            "Epoch 112/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4907 - accuracy: 0.7815\n",
            "Epoch 113/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.7830\n",
            "Epoch 114/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.7883\n",
            "Epoch 115/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7781\n",
            "Epoch 116/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.7881\n",
            "Epoch 117/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.7901\n",
            "Epoch 118/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5047 - accuracy: 0.7791\n",
            "Epoch 119/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4762 - accuracy: 0.7869\n",
            "Epoch 120/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7770\n",
            "Epoch 121/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5810 - accuracy: 0.7676\n",
            "Epoch 122/122\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6096 - accuracy: 0.7623\n",
            "23/23 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:13:22,354] Trial 25 finished with value: 0.8697033898305084 and parameters: {'xgb__subsample': 0.9233806125507804, 'xgb__scale_pos_weight': 3.3209774529885707, 'xgb__reg_lambda': 2.1803700840125364, 'xgb__n_estimators': 999, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.05039906127933683, 'xgb__gamma': 0.16431762039834208, 'xgb__colsample_bytree': 0.9145350763900154, 'rf__n_estimators': 453, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 2, 'rf__max_depth': 10, 'rf__bootstrap': False, 'ann__epochs': 122, 'ann__batch_size': 84, 'ann__learning_rate': 0.006318259715531871}. Best is trial 11 with value: 0.871822033898305.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 5s 30ms/step - loss: 0.4614 - accuracy: 0.7875\n",
            "Epoch 2/124\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4235 - accuracy: 0.8100\n",
            "Epoch 3/124\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4268 - accuracy: 0.8068\n",
            "Epoch 4/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8065\n",
            "Epoch 5/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8050\n",
            "Epoch 6/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8067\n",
            "Epoch 7/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.8008\n",
            "Epoch 8/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4337 - accuracy: 0.8039\n",
            "Epoch 9/124\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4312 - accuracy: 0.8048\n",
            "Epoch 10/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.7989\n",
            "Epoch 11/124\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4297 - accuracy: 0.8053\n",
            "Epoch 12/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8096\n",
            "Epoch 13/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8014\n",
            "Epoch 14/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4285 - accuracy: 0.8052\n",
            "Epoch 15/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4459 - accuracy: 0.7962\n",
            "Epoch 16/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.7998\n",
            "Epoch 17/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4399 - accuracy: 0.8024\n",
            "Epoch 18/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8055\n",
            "Epoch 19/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4408 - accuracy: 0.7982\n",
            "Epoch 20/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8012\n",
            "Epoch 21/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.7994\n",
            "Epoch 22/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7970\n",
            "Epoch 23/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.8035\n",
            "Epoch 24/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.7990\n",
            "Epoch 25/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8050\n",
            "Epoch 26/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.7979\n",
            "Epoch 27/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4485 - accuracy: 0.8053\n",
            "Epoch 28/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4472 - accuracy: 0.7983\n",
            "Epoch 29/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4468 - accuracy: 0.7990\n",
            "Epoch 30/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8005\n",
            "Epoch 31/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.7977\n",
            "Epoch 32/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4606 - accuracy: 0.7936\n",
            "Epoch 33/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4621 - accuracy: 0.7909\n",
            "Epoch 34/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4644 - accuracy: 0.7930\n",
            "Epoch 35/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4570 - accuracy: 0.7953\n",
            "Epoch 36/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.7963\n",
            "Epoch 37/124\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.7998\n",
            "Epoch 38/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.7957\n",
            "Epoch 39/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4555 - accuracy: 0.7903\n",
            "Epoch 40/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4505 - accuracy: 0.7969\n",
            "Epoch 41/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.7916\n",
            "Epoch 42/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.8010\n",
            "Epoch 43/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4474 - accuracy: 0.7958\n",
            "Epoch 44/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.7842\n",
            "Epoch 45/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.7918\n",
            "Epoch 46/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.7961\n",
            "Epoch 47/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.7982\n",
            "Epoch 48/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7961\n",
            "Epoch 49/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.7888\n",
            "Epoch 50/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.8005\n",
            "Epoch 51/124\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4563 - accuracy: 0.7887\n",
            "Epoch 52/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4542 - accuracy: 0.7965\n",
            "Epoch 53/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4584 - accuracy: 0.7958\n",
            "Epoch 54/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4540 - accuracy: 0.7922\n",
            "Epoch 55/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8023\n",
            "Epoch 56/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.7986\n",
            "Epoch 57/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7883\n",
            "Epoch 58/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4470 - accuracy: 0.8005\n",
            "Epoch 59/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4662 - accuracy: 0.7897\n",
            "Epoch 60/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4593 - accuracy: 0.7959\n",
            "Epoch 61/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.7860\n",
            "Epoch 62/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.7926\n",
            "Epoch 63/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7914\n",
            "Epoch 64/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4583 - accuracy: 0.7922\n",
            "Epoch 65/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4408 - accuracy: 0.8001\n",
            "Epoch 66/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4968 - accuracy: 0.7818\n",
            "Epoch 67/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4750 - accuracy: 0.7859\n",
            "Epoch 68/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.7973\n",
            "Epoch 69/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7940\n",
            "Epoch 70/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4652 - accuracy: 0.7941\n",
            "Epoch 71/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4600 - accuracy: 0.7938\n",
            "Epoch 72/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.5032 - accuracy: 0.7807\n",
            "Epoch 73/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7855\n",
            "Epoch 74/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5256 - accuracy: 0.7729\n",
            "Epoch 75/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7952\n",
            "Epoch 76/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.7897\n",
            "Epoch 77/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4636 - accuracy: 0.7934\n",
            "Epoch 78/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4542 - accuracy: 0.7965\n",
            "Epoch 79/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7869\n",
            "Epoch 80/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4548 - accuracy: 0.7920\n",
            "Epoch 81/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4637 - accuracy: 0.7983\n",
            "Epoch 82/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4717 - accuracy: 0.7905\n",
            "Epoch 83/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4756 - accuracy: 0.7881\n",
            "Epoch 84/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4613 - accuracy: 0.7948\n",
            "Epoch 85/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4559 - accuracy: 0.7962\n",
            "Epoch 86/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7812\n",
            "Epoch 87/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7884\n",
            "Epoch 88/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4925 - accuracy: 0.7832\n",
            "Epoch 89/124\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4684 - accuracy: 0.7899\n",
            "Epoch 90/124\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4542 - accuracy: 0.7945\n",
            "Epoch 91/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.7975\n",
            "Epoch 92/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4858 - accuracy: 0.7903\n",
            "Epoch 93/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4940 - accuracy: 0.7863\n",
            "Epoch 94/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.7842\n",
            "Epoch 95/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.7891\n",
            "Epoch 96/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7913\n",
            "Epoch 97/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4647 - accuracy: 0.7908\n",
            "Epoch 98/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.7824\n",
            "Epoch 99/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5195 - accuracy: 0.7797\n",
            "Epoch 100/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5091 - accuracy: 0.7807\n",
            "Epoch 101/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4836 - accuracy: 0.7856\n",
            "Epoch 102/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.7868\n",
            "Epoch 103/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.7822\n",
            "Epoch 104/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4797 - accuracy: 0.7896\n",
            "Epoch 105/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.7933\n",
            "Epoch 106/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.7910\n",
            "Epoch 107/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4855 - accuracy: 0.7891\n",
            "Epoch 108/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.7917\n",
            "Epoch 109/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.7786\n",
            "Epoch 110/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4958 - accuracy: 0.7861\n",
            "Epoch 111/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4698 - accuracy: 0.7903\n",
            "Epoch 112/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4803 - accuracy: 0.7880\n",
            "Epoch 113/124\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5217 - accuracy: 0.7797\n",
            "Epoch 114/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4945 - accuracy: 0.7848\n",
            "Epoch 115/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.7897\n",
            "Epoch 116/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4819 - accuracy: 0.7847\n",
            "Epoch 117/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4891 - accuracy: 0.7852\n",
            "Epoch 118/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.7850\n",
            "Epoch 119/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.7867\n",
            "Epoch 120/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4743 - accuracy: 0.7892\n",
            "Epoch 121/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5569 - accuracy: 0.7720\n",
            "Epoch 122/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4862 - accuracy: 0.7873\n",
            "Epoch 123/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7828\n",
            "Epoch 124/124\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.7803\n",
            "23/23 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:14:47,442] Trial 26 finished with value: 0.8734110169491526 and parameters: {'xgb__subsample': 0.8550634130275675, 'xgb__scale_pos_weight': 3.439527500870976, 'xgb__reg_lambda': 2.2968363116256563, 'xgb__n_estimators': 868, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.05648237633750645, 'xgb__gamma': 0.16612089220789483, 'xgb__colsample_bytree': 0.8280531822419329, 'rf__n_estimators': 671, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 3, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 124, 'ann__batch_size': 84, 'ann__learning_rate': 0.0063619465835174785}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74/74 [==============================] - 5s 35ms/step - loss: 0.4502 - accuracy: 0.7950\n",
            "Epoch 2/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8073\n",
            "Epoch 3/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8048\n",
            "Epoch 4/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8060\n",
            "Epoch 5/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8095\n",
            "Epoch 6/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8040\n",
            "Epoch 7/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8048\n",
            "Epoch 8/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8010\n",
            "Epoch 9/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8028\n",
            "Epoch 10/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4313 - accuracy: 0.8067\n",
            "Epoch 11/116\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4400 - accuracy: 0.8023\n",
            "Epoch 12/116\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4544 - accuracy: 0.7922\n",
            "Epoch 13/116\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4375 - accuracy: 0.8019\n",
            "Epoch 14/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.8044\n",
            "Epoch 15/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8011\n",
            "Epoch 16/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8002\n",
            "Epoch 17/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.7983\n",
            "Epoch 18/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.7986\n",
            "Epoch 19/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.8052\n",
            "Epoch 20/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.7948\n",
            "Epoch 21/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.8046\n",
            "Epoch 22/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7991\n",
            "Epoch 23/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4474 - accuracy: 0.7993\n",
            "Epoch 24/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7977\n",
            "Epoch 25/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8023\n",
            "Epoch 26/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8003\n",
            "Epoch 27/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.7933\n",
            "Epoch 28/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.8061\n",
            "Epoch 29/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.8051\n",
            "Epoch 30/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.7883\n",
            "Epoch 31/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7949\n",
            "Epoch 32/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4606 - accuracy: 0.7942\n",
            "Epoch 33/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.7946\n",
            "Epoch 34/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7994\n",
            "Epoch 35/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4622 - accuracy: 0.7930\n",
            "Epoch 36/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.7929\n",
            "Epoch 37/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7969\n",
            "Epoch 38/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7842\n",
            "Epoch 39/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.7920\n",
            "Epoch 40/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.8001\n",
            "Epoch 41/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7925\n",
            "Epoch 42/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.7867\n",
            "Epoch 43/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7993\n",
            "Epoch 44/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7975\n",
            "Epoch 45/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4500 - accuracy: 0.7930\n",
            "Epoch 46/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7953\n",
            "Epoch 47/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.7934\n",
            "Epoch 48/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7975\n",
            "Epoch 49/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.7926\n",
            "Epoch 50/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7946\n",
            "Epoch 51/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.7803\n",
            "Epoch 52/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7917\n",
            "Epoch 53/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7901\n",
            "Epoch 54/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7957\n",
            "Epoch 55/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4796 - accuracy: 0.7885\n",
            "Epoch 56/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.7938\n",
            "Epoch 57/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7910\n",
            "Epoch 58/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7854\n",
            "Epoch 59/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.7971\n",
            "Epoch 60/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.7917\n",
            "Epoch 61/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7883\n",
            "Epoch 62/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4544 - accuracy: 0.8001\n",
            "Epoch 63/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7932\n",
            "Epoch 64/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7954\n",
            "Epoch 65/116\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7834\n",
            "Epoch 66/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7929\n",
            "Epoch 67/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.7903\n",
            "Epoch 68/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4891 - accuracy: 0.7831\n",
            "Epoch 69/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7880\n",
            "Epoch 70/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5295 - accuracy: 0.7742\n",
            "Epoch 71/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.7807\n",
            "Epoch 72/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7884\n",
            "Epoch 73/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7860\n",
            "Epoch 74/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7889\n",
            "Epoch 75/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.7848\n",
            "Epoch 76/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7718\n",
            "Epoch 77/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7876\n",
            "Epoch 78/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7900\n",
            "Epoch 79/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7863\n",
            "Epoch 80/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5086 - accuracy: 0.7811\n",
            "Epoch 81/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.7893\n",
            "Epoch 82/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7893\n",
            "Epoch 83/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7959\n",
            "Epoch 84/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5057 - accuracy: 0.7815\n",
            "Epoch 85/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4505 - accuracy: 0.7963\n",
            "Epoch 86/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.7977\n",
            "Epoch 87/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.7787\n",
            "Epoch 88/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.7846\n",
            "Epoch 89/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.7856\n",
            "Epoch 90/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4659 - accuracy: 0.7953\n",
            "Epoch 91/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7807\n",
            "Epoch 92/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7938\n",
            "Epoch 93/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7802\n",
            "Epoch 94/116\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7852\n",
            "Epoch 95/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7831\n",
            "Epoch 96/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7865\n",
            "Epoch 97/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.7905\n",
            "Epoch 98/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5293 - accuracy: 0.7767\n",
            "Epoch 99/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7762\n",
            "Epoch 100/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7824\n",
            "Epoch 101/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7789\n",
            "Epoch 102/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7986\n",
            "Epoch 103/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5074 - accuracy: 0.7831\n",
            "Epoch 104/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7756\n",
            "Epoch 105/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7934\n",
            "Epoch 106/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.7843\n",
            "Epoch 107/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7961\n",
            "Epoch 108/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7843\n",
            "Epoch 109/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7904\n",
            "Epoch 110/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.7928\n",
            "Epoch 111/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4868 - accuracy: 0.7861\n",
            "Epoch 112/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4813 - accuracy: 0.7844\n",
            "Epoch 113/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7681\n",
            "Epoch 114/116\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5033 - accuracy: 0.7834\n",
            "Epoch 115/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5200 - accuracy: 0.7781\n",
            "Epoch 116/116\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.7807\n",
            "19/19 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:15:54,972] Trial 27 finished with value: 0.8628177966101694 and parameters: {'xgb__subsample': 0.8254743685399658, 'xgb__scale_pos_weight': 3.692255400147878, 'xgb__reg_lambda': 2.2104270945246607, 'xgb__n_estimators': 931, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.04587418960862568, 'xgb__gamma': 0.16835731396150166, 'xgb__colsample_bytree': 0.8187523529582148, 'rf__n_estimators': 699, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 8, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 116, 'ann__batch_size': 103, 'ann__learning_rate': 0.00795373643361289}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 5s 29ms/step - loss: 0.4485 - accuracy: 0.7920\n",
            "Epoch 2/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8091\n",
            "Epoch 3/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8056\n",
            "Epoch 4/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8096\n",
            "Epoch 5/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8047\n",
            "Epoch 6/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8068\n",
            "Epoch 7/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8067\n",
            "Epoch 8/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8080\n",
            "Epoch 9/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8019\n",
            "Epoch 10/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.8020\n",
            "Epoch 11/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8034\n",
            "Epoch 12/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8026\n",
            "Epoch 13/162\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.4538 - accuracy: 0.7946\n",
            "Epoch 14/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8010\n",
            "Epoch 15/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8007\n",
            "Epoch 16/162\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 0.4452 - accuracy: 0.7993\n",
            "Epoch 17/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8048\n",
            "Epoch 18/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.8005\n",
            "Epoch 19/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4426 - accuracy: 0.7986\n",
            "Epoch 20/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8027\n",
            "Epoch 21/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4435 - accuracy: 0.7989\n",
            "Epoch 22/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.8016\n",
            "Epoch 23/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4510 - accuracy: 0.7957\n",
            "Epoch 24/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8015\n",
            "Epoch 25/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.8002\n",
            "Epoch 26/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.8019\n",
            "Epoch 27/162\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 0.4410 - accuracy: 0.8012\n",
            "Epoch 28/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8065\n",
            "Epoch 29/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4432 - accuracy: 0.8020\n",
            "Epoch 30/162\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 0.4597 - accuracy: 0.7914\n",
            "Epoch 31/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4666 - accuracy: 0.7912\n",
            "Epoch 32/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4697 - accuracy: 0.7885\n",
            "Epoch 33/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4581 - accuracy: 0.7957\n",
            "Epoch 34/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4613 - accuracy: 0.7913\n",
            "Epoch 35/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.7916\n",
            "Epoch 36/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4494 - accuracy: 0.7924\n",
            "Epoch 37/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4560 - accuracy: 0.7965\n",
            "Epoch 38/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4513 - accuracy: 0.7961\n",
            "Epoch 39/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.7977\n",
            "Epoch 40/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8022\n",
            "Epoch 41/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7938\n",
            "Epoch 42/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.7908\n",
            "Epoch 43/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4679 - accuracy: 0.7949\n",
            "Epoch 44/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4883 - accuracy: 0.7810\n",
            "Epoch 45/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7934\n",
            "Epoch 46/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4399 - accuracy: 0.8005\n",
            "Epoch 47/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.7901\n",
            "Epoch 48/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5036 - accuracy: 0.7822\n",
            "Epoch 49/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.8003\n",
            "Epoch 50/162\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 0.4631 - accuracy: 0.7989\n",
            "Epoch 51/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4555 - accuracy: 0.7954\n",
            "Epoch 52/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4702 - accuracy: 0.7871\n",
            "Epoch 53/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4708 - accuracy: 0.7904\n",
            "Epoch 54/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4623 - accuracy: 0.7941\n",
            "Epoch 55/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4599 - accuracy: 0.7925\n",
            "Epoch 56/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.7864\n",
            "Epoch 57/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.7993\n",
            "Epoch 58/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4505 - accuracy: 0.8020\n",
            "Epoch 59/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4973 - accuracy: 0.7810\n",
            "Epoch 60/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.7858\n",
            "Epoch 61/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4536 - accuracy: 0.7979\n",
            "Epoch 62/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7867\n",
            "Epoch 63/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5005 - accuracy: 0.7744\n",
            "Epoch 64/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7917\n",
            "Epoch 65/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7930\n",
            "Epoch 66/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7802\n",
            "Epoch 67/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4690 - accuracy: 0.7914\n",
            "Epoch 68/162\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.4682 - accuracy: 0.7921\n",
            "Epoch 69/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4532 - accuracy: 0.7956\n",
            "Epoch 70/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4656 - accuracy: 0.7917\n",
            "Epoch 71/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4769 - accuracy: 0.7899\n",
            "Epoch 72/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.7887\n",
            "Epoch 73/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.7842\n",
            "Epoch 74/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.7912\n",
            "Epoch 75/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4594 - accuracy: 0.7946\n",
            "Epoch 76/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4911 - accuracy: 0.7820\n",
            "Epoch 77/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.7982\n",
            "Epoch 78/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.7854\n",
            "Epoch 79/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4913 - accuracy: 0.7812\n",
            "Epoch 80/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4959 - accuracy: 0.7795\n",
            "Epoch 81/162\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.4607 - accuracy: 0.7901\n",
            "Epoch 82/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.7889\n",
            "Epoch 83/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.7810\n",
            "Epoch 84/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4911 - accuracy: 0.7869\n",
            "Epoch 85/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4708 - accuracy: 0.7885\n",
            "Epoch 86/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4815 - accuracy: 0.7876\n",
            "Epoch 87/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5052 - accuracy: 0.7816\n",
            "Epoch 88/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.7872\n",
            "Epoch 89/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5533 - accuracy: 0.7716\n",
            "Epoch 90/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4560 - accuracy: 0.7994\n",
            "Epoch 91/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4875 - accuracy: 0.7854\n",
            "Epoch 92/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5249 - accuracy: 0.7769\n",
            "Epoch 93/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5078 - accuracy: 0.7811\n",
            "Epoch 94/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4807 - accuracy: 0.7858\n",
            "Epoch 95/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5360 - accuracy: 0.7756\n",
            "Epoch 96/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7918\n",
            "Epoch 97/162\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.4851 - accuracy: 0.7864\n",
            "Epoch 98/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.7879\n",
            "Epoch 99/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4744 - accuracy: 0.7909\n",
            "Epoch 100/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5060 - accuracy: 0.7812\n",
            "Epoch 101/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7760\n",
            "Epoch 102/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.7905\n",
            "Epoch 103/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.7864\n",
            "Epoch 104/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5118 - accuracy: 0.7834\n",
            "Epoch 105/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4521 - accuracy: 0.7932\n",
            "Epoch 106/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4589 - accuracy: 0.7916\n",
            "Epoch 107/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.7791\n",
            "Epoch 108/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.7934\n",
            "Epoch 109/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4904 - accuracy: 0.7818\n",
            "Epoch 110/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5137 - accuracy: 0.7807\n",
            "Epoch 111/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4802 - accuracy: 0.7876\n",
            "Epoch 112/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.7823\n",
            "Epoch 113/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4878 - accuracy: 0.7795\n",
            "Epoch 114/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.7773\n",
            "Epoch 115/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.7803\n",
            "Epoch 116/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7787\n",
            "Epoch 117/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.7794\n",
            "Epoch 118/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5207 - accuracy: 0.7757\n",
            "Epoch 119/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5102 - accuracy: 0.7828\n",
            "Epoch 120/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.7875\n",
            "Epoch 121/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4795 - accuracy: 0.7909\n",
            "Epoch 122/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.7869\n",
            "Epoch 123/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.7798\n",
            "Epoch 124/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5274 - accuracy: 0.7758\n",
            "Epoch 125/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4650 - accuracy: 0.7929\n",
            "Epoch 126/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4707 - accuracy: 0.7901\n",
            "Epoch 127/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7781\n",
            "Epoch 128/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4975 - accuracy: 0.7794\n",
            "Epoch 129/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5074 - accuracy: 0.7827\n",
            "Epoch 130/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.7855\n",
            "Epoch 131/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.7921\n",
            "Epoch 132/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.7762\n",
            "Epoch 133/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5475 - accuracy: 0.7774\n",
            "Epoch 134/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5299 - accuracy: 0.7728\n",
            "Epoch 135/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4768 - accuracy: 0.7908\n",
            "Epoch 136/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4685 - accuracy: 0.7903\n",
            "Epoch 137/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.7925\n",
            "Epoch 138/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7936\n",
            "Epoch 139/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5499 - accuracy: 0.7691\n",
            "Epoch 140/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4780 - accuracy: 0.7802\n",
            "Epoch 141/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7803\n",
            "Epoch 142/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7789\n",
            "Epoch 143/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.7744\n",
            "Epoch 144/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.7827\n",
            "Epoch 145/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4939 - accuracy: 0.7806\n",
            "Epoch 146/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5818 - accuracy: 0.7673\n",
            "Epoch 147/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.7646\n",
            "Epoch 148/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7774\n",
            "Epoch 149/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.7749\n",
            "Epoch 150/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4921 - accuracy: 0.7903\n",
            "Epoch 151/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4836 - accuracy: 0.7924\n",
            "Epoch 152/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7692\n",
            "Epoch 153/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.7794\n",
            "Epoch 154/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4928 - accuracy: 0.7822\n",
            "Epoch 155/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4716 - accuracy: 0.7889\n",
            "Epoch 156/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4890 - accuracy: 0.7861\n",
            "Epoch 157/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4878 - accuracy: 0.7816\n",
            "Epoch 158/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.7749\n",
            "Epoch 159/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.4958 - accuracy: 0.7863\n",
            "Epoch 160/162\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.7892\n",
            "Epoch 161/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.6274 - accuracy: 0.7591\n",
            "Epoch 162/162\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7785\n",
            "23/23 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:17:43,197] Trial 28 finished with value: 0.8628177966101694 and parameters: {'xgb__subsample': 0.6796481552160476, 'xgb__scale_pos_weight': 4.30761933423244, 'xgb__reg_lambda': 3.901631242391485, 'xgb__n_estimators': 462, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.06065027911572771, 'xgb__gamma': 0.2756529773194801, 'xgb__colsample_bytree': 0.7450172723215619, 'rf__n_estimators': 541, 'rf__min_samples_split': 6, 'rf__min_samples_leaf': 4, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 162, 'ann__batch_size': 83, 'ann__learning_rate': 0.0062623498849682865}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 5s 28ms/step - loss: 0.4435 - accuracy: 0.7985\n",
            "Epoch 2/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4611 - accuracy: 0.7929\n",
            "Epoch 3/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4432 - accuracy: 0.7974\n",
            "Epoch 4/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.7929\n",
            "Epoch 5/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4530 - accuracy: 0.7979\n",
            "Epoch 6/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.7952\n",
            "Epoch 7/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4896 - accuracy: 0.7822\n",
            "Epoch 8/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.7846\n",
            "Epoch 9/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.7740\n",
            "Epoch 10/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4871 - accuracy: 0.7838\n",
            "Epoch 11/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6543 - accuracy: 0.7530\n",
            "Epoch 12/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.7786\n",
            "Epoch 13/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5049 - accuracy: 0.7760\n",
            "Epoch 14/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.7838\n",
            "Epoch 15/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4792 - accuracy: 0.7860\n",
            "Epoch 16/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5553 - accuracy: 0.7684\n",
            "Epoch 17/199\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4992 - accuracy: 0.7819\n",
            "Epoch 18/199\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5130 - accuracy: 0.7816\n",
            "Epoch 19/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5853 - accuracy: 0.7701\n",
            "Epoch 20/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5447 - accuracy: 0.7717\n",
            "Epoch 21/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7844\n",
            "Epoch 22/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5288 - accuracy: 0.7799\n",
            "Epoch 23/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4933 - accuracy: 0.7848\n",
            "Epoch 24/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.7765\n",
            "Epoch 25/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4985 - accuracy: 0.7830\n",
            "Epoch 26/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6039 - accuracy: 0.7605\n",
            "Epoch 27/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5622 - accuracy: 0.7695\n",
            "Epoch 28/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5900 - accuracy: 0.7627\n",
            "Epoch 29/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6021 - accuracy: 0.7666\n",
            "Epoch 30/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5634 - accuracy: 0.7654\n",
            "Epoch 31/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7781\n",
            "Epoch 32/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6157 - accuracy: 0.7595\n",
            "Epoch 33/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5056 - accuracy: 0.7819\n",
            "Epoch 34/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5390 - accuracy: 0.7779\n",
            "Epoch 35/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5794 - accuracy: 0.7687\n",
            "Epoch 36/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5795 - accuracy: 0.7722\n",
            "Epoch 37/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6375 - accuracy: 0.7606\n",
            "Epoch 38/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7791\n",
            "Epoch 39/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5452 - accuracy: 0.7760\n",
            "Epoch 40/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5553 - accuracy: 0.7722\n",
            "Epoch 41/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5929 - accuracy: 0.7636\n",
            "Epoch 42/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5645 - accuracy: 0.7658\n",
            "Epoch 43/199\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6185 - accuracy: 0.7679\n",
            "Epoch 44/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6801 - accuracy: 0.7632\n",
            "Epoch 45/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5729 - accuracy: 0.7615\n",
            "Epoch 46/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6578 - accuracy: 0.7609\n",
            "Epoch 47/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6002 - accuracy: 0.7644\n",
            "Epoch 48/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.7742\n",
            "Epoch 49/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5366 - accuracy: 0.7725\n",
            "Epoch 50/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6027 - accuracy: 0.7591\n",
            "Epoch 51/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6017 - accuracy: 0.7677\n",
            "Epoch 52/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5734 - accuracy: 0.7658\n",
            "Epoch 53/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6658 - accuracy: 0.7602\n",
            "Epoch 54/199\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.6738 - accuracy: 0.7542\n",
            "Epoch 55/199\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.5362 - accuracy: 0.7765\n",
            "Epoch 56/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5942 - accuracy: 0.7693\n",
            "Epoch 57/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6903 - accuracy: 0.7545\n",
            "Epoch 58/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6128 - accuracy: 0.7651\n",
            "Epoch 59/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7736\n",
            "Epoch 60/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6433 - accuracy: 0.7573\n",
            "Epoch 61/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6794 - accuracy: 0.7495\n",
            "Epoch 62/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6460 - accuracy: 0.7568\n",
            "Epoch 63/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5868 - accuracy: 0.7704\n",
            "Epoch 64/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6092 - accuracy: 0.7635\n",
            "Epoch 65/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6002 - accuracy: 0.7689\n",
            "Epoch 66/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7007 - accuracy: 0.7650\n",
            "Epoch 67/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6041 - accuracy: 0.7587\n",
            "Epoch 68/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5957 - accuracy: 0.7655\n",
            "Epoch 69/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5636 - accuracy: 0.7692\n",
            "Epoch 70/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5971 - accuracy: 0.7681\n",
            "Epoch 71/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9314 - accuracy: 0.7407\n",
            "Epoch 72/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6691 - accuracy: 0.7587\n",
            "Epoch 73/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6662 - accuracy: 0.7734\n",
            "Epoch 74/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6501 - accuracy: 0.7575\n",
            "Epoch 75/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6318 - accuracy: 0.7642\n",
            "Epoch 76/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6299 - accuracy: 0.7630\n",
            "Epoch 77/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6679 - accuracy: 0.7582\n",
            "Epoch 78/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6572 - accuracy: 0.7609\n",
            "Epoch 79/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6899 - accuracy: 0.7573\n",
            "Epoch 80/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7426 - accuracy: 0.7517\n",
            "Epoch 81/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8555 - accuracy: 0.7389\n",
            "Epoch 82/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7166 - accuracy: 0.7623\n",
            "Epoch 83/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.7627\n",
            "Epoch 84/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6192 - accuracy: 0.7651\n",
            "Epoch 85/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6665 - accuracy: 0.7602\n",
            "Epoch 86/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8468 - accuracy: 0.7526\n",
            "Epoch 87/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7011 - accuracy: 0.7613\n",
            "Epoch 88/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7364 - accuracy: 0.7516\n",
            "Epoch 89/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7230 - accuracy: 0.7587\n",
            "Epoch 90/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7247 - accuracy: 0.7499\n",
            "Epoch 91/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6400 - accuracy: 0.7602\n",
            "Epoch 92/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7796 - accuracy: 0.7491\n",
            "Epoch 93/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8728 - accuracy: 0.7467\n",
            "Epoch 94/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9515 - accuracy: 0.7446\n",
            "Epoch 95/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.7586\n",
            "Epoch 96/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7496 - accuracy: 0.7577\n",
            "Epoch 97/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8028 - accuracy: 0.7499\n",
            "Epoch 98/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.7634\n",
            "Epoch 99/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7073 - accuracy: 0.7499\n",
            "Epoch 100/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8007 - accuracy: 0.7552\n",
            "Epoch 101/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7529 - accuracy: 0.7668\n",
            "Epoch 102/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6335 - accuracy: 0.7646\n",
            "Epoch 103/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6529 - accuracy: 0.7557\n",
            "Epoch 104/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6895 - accuracy: 0.7565\n",
            "Epoch 105/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7428 - accuracy: 0.7509\n",
            "Epoch 106/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7532 - accuracy: 0.7470\n",
            "Epoch 107/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0090 - accuracy: 0.7451\n",
            "Epoch 108/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9586 - accuracy: 0.7544\n",
            "Epoch 109/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7132 - accuracy: 0.7606\n",
            "Epoch 110/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7667 - accuracy: 0.7468\n",
            "Epoch 111/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7841 - accuracy: 0.7552\n",
            "Epoch 112/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7758 - accuracy: 0.7572\n",
            "Epoch 113/199\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.8799 - accuracy: 0.7556\n",
            "Epoch 114/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8101 - accuracy: 0.7554\n",
            "Epoch 115/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7609 - accuracy: 0.7536\n",
            "Epoch 116/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8828 - accuracy: 0.7528\n",
            "Epoch 117/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7545 - accuracy: 0.7681\n",
            "Epoch 118/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6509 - accuracy: 0.7590\n",
            "Epoch 119/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6786 - accuracy: 0.7595\n",
            "Epoch 120/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7051 - accuracy: 0.7569\n",
            "Epoch 121/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8285 - accuracy: 0.7448\n",
            "Epoch 122/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8204 - accuracy: 0.7552\n",
            "Epoch 123/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8012 - accuracy: 0.7532\n",
            "Epoch 124/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7039 - accuracy: 0.7578\n",
            "Epoch 125/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9390 - accuracy: 0.7481\n",
            "Epoch 126/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8310 - accuracy: 0.7448\n",
            "Epoch 127/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7032 - accuracy: 0.7638\n",
            "Epoch 128/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6943 - accuracy: 0.7500\n",
            "Epoch 129/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7295 - accuracy: 0.7586\n",
            "Epoch 130/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7474 - accuracy: 0.7509\n",
            "Epoch 131/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8661 - accuracy: 0.7458\n",
            "Epoch 132/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9136 - accuracy: 0.7439\n",
            "Epoch 133/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9403 - accuracy: 0.7464\n",
            "Epoch 134/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7808 - accuracy: 0.7553\n",
            "Epoch 135/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9475 - accuracy: 0.7464\n",
            "Epoch 136/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9309 - accuracy: 0.7434\n",
            "Epoch 137/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7689 - accuracy: 0.7550\n",
            "Epoch 138/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7868 - accuracy: 0.7577\n",
            "Epoch 139/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7399 - accuracy: 0.7620\n",
            "Epoch 140/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7900 - accuracy: 0.7491\n",
            "Epoch 141/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9214 - accuracy: 0.7439\n",
            "Epoch 142/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8434 - accuracy: 0.7545\n",
            "Epoch 143/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0073 - accuracy: 0.7419\n",
            "Epoch 144/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.1434 - accuracy: 0.7444\n",
            "Epoch 145/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9243 - accuracy: 0.7544\n",
            "Epoch 146/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.2861 - accuracy: 0.7467\n",
            "Epoch 147/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8992 - accuracy: 0.7492\n",
            "Epoch 148/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8095 - accuracy: 0.7541\n",
            "Epoch 149/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7474 - accuracy: 0.7542\n",
            "Epoch 150/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9304 - accuracy: 0.7520\n",
            "Epoch 151/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7888 - accuracy: 0.7450\n",
            "Epoch 152/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8212 - accuracy: 0.7515\n",
            "Epoch 153/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7900 - accuracy: 0.7499\n",
            "Epoch 154/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6954 - accuracy: 0.7564\n",
            "Epoch 155/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9089 - accuracy: 0.7481\n",
            "Epoch 156/199\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 1.0708 - accuracy: 0.7428\n",
            "Epoch 157/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.4216 - accuracy: 0.7327\n",
            "Epoch 158/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8471 - accuracy: 0.7489\n",
            "Epoch 159/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8555 - accuracy: 0.7484\n",
            "Epoch 160/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8597 - accuracy: 0.7587\n",
            "Epoch 161/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.1763 - accuracy: 0.7373\n",
            "Epoch 162/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8661 - accuracy: 0.7564\n",
            "Epoch 163/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0765 - accuracy: 0.7497\n",
            "Epoch 164/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0930 - accuracy: 0.7428\n",
            "Epoch 165/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9091 - accuracy: 0.7489\n",
            "Epoch 166/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9111 - accuracy: 0.7394\n",
            "Epoch 167/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9993 - accuracy: 0.7479\n",
            "Epoch 168/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9665 - accuracy: 0.7425\n",
            "Epoch 169/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9350 - accuracy: 0.7495\n",
            "Epoch 170/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9085 - accuracy: 0.7464\n",
            "Epoch 171/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9824 - accuracy: 0.7446\n",
            "Epoch 172/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.1346 - accuracy: 0.7438\n",
            "Epoch 173/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.2236 - accuracy: 0.7558\n",
            "Epoch 174/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7545 - accuracy: 0.7589\n",
            "Epoch 175/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8947 - accuracy: 0.7511\n",
            "Epoch 176/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0011 - accuracy: 0.7406\n",
            "Epoch 177/199\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 1.4009 - accuracy: 0.7382\n",
            "Epoch 178/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0397 - accuracy: 0.7438\n",
            "Epoch 179/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.1133 - accuracy: 0.7405\n",
            "Epoch 180/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0679 - accuracy: 0.7448\n",
            "Epoch 181/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0225 - accuracy: 0.7521\n",
            "Epoch 182/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.4842 - accuracy: 0.7338\n",
            "Epoch 183/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9006 - accuracy: 0.7517\n",
            "Epoch 184/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0323 - accuracy: 0.7480\n",
            "Epoch 185/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9389 - accuracy: 0.7493\n",
            "Epoch 186/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.3154 - accuracy: 0.7394\n",
            "Epoch 187/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8487 - accuracy: 0.7623\n",
            "Epoch 188/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8986 - accuracy: 0.7462\n",
            "Epoch 189/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9788 - accuracy: 0.7515\n",
            "Epoch 190/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.0299 - accuracy: 0.7501\n",
            "Epoch 191/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8194 - accuracy: 0.7523\n",
            "Epoch 192/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.7551 - accuracy: 0.7548\n",
            "Epoch 193/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.4662 - accuracy: 0.7357\n",
            "Epoch 194/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9198 - accuracy: 0.7553\n",
            "Epoch 195/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9433 - accuracy: 0.7496\n",
            "Epoch 196/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 1.1072 - accuracy: 0.7464\n",
            "Epoch 197/199\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.9490 - accuracy: 0.7456\n",
            "Epoch 198/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.9666 - accuracy: 0.7491\n",
            "Epoch 199/199\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.8148 - accuracy: 0.7569\n",
            "23/23 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:19:55,272] Trial 29 finished with value: 0.847457627118644 and parameters: {'xgb__subsample': 0.8944563447949043, 'xgb__scale_pos_weight': 3.0034327364666735, 'xgb__reg_lambda': 5.369362851590323, 'xgb__n_estimators': 996, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.048229492421175656, 'xgb__gamma': 0.1529591938006843, 'xgb__colsample_bytree': 0.8942410313306042, 'rf__n_estimators': 699, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 2, 'rf__max_depth': 8, 'rf__bootstrap': True, 'ann__epochs': 199, 'ann__batch_size': 84, 'ann__learning_rate': 0.026003528990254293}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74/74 [==============================] - 5s 34ms/step - loss: 0.4524 - accuracy: 0.7859\n",
            "Epoch 2/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8073\n",
            "Epoch 3/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8091\n",
            "Epoch 4/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8056\n",
            "Epoch 5/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8075\n",
            "Epoch 6/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8085\n",
            "Epoch 7/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8057\n",
            "Epoch 8/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8060\n",
            "Epoch 9/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.8057\n",
            "Epoch 10/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8044\n",
            "Epoch 11/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8008\n",
            "Epoch 12/125\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4343 - accuracy: 0.8030\n",
            "Epoch 13/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8019\n",
            "Epoch 14/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8027\n",
            "Epoch 15/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.8032\n",
            "Epoch 16/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8092\n",
            "Epoch 17/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.8065\n",
            "Epoch 18/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8064\n",
            "Epoch 19/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8020\n",
            "Epoch 20/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8050\n",
            "Epoch 21/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8081\n",
            "Epoch 22/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8051\n",
            "Epoch 23/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.8012\n",
            "Epoch 24/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7959\n",
            "Epoch 25/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8015\n",
            "Epoch 26/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.8047\n",
            "Epoch 27/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.7999\n",
            "Epoch 28/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.8007\n",
            "Epoch 29/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.8026\n",
            "Epoch 30/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.7967\n",
            "Epoch 31/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8024\n",
            "Epoch 32/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.8005\n",
            "Epoch 33/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7865\n",
            "Epoch 34/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7965\n",
            "Epoch 35/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7987\n",
            "Epoch 36/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4474 - accuracy: 0.7953\n",
            "Epoch 37/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8068\n",
            "Epoch 38/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8011\n",
            "Epoch 39/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.8012\n",
            "Epoch 40/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7995\n",
            "Epoch 41/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.7959\n",
            "Epoch 42/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8014\n",
            "Epoch 43/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.7973\n",
            "Epoch 44/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.7958\n",
            "Epoch 45/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4402 - accuracy: 0.8007\n",
            "Epoch 46/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8023\n",
            "Epoch 47/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.7981\n",
            "Epoch 48/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4602 - accuracy: 0.7954\n",
            "Epoch 49/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4482 - accuracy: 0.7994\n",
            "Epoch 50/125\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.7994\n",
            "Epoch 51/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4799 - accuracy: 0.7883\n",
            "Epoch 52/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.7908\n",
            "Epoch 53/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4559 - accuracy: 0.7909\n",
            "Epoch 54/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.8024\n",
            "Epoch 55/125\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4581 - accuracy: 0.7925\n",
            "Epoch 56/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.7977\n",
            "Epoch 57/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.7963\n",
            "Epoch 58/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4622 - accuracy: 0.7896\n",
            "Epoch 59/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4669 - accuracy: 0.7914\n",
            "Epoch 60/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8005\n",
            "Epoch 61/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8024\n",
            "Epoch 62/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.8015\n",
            "Epoch 63/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4545 - accuracy: 0.7961\n",
            "Epoch 64/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.7888\n",
            "Epoch 65/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.7933\n",
            "Epoch 66/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7836\n",
            "Epoch 67/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7974\n",
            "Epoch 68/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7948\n",
            "Epoch 69/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4956 - accuracy: 0.7834\n",
            "Epoch 70/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4870 - accuracy: 0.7832\n",
            "Epoch 71/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7903\n",
            "Epoch 72/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.8007\n",
            "Epoch 73/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.7942\n",
            "Epoch 74/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7954\n",
            "Epoch 75/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.7946\n",
            "Epoch 76/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4597 - accuracy: 0.7910\n",
            "Epoch 77/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4485 - accuracy: 0.7958\n",
            "Epoch 78/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.7926\n",
            "Epoch 79/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8016\n",
            "Epoch 80/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4680 - accuracy: 0.7892\n",
            "Epoch 81/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4807 - accuracy: 0.7877\n",
            "Epoch 82/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7949\n",
            "Epoch 83/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7971\n",
            "Epoch 84/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7929\n",
            "Epoch 85/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4997 - accuracy: 0.7803\n",
            "Epoch 86/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4646 - accuracy: 0.7957\n",
            "Epoch 87/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7859\n",
            "Epoch 88/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7752\n",
            "Epoch 89/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7946\n",
            "Epoch 90/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.7876\n",
            "Epoch 91/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7956\n",
            "Epoch 92/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4893 - accuracy: 0.7856\n",
            "Epoch 93/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7925\n",
            "Epoch 94/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4569 - accuracy: 0.7953\n",
            "Epoch 95/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8016\n",
            "Epoch 96/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.7986\n",
            "Epoch 97/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7994\n",
            "Epoch 98/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7889\n",
            "Epoch 99/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7875\n",
            "Epoch 100/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4795 - accuracy: 0.7880\n",
            "Epoch 101/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7970\n",
            "Epoch 102/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.7764\n",
            "Epoch 103/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5002 - accuracy: 0.7830\n",
            "Epoch 104/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.7952\n",
            "Epoch 105/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4876 - accuracy: 0.7873\n",
            "Epoch 106/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7998\n",
            "Epoch 107/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.7855\n",
            "Epoch 108/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.7942\n",
            "Epoch 109/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.8005\n",
            "Epoch 110/125\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4550 - accuracy: 0.7946\n",
            "Epoch 111/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4620 - accuracy: 0.7884\n",
            "Epoch 112/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4818 - accuracy: 0.7827\n",
            "Epoch 113/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4631 - accuracy: 0.7936\n",
            "Epoch 114/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4872 - accuracy: 0.7835\n",
            "Epoch 115/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7987\n",
            "Epoch 116/125\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.7863\n",
            "Epoch 117/125\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4983 - accuracy: 0.7881\n",
            "Epoch 118/125\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5102 - accuracy: 0.7823\n",
            "Epoch 119/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7920\n",
            "Epoch 120/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7928\n",
            "Epoch 121/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4902 - accuracy: 0.7859\n",
            "Epoch 122/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5339 - accuracy: 0.7745\n",
            "Epoch 123/125\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4700 - accuracy: 0.7869\n",
            "Epoch 124/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7836\n",
            "Epoch 125/125\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7864\n",
            "19/19 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:21:06,296] Trial 30 finished with value: 0.8686440677966102 and parameters: {'xgb__subsample': 0.7802622363487499, 'xgb__scale_pos_weight': 2.294968562561012, 'xgb__reg_lambda': 2.5207419942246023, 'xgb__n_estimators': 689, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.08849834303910886, 'xgb__gamma': 0.31523449141998794, 'xgb__colsample_bytree': 0.8275813419316955, 'rf__n_estimators': 436, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 7, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 125, 'ann__batch_size': 103, 'ann__learning_rate': 0.005607334214798402}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - 6s 34ms/step - loss: 0.4423 - accuracy: 0.7934\n",
            "Epoch 2/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4237 - accuracy: 0.8084\n",
            "Epoch 3/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8101\n",
            "Epoch 4/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8068\n",
            "Epoch 5/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8105\n",
            "Epoch 6/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8088\n",
            "Epoch 7/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8072\n",
            "Epoch 8/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8050\n",
            "Epoch 9/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.8096\n",
            "Epoch 10/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7994\n",
            "Epoch 11/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8057\n",
            "Epoch 12/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8079\n",
            "Epoch 13/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8061\n",
            "Epoch 14/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8080\n",
            "Epoch 15/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8076\n",
            "Epoch 16/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7995\n",
            "Epoch 17/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8055\n",
            "Epoch 18/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8015\n",
            "Epoch 19/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8059\n",
            "Epoch 20/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4335 - accuracy: 0.8100\n",
            "Epoch 21/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8067\n",
            "Epoch 22/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8071\n",
            "Epoch 23/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8076\n",
            "Epoch 24/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7994\n",
            "Epoch 25/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4628 - accuracy: 0.7893\n",
            "Epoch 26/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8030\n",
            "Epoch 27/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8005\n",
            "Epoch 28/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7959\n",
            "Epoch 29/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8005\n",
            "Epoch 30/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8038\n",
            "Epoch 31/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8052\n",
            "Epoch 32/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8044\n",
            "Epoch 33/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7991\n",
            "Epoch 34/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8059\n",
            "Epoch 35/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7948\n",
            "Epoch 36/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8006\n",
            "Epoch 37/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.7998\n",
            "Epoch 38/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4500 - accuracy: 0.7948\n",
            "Epoch 39/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8019\n",
            "Epoch 40/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.8035\n",
            "Epoch 41/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7900\n",
            "Epoch 42/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7924\n",
            "Epoch 43/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4516 - accuracy: 0.7997\n",
            "Epoch 44/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.8044\n",
            "Epoch 45/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7973\n",
            "Epoch 46/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8085\n",
            "Epoch 47/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7998\n",
            "Epoch 48/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7994\n",
            "Epoch 49/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.7942\n",
            "Epoch 50/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7987\n",
            "Epoch 51/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7986\n",
            "Epoch 52/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.8034\n",
            "Epoch 53/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.7897\n",
            "Epoch 54/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4521 - accuracy: 0.7956\n",
            "Epoch 55/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7989\n",
            "Epoch 56/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7961\n",
            "Epoch 57/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8015\n",
            "Epoch 58/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7918\n",
            "Epoch 59/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7963\n",
            "Epoch 60/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7920\n",
            "Epoch 61/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.7991\n",
            "Epoch 62/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7901\n",
            "Epoch 63/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4609 - accuracy: 0.7922\n",
            "Epoch 64/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4562 - accuracy: 0.7917\n",
            "Epoch 65/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.7893\n",
            "Epoch 66/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.7974\n",
            "Epoch 67/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7913\n",
            "Epoch 68/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4718 - accuracy: 0.7903\n",
            "Epoch 69/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.7974\n",
            "Epoch 70/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.7948\n",
            "Epoch 71/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.8015\n",
            "Epoch 72/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7994\n",
            "Epoch 73/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.7941\n",
            "Epoch 74/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.7970\n",
            "Epoch 75/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7954\n",
            "Epoch 76/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4571 - accuracy: 0.7967\n",
            "Epoch 77/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4761 - accuracy: 0.7806\n",
            "Epoch 78/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7918\n",
            "Epoch 79/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7985\n",
            "Epoch 80/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4600 - accuracy: 0.7892\n",
            "Epoch 81/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4529 - accuracy: 0.7956\n",
            "Epoch 82/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7938\n",
            "Epoch 83/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4490 - accuracy: 0.7973\n",
            "Epoch 84/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7904\n",
            "Epoch 85/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7918\n",
            "Epoch 86/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7983\n",
            "Epoch 87/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7985\n",
            "Epoch 88/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.7924\n",
            "Epoch 89/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4871 - accuracy: 0.7891\n",
            "Epoch 90/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7893\n",
            "Epoch 91/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.5047 - accuracy: 0.7798\n",
            "Epoch 92/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7982\n",
            "Epoch 93/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4715 - accuracy: 0.7891\n",
            "Epoch 94/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7905\n",
            "Epoch 95/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7940\n",
            "Epoch 96/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7991\n",
            "Epoch 97/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4465 - accuracy: 0.7959\n",
            "Epoch 98/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4600 - accuracy: 0.7979\n",
            "Epoch 99/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4472 - accuracy: 0.7925\n",
            "Epoch 100/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7925\n",
            "Epoch 101/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4794 - accuracy: 0.7865\n",
            "Epoch 102/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.5091 - accuracy: 0.7811\n",
            "Epoch 103/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7921\n",
            "Epoch 104/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.7885\n",
            "Epoch 105/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7989\n",
            "Epoch 106/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7897\n",
            "Epoch 107/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7989\n",
            "Epoch 108/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7913\n",
            "Epoch 109/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.7934\n",
            "Epoch 110/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7994\n",
            "Epoch 111/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7946\n",
            "Epoch 112/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.4621 - accuracy: 0.7887\n",
            "Epoch 113/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4804 - accuracy: 0.7843\n",
            "Epoch 114/124\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7914\n",
            "Epoch 115/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.5042 - accuracy: 0.7811\n",
            "Epoch 116/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.7852\n",
            "Epoch 117/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7879\n",
            "Epoch 118/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7949\n",
            "Epoch 119/124\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.5029 - accuracy: 0.7811\n",
            "Epoch 120/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4985 - accuracy: 0.7823\n",
            "Epoch 121/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7888\n",
            "Epoch 122/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7900\n",
            "Epoch 123/124\n",
            "73/73 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.7858\n",
            "Epoch 124/124\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4757 - accuracy: 0.7856\n",
            "19/19 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:22:15,029] Trial 31 finished with value: 0.8649364406779662 and parameters: {'xgb__subsample': 0.7802794382253256, 'xgb__scale_pos_weight': 2.1688848021834657, 'xgb__reg_lambda': 2.5128931397784253, 'xgb__n_estimators': 686, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.08153677383053644, 'xgb__gamma': 0.30070429512340724, 'xgb__colsample_bytree': 0.8241908723618125, 'rf__n_estimators': 430, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 7, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 124, 'ann__batch_size': 104, 'ann__learning_rate': 0.005371742830560267}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - 6s 31ms/step - loss: 0.4453 - accuracy: 0.7938\n",
            "Epoch 2/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8030\n",
            "Epoch 3/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8057\n",
            "Epoch 4/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8038\n",
            "Epoch 5/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.7962\n",
            "Epoch 6/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8008\n",
            "Epoch 7/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4425 - accuracy: 0.8008\n",
            "Epoch 8/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8024\n",
            "Epoch 9/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.8010\n",
            "Epoch 10/104\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.4678 - accuracy: 0.7920\n",
            "Epoch 11/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.7879\n",
            "Epoch 12/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4553 - accuracy: 0.7954\n",
            "Epoch 13/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4617 - accuracy: 0.7936\n",
            "Epoch 14/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4622 - accuracy: 0.7920\n",
            "Epoch 15/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.7926\n",
            "Epoch 16/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4696 - accuracy: 0.7893\n",
            "Epoch 17/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4840 - accuracy: 0.7826\n",
            "Epoch 18/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.7963\n",
            "Epoch 19/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7786\n",
            "Epoch 20/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4761 - accuracy: 0.7854\n",
            "Epoch 21/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.7938\n",
            "Epoch 22/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4678 - accuracy: 0.7885\n",
            "Epoch 23/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5227 - accuracy: 0.7730\n",
            "Epoch 24/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.8051\n",
            "Epoch 25/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4642 - accuracy: 0.7948\n",
            "Epoch 26/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4943 - accuracy: 0.7797\n",
            "Epoch 27/104\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.7863\n",
            "Epoch 28/104\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.5115 - accuracy: 0.7785\n",
            "Epoch 29/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.7820\n",
            "Epoch 30/104\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.4998 - accuracy: 0.7834\n",
            "Epoch 31/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.7815\n",
            "Epoch 32/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4825 - accuracy: 0.7880\n",
            "Epoch 33/104\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.4964 - accuracy: 0.7847\n",
            "Epoch 34/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.7847\n",
            "Epoch 35/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.7854\n",
            "Epoch 36/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5303 - accuracy: 0.7806\n",
            "Epoch 37/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5126 - accuracy: 0.7762\n",
            "Epoch 38/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4985 - accuracy: 0.7852\n",
            "Epoch 39/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5202 - accuracy: 0.7757\n",
            "Epoch 40/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4963 - accuracy: 0.7826\n",
            "Epoch 41/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6035 - accuracy: 0.7634\n",
            "Epoch 42/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5624 - accuracy: 0.7688\n",
            "Epoch 43/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.7835\n",
            "Epoch 44/104\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.4824 - accuracy: 0.7897\n",
            "Epoch 45/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.7749\n",
            "Epoch 46/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4909 - accuracy: 0.7846\n",
            "Epoch 47/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7770\n",
            "Epoch 48/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7752\n",
            "Epoch 49/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4875 - accuracy: 0.7838\n",
            "Epoch 50/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7761\n",
            "Epoch 51/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4696 - accuracy: 0.7969\n",
            "Epoch 52/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.7762\n",
            "Epoch 53/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7724\n",
            "Epoch 54/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4839 - accuracy: 0.7895\n",
            "Epoch 55/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5582 - accuracy: 0.7717\n",
            "Epoch 56/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4935 - accuracy: 0.7858\n",
            "Epoch 57/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5138 - accuracy: 0.7781\n",
            "Epoch 58/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.7774\n",
            "Epoch 59/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.7715\n",
            "Epoch 60/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7775\n",
            "Epoch 61/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7738\n",
            "Epoch 62/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6112 - accuracy: 0.7658\n",
            "Epoch 63/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5043 - accuracy: 0.7860\n",
            "Epoch 64/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5894 - accuracy: 0.7671\n",
            "Epoch 65/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.7814\n",
            "Epoch 66/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.7677\n",
            "Epoch 67/104\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.4984 - accuracy: 0.7842\n",
            "Epoch 68/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5747 - accuracy: 0.7708\n",
            "Epoch 69/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.7809\n",
            "Epoch 70/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5964 - accuracy: 0.7655\n",
            "Epoch 71/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4989 - accuracy: 0.7812\n",
            "Epoch 72/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5097 - accuracy: 0.7793\n",
            "Epoch 73/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5039 - accuracy: 0.7809\n",
            "Epoch 74/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.7749\n",
            "Epoch 75/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.7722\n",
            "Epoch 76/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7806\n",
            "Epoch 77/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7732\n",
            "Epoch 78/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6667 - accuracy: 0.7570\n",
            "Epoch 79/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7722\n",
            "Epoch 80/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7730\n",
            "Epoch 81/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7876\n",
            "Epoch 82/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5764 - accuracy: 0.7663\n",
            "Epoch 83/104\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.6049 - accuracy: 0.7683\n",
            "Epoch 84/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.7672\n",
            "Epoch 85/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5733 - accuracy: 0.7699\n",
            "Epoch 86/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5764 - accuracy: 0.7712\n",
            "Epoch 87/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.7703\n",
            "Epoch 88/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.7884\n",
            "Epoch 89/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.7805\n",
            "Epoch 90/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5911 - accuracy: 0.7668\n",
            "Epoch 91/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6109 - accuracy: 0.7660\n",
            "Epoch 92/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6024 - accuracy: 0.7627\n",
            "Epoch 93/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6615 - accuracy: 0.7609\n",
            "Epoch 94/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6029 - accuracy: 0.7662\n",
            "Epoch 95/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6122 - accuracy: 0.7672\n",
            "Epoch 96/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5791 - accuracy: 0.7659\n",
            "Epoch 97/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5636 - accuracy: 0.7704\n",
            "Epoch 98/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7799\n",
            "Epoch 99/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5479 - accuracy: 0.7699\n",
            "Epoch 100/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5925 - accuracy: 0.7696\n",
            "Epoch 101/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5446 - accuracy: 0.7789\n",
            "Epoch 102/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.7786\n",
            "Epoch 103/104\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.7575\n",
            "Epoch 104/104\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6016 - accuracy: 0.7642\n",
            "22/22 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:23:23,550] Trial 32 finished with value: 0.8569915254237288 and parameters: {'xgb__subsample': 0.9320733959418366, 'xgb__scale_pos_weight': 3.334090077467118, 'xgb__reg_lambda': 1.6648714830218339, 'xgb__n_estimators': 597, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.08898539583194555, 'xgb__gamma': 0.22459085896375522, 'xgb__colsample_bytree': 0.9272990188894862, 'rf__n_estimators': 536, 'rf__min_samples_split': 6, 'rf__min_samples_leaf': 3, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 104, 'ann__batch_size': 88, 'ann__learning_rate': 0.013247788914743907}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 6s 27ms/step - loss: 0.4435 - accuracy: 0.7977\n",
            "Epoch 2/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8097\n",
            "Epoch 3/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8018\n",
            "Epoch 4/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8089\n",
            "Epoch 5/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8044\n",
            "Epoch 6/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8055\n",
            "Epoch 7/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8079\n",
            "Epoch 8/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8031\n",
            "Epoch 9/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.7994\n",
            "Epoch 10/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.8010\n",
            "Epoch 11/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8040\n",
            "Epoch 12/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4445 - accuracy: 0.7983\n",
            "Epoch 13/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.8053\n",
            "Epoch 14/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4461 - accuracy: 0.7959\n",
            "Epoch 15/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4375 - accuracy: 0.8019\n",
            "Epoch 16/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.7997\n",
            "Epoch 17/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8052\n",
            "Epoch 18/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8034\n",
            "Epoch 19/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4465 - accuracy: 0.7982\n",
            "Epoch 20/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8051\n",
            "Epoch 21/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.8014\n",
            "Epoch 22/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4577 - accuracy: 0.7926\n",
            "Epoch 23/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.7991\n",
            "Epoch 24/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4642 - accuracy: 0.7982\n",
            "Epoch 25/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.8008\n",
            "Epoch 26/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4427 - accuracy: 0.7985\n",
            "Epoch 27/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4532 - accuracy: 0.7995\n",
            "Epoch 28/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.7942\n",
            "Epoch 29/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4562 - accuracy: 0.7953\n",
            "Epoch 30/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.7987\n",
            "Epoch 31/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.7953\n",
            "Epoch 32/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4594 - accuracy: 0.7953\n",
            "Epoch 33/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4493 - accuracy: 0.7938\n",
            "Epoch 34/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.7975\n",
            "Epoch 35/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4526 - accuracy: 0.7965\n",
            "Epoch 36/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4429 - accuracy: 0.8035\n",
            "Epoch 37/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.8010\n",
            "Epoch 38/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4722 - accuracy: 0.7892\n",
            "Epoch 39/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4625 - accuracy: 0.7895\n",
            "Epoch 40/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4626 - accuracy: 0.7905\n",
            "Epoch 41/124\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4841 - accuracy: 0.7794\n",
            "Epoch 42/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4341 - accuracy: 0.8040\n",
            "Epoch 43/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.7885\n",
            "Epoch 44/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.7824\n",
            "Epoch 45/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4588 - accuracy: 0.7989\n",
            "Epoch 46/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.7916\n",
            "Epoch 47/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8039\n",
            "Epoch 48/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.7918\n",
            "Epoch 49/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4543 - accuracy: 0.7952\n",
            "Epoch 50/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.7970\n",
            "Epoch 51/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.7965\n",
            "Epoch 52/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4570 - accuracy: 0.7926\n",
            "Epoch 53/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4584 - accuracy: 0.7949\n",
            "Epoch 54/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4751 - accuracy: 0.7855\n",
            "Epoch 55/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4523 - accuracy: 0.7995\n",
            "Epoch 56/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.7863\n",
            "Epoch 57/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.7918\n",
            "Epoch 58/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.7891\n",
            "Epoch 59/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.7893\n",
            "Epoch 60/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4841 - accuracy: 0.7851\n",
            "Epoch 61/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4720 - accuracy: 0.7881\n",
            "Epoch 62/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4709 - accuracy: 0.7893\n",
            "Epoch 63/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4714 - accuracy: 0.7900\n",
            "Epoch 64/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4624 - accuracy: 0.7940\n",
            "Epoch 65/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4855 - accuracy: 0.7869\n",
            "Epoch 66/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.7930\n",
            "Epoch 67/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7864\n",
            "Epoch 68/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4897 - accuracy: 0.7854\n",
            "Epoch 69/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4692 - accuracy: 0.7893\n",
            "Epoch 70/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.7834\n",
            "Epoch 71/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4858 - accuracy: 0.7872\n",
            "Epoch 72/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4843 - accuracy: 0.7816\n",
            "Epoch 73/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4702 - accuracy: 0.7908\n",
            "Epoch 74/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7912\n",
            "Epoch 75/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5008 - accuracy: 0.7835\n",
            "Epoch 76/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.7864\n",
            "Epoch 77/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4566 - accuracy: 0.7950\n",
            "Epoch 78/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4909 - accuracy: 0.7838\n",
            "Epoch 79/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5064 - accuracy: 0.7789\n",
            "Epoch 80/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4708 - accuracy: 0.7909\n",
            "Epoch 81/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.7875\n",
            "Epoch 82/124\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4520 - accuracy: 0.7941\n",
            "Epoch 83/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7903\n",
            "Epoch 84/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4772 - accuracy: 0.7868\n",
            "Epoch 85/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4721 - accuracy: 0.7893\n",
            "Epoch 86/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4584 - accuracy: 0.7937\n",
            "Epoch 87/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4846 - accuracy: 0.7895\n",
            "Epoch 88/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.7907\n",
            "Epoch 89/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4713 - accuracy: 0.7933\n",
            "Epoch 90/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4987 - accuracy: 0.7851\n",
            "Epoch 91/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7790\n",
            "Epoch 92/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7865\n",
            "Epoch 93/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4565 - accuracy: 0.7975\n",
            "Epoch 94/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.7925\n",
            "Epoch 95/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4704 - accuracy: 0.7938\n",
            "Epoch 96/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4875 - accuracy: 0.7913\n",
            "Epoch 97/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4895 - accuracy: 0.7861\n",
            "Epoch 98/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7893\n",
            "Epoch 99/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4831 - accuracy: 0.7863\n",
            "Epoch 100/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5170 - accuracy: 0.7738\n",
            "Epoch 101/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.7709\n",
            "Epoch 102/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4814 - accuracy: 0.7885\n",
            "Epoch 103/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7865\n",
            "Epoch 104/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5703 - accuracy: 0.7677\n",
            "Epoch 105/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4877 - accuracy: 0.7855\n",
            "Epoch 106/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4678 - accuracy: 0.7892\n",
            "Epoch 107/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5216 - accuracy: 0.7775\n",
            "Epoch 108/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.7713\n",
            "Epoch 109/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.7865\n",
            "Epoch 110/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.7863\n",
            "Epoch 111/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.7929\n",
            "Epoch 112/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.7819\n",
            "Epoch 113/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4780 - accuracy: 0.7885\n",
            "Epoch 114/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7920\n",
            "Epoch 115/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4807 - accuracy: 0.7864\n",
            "Epoch 116/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5076 - accuracy: 0.7868\n",
            "Epoch 117/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4821 - accuracy: 0.7844\n",
            "Epoch 118/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5320 - accuracy: 0.7738\n",
            "Epoch 119/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5015 - accuracy: 0.7806\n",
            "Epoch 120/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.7816\n",
            "Epoch 121/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4829 - accuracy: 0.7921\n",
            "Epoch 122/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.7851\n",
            "Epoch 123/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.7873\n",
            "Epoch 124/124\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7746\n",
            "28/28 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:25:04,146] Trial 33 finished with value: 0.8490466101694916 and parameters: {'xgb__subsample': 0.8452408044748115, 'xgb__scale_pos_weight': 2.672730581248163, 'xgb__reg_lambda': 3.317083507286352, 'xgb__n_estimators': 784, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.04233659152501282, 'xgb__gamma': 0.08422929918718786, 'xgb__colsample_bytree': 0.870874587788185, 'rf__n_estimators': 620, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 5, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 124, 'ann__batch_size': 69, 'ann__learning_rate': 0.005707188257390968}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72/72 [==============================] - 6s 41ms/step - loss: 0.4481 - accuracy: 0.7926\n",
            "Epoch 2/76\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4563 - accuracy: 0.7970\n",
            "Epoch 3/76\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.8018\n",
            "Epoch 4/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8028\n",
            "Epoch 5/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4437 - accuracy: 0.8030\n",
            "Epoch 6/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4565 - accuracy: 0.7936\n",
            "Epoch 7/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.7925\n",
            "Epoch 8/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7966\n",
            "Epoch 9/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7905\n",
            "Epoch 10/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4888 - accuracy: 0.7883\n",
            "Epoch 11/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7858\n",
            "Epoch 12/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.8022\n",
            "Epoch 13/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7896\n",
            "Epoch 14/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4680 - accuracy: 0.7880\n",
            "Epoch 15/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7826\n",
            "Epoch 16/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7840\n",
            "Epoch 17/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5252 - accuracy: 0.7819\n",
            "Epoch 18/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7885\n",
            "Epoch 19/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7888\n",
            "Epoch 20/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.7920\n",
            "Epoch 21/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7847\n",
            "Epoch 22/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.7724\n",
            "Epoch 23/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7864\n",
            "Epoch 24/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7722\n",
            "Epoch 25/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7802\n",
            "Epoch 26/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4660 - accuracy: 0.7912\n",
            "Epoch 27/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.7942\n",
            "Epoch 28/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.7660\n",
            "Epoch 29/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.7850\n",
            "Epoch 30/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5469 - accuracy: 0.7736\n",
            "Epoch 31/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5683 - accuracy: 0.7681\n",
            "Epoch 32/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5657 - accuracy: 0.7699\n",
            "Epoch 33/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7749\n",
            "Epoch 34/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7761\n",
            "Epoch 35/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6384 - accuracy: 0.7602\n",
            "Epoch 36/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.7638\n",
            "Epoch 37/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5200 - accuracy: 0.7803\n",
            "Epoch 38/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5122 - accuracy: 0.7807\n",
            "Epoch 39/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7754\n",
            "Epoch 40/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.7620\n",
            "Epoch 41/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7744\n",
            "Epoch 42/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5551 - accuracy: 0.7680\n",
            "Epoch 43/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7863\n",
            "Epoch 44/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5874 - accuracy: 0.7639\n",
            "Epoch 45/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5519 - accuracy: 0.7712\n",
            "Epoch 46/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.7745\n",
            "Epoch 47/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.7745\n",
            "Epoch 48/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7722\n",
            "Epoch 49/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5860 - accuracy: 0.7646\n",
            "Epoch 50/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.7619\n",
            "Epoch 51/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.7830\n",
            "Epoch 52/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5959 - accuracy: 0.7597\n",
            "Epoch 53/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5981 - accuracy: 0.7708\n",
            "Epoch 54/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5277 - accuracy: 0.7781\n",
            "Epoch 55/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7783\n",
            "Epoch 56/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.7589\n",
            "Epoch 57/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.7687\n",
            "Epoch 58/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5307 - accuracy: 0.7797\n",
            "Epoch 59/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5578 - accuracy: 0.7660\n",
            "Epoch 60/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6539 - accuracy: 0.7549\n",
            "Epoch 61/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5477 - accuracy: 0.7656\n",
            "Epoch 62/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6279 - accuracy: 0.7519\n",
            "Epoch 63/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.7722\n",
            "Epoch 64/76\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5570 - accuracy: 0.7699\n",
            "Epoch 65/76\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5962 - accuracy: 0.7646\n",
            "Epoch 66/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.7486 - accuracy: 0.7491\n",
            "Epoch 67/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6725 - accuracy: 0.7582\n",
            "Epoch 68/76\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6199 - accuracy: 0.7658\n",
            "Epoch 69/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6574 - accuracy: 0.7627\n",
            "Epoch 70/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6088 - accuracy: 0.7636\n",
            "Epoch 71/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5597 - accuracy: 0.7757\n",
            "Epoch 72/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5415 - accuracy: 0.7718\n",
            "Epoch 73/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.7561\n",
            "Epoch 74/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.7613\n",
            "Epoch 75/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6465 - accuracy: 0.7564\n",
            "Epoch 76/76\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5877 - accuracy: 0.7782\n",
            "18/18 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:25:50,251] Trial 34 finished with value: 0.8501059322033898 and parameters: {'xgb__subsample': 0.9348268947879472, 'xgb__scale_pos_weight': 1.7550473899471388, 'xgb__reg_lambda': 2.5993223215112415, 'xgb__n_estimators': 852, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.06508387319274296, 'xgb__gamma': 0.36930797809372884, 'xgb__colsample_bytree': 0.9429193405970987, 'rf__n_estimators': 689, 'rf__min_samples_split': 4, 'rf__min_samples_leaf': 2, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 76, 'ann__batch_size': 106, 'ann__learning_rate': 0.02112484880751787}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 6s 34ms/step - loss: 0.4479 - accuracy: 0.7953\n",
            "Epoch 2/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4214 - accuracy: 0.8114\n",
            "Epoch 3/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8109\n",
            "Epoch 4/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8099\n",
            "Epoch 5/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8104\n",
            "Epoch 6/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8092\n",
            "Epoch 7/143\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4222 - accuracy: 0.8109\n",
            "Epoch 8/143\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4223 - accuracy: 0.8109\n",
            "Epoch 9/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4227 - accuracy: 0.8069\n",
            "Epoch 10/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8085\n",
            "Epoch 11/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8109\n",
            "Epoch 12/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.8091\n",
            "Epoch 13/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8061\n",
            "Epoch 14/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8060\n",
            "Epoch 15/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8091\n",
            "Epoch 16/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8105\n",
            "Epoch 17/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8088\n",
            "Epoch 18/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8075\n",
            "Epoch 19/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8059\n",
            "Epoch 20/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8044\n",
            "Epoch 21/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8079\n",
            "Epoch 22/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8067\n",
            "Epoch 23/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8053\n",
            "Epoch 24/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8060\n",
            "Epoch 25/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8053\n",
            "Epoch 26/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.8067\n",
            "Epoch 27/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8057\n",
            "Epoch 28/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8076\n",
            "Epoch 29/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8093\n",
            "Epoch 30/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8028\n",
            "Epoch 31/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8069\n",
            "Epoch 32/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8060\n",
            "Epoch 33/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8079\n",
            "Epoch 34/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8034\n",
            "Epoch 35/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8095\n",
            "Epoch 36/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8079\n",
            "Epoch 37/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8047\n",
            "Epoch 38/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8056\n",
            "Epoch 39/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8061\n",
            "Epoch 40/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8075\n",
            "Epoch 41/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.8027\n",
            "Epoch 42/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8061\n",
            "Epoch 43/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8057\n",
            "Epoch 44/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.8112\n",
            "Epoch 45/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8043\n",
            "Epoch 46/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8035\n",
            "Epoch 47/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8060\n",
            "Epoch 48/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8020\n",
            "Epoch 49/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8083\n",
            "Epoch 50/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8079\n",
            "Epoch 51/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8056\n",
            "Epoch 52/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8034\n",
            "Epoch 53/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8006\n",
            "Epoch 54/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8051\n",
            "Epoch 55/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8012\n",
            "Epoch 56/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8046\n",
            "Epoch 57/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.8088\n",
            "Epoch 58/143\n",
            "78/78 [==============================] - 1s 6ms/step - loss: 0.4295 - accuracy: 0.8067\n",
            "Epoch 59/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.8072\n",
            "Epoch 60/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8069\n",
            "Epoch 61/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8075\n",
            "Epoch 62/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8019\n",
            "Epoch 63/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.7989\n",
            "Epoch 64/143\n",
            "78/78 [==============================] - 1s 6ms/step - loss: 0.4335 - accuracy: 0.8030\n",
            "Epoch 65/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4286 - accuracy: 0.8061\n",
            "Epoch 66/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4292 - accuracy: 0.8077\n",
            "Epoch 67/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.8028\n",
            "Epoch 68/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.8038\n",
            "Epoch 69/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8038\n",
            "Epoch 70/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.8047\n",
            "Epoch 71/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8089\n",
            "Epoch 72/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8067\n",
            "Epoch 73/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8065\n",
            "Epoch 74/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.8010\n",
            "Epoch 75/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8015\n",
            "Epoch 76/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4487 - accuracy: 0.7970\n",
            "Epoch 77/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.7970\n",
            "Epoch 78/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8077\n",
            "Epoch 79/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.8043\n",
            "Epoch 80/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8050\n",
            "Epoch 81/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8071\n",
            "Epoch 82/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8034\n",
            "Epoch 83/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.8051\n",
            "Epoch 84/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.7970\n",
            "Epoch 85/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8023\n",
            "Epoch 86/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8099\n",
            "Epoch 87/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8052\n",
            "Epoch 88/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8080\n",
            "Epoch 89/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8003\n",
            "Epoch 90/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8046\n",
            "Epoch 91/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.7973\n",
            "Epoch 92/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8064\n",
            "Epoch 93/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.7998\n",
            "Epoch 94/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8026\n",
            "Epoch 95/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8057\n",
            "Epoch 96/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8027\n",
            "Epoch 97/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8069\n",
            "Epoch 98/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8024\n",
            "Epoch 99/143\n",
            "78/78 [==============================] - 1s 6ms/step - loss: 0.4342 - accuracy: 0.8046\n",
            "Epoch 100/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.7990\n",
            "Epoch 101/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.7998\n",
            "Epoch 102/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8056\n",
            "Epoch 103/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8031\n",
            "Epoch 104/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.8035\n",
            "Epoch 105/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.8028\n",
            "Epoch 106/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8048\n",
            "Epoch 107/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8042\n",
            "Epoch 108/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8050\n",
            "Epoch 109/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8080\n",
            "Epoch 110/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8081\n",
            "Epoch 111/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8019\n",
            "Epoch 112/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8014\n",
            "Epoch 113/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8027\n",
            "Epoch 114/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.7973\n",
            "Epoch 115/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4482 - accuracy: 0.7883\n",
            "Epoch 116/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8019\n",
            "Epoch 117/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8016\n",
            "Epoch 118/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.8018\n",
            "Epoch 119/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8089\n",
            "Epoch 120/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8024\n",
            "Epoch 121/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.7959\n",
            "Epoch 122/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.7949\n",
            "Epoch 123/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4386 - accuracy: 0.8038\n",
            "Epoch 124/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8019\n",
            "Epoch 125/143\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4321 - accuracy: 0.8076\n",
            "Epoch 126/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.8008\n",
            "Epoch 127/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4401 - accuracy: 0.8030\n",
            "Epoch 128/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4444 - accuracy: 0.8012\n",
            "Epoch 129/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4714 - accuracy: 0.7921\n",
            "Epoch 130/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4360 - accuracy: 0.7987\n",
            "Epoch 131/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.8003\n",
            "Epoch 132/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8068\n",
            "Epoch 133/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8042\n",
            "Epoch 134/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8028\n",
            "Epoch 135/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8100\n",
            "Epoch 136/143\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4333 - accuracy: 0.8053\n",
            "Epoch 137/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.8010\n",
            "Epoch 138/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8028\n",
            "Epoch 139/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.8002\n",
            "Epoch 140/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.8005\n",
            "Epoch 141/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.8028\n",
            "Epoch 142/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.8010\n",
            "Epoch 143/143\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8099\n",
            "20/20 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:27:14,713] Trial 35 finished with value: 0.8204449152542372 and parameters: {'xgb__subsample': 0.8439873746668471, 'xgb__scale_pos_weight': 2.3911120575544675, 'xgb__reg_lambda': 3.097828646246631, 'xgb__n_estimators': 112, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.03605080600041095, 'xgb__gamma': 0.14133405266820145, 'xgb__colsample_bytree': 0.8797314717854888, 'rf__n_estimators': 791, 'rf__min_samples_split': 7, 'rf__min_samples_leaf': 10, 'rf__max_depth': 7, 'rf__bootstrap': True, 'ann__epochs': 143, 'ann__batch_size': 98, 'ann__learning_rate': 0.0024762003457388083}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99/99 [==============================] - 6s 29ms/step - loss: 0.4388 - accuracy: 0.8032\n",
            "Epoch 2/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8020\n",
            "Epoch 3/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8028\n",
            "Epoch 4/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4591 - accuracy: 0.7962\n",
            "Epoch 5/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4701 - accuracy: 0.7891\n",
            "Epoch 6/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7965\n",
            "Epoch 7/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.7847\n",
            "Epoch 8/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.7892\n",
            "Epoch 9/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4544 - accuracy: 0.7948\n",
            "Epoch 10/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4898 - accuracy: 0.7838\n",
            "Epoch 11/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4821 - accuracy: 0.7867\n",
            "Epoch 12/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.7840\n",
            "Epoch 13/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4524 - accuracy: 0.7967\n",
            "Epoch 14/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.7831\n",
            "Epoch 15/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.7838\n",
            "Epoch 16/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.7802\n",
            "Epoch 17/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4715 - accuracy: 0.7891\n",
            "Epoch 18/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4890 - accuracy: 0.7830\n",
            "Epoch 19/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4782 - accuracy: 0.7900\n",
            "Epoch 20/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4808 - accuracy: 0.7876\n",
            "Epoch 21/62\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.4802 - accuracy: 0.7843\n",
            "Epoch 22/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5016 - accuracy: 0.7789\n",
            "Epoch 23/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.7712\n",
            "Epoch 24/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5510 - accuracy: 0.7737\n",
            "Epoch 25/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5520 - accuracy: 0.7730\n",
            "Epoch 26/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4815 - accuracy: 0.7852\n",
            "Epoch 27/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4850 - accuracy: 0.7891\n",
            "Epoch 28/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5129 - accuracy: 0.7848\n",
            "Epoch 29/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7860\n",
            "Epoch 30/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7722\n",
            "Epoch 31/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.7681\n",
            "Epoch 32/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5302 - accuracy: 0.7758\n",
            "Epoch 33/62\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.4827 - accuracy: 0.7822\n",
            "Epoch 34/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5227 - accuracy: 0.7771\n",
            "Epoch 35/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5524 - accuracy: 0.7691\n",
            "Epoch 36/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6277 - accuracy: 0.7623\n",
            "Epoch 37/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.7632\n",
            "Epoch 38/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5341 - accuracy: 0.7799\n",
            "Epoch 39/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.7790\n",
            "Epoch 40/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5360 - accuracy: 0.7696\n",
            "Epoch 41/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.7696\n",
            "Epoch 42/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7803\n",
            "Epoch 43/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.7794\n",
            "Epoch 44/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5533 - accuracy: 0.7688\n",
            "Epoch 45/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5775 - accuracy: 0.7666\n",
            "Epoch 46/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5340 - accuracy: 0.7740\n",
            "Epoch 47/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7801\n",
            "Epoch 48/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5652 - accuracy: 0.7685\n",
            "Epoch 49/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6110 - accuracy: 0.7636\n",
            "Epoch 50/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5835 - accuracy: 0.7666\n",
            "Epoch 51/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.7778\n",
            "Epoch 52/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.7806\n",
            "Epoch 53/62\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.5399 - accuracy: 0.7711\n",
            "Epoch 54/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6571 - accuracy: 0.7566\n",
            "Epoch 55/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5231 - accuracy: 0.7809\n",
            "Epoch 56/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5164 - accuracy: 0.7783\n",
            "Epoch 57/62\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6196 - accuracy: 0.7611\n",
            "Epoch 58/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5355 - accuracy: 0.7819\n",
            "Epoch 59/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5511 - accuracy: 0.7733\n",
            "Epoch 60/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5435 - accuracy: 0.7794\n",
            "Epoch 61/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5899 - accuracy: 0.7688\n",
            "Epoch 62/62\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7746\n",
            "25/25 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:28:06,127] Trial 36 finished with value: 0.8432203389830508 and parameters: {'xgb__subsample': 0.9332912491874867, 'xgb__scale_pos_weight': 4.225119988368393, 'xgb__reg_lambda': 1.7372423084798574, 'xgb__n_estimators': 676, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.02661263444855862, 'xgb__gamma': 0.056284730072866086, 'xgb__colsample_bytree': 0.7913006783405858, 'rf__n_estimators': 485, 'rf__min_samples_split': 11, 'rf__min_samples_leaf': 5, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 62, 'ann__batch_size': 77, 'ann__learning_rate': 0.015915215161838754}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 6s 40ms/step - loss: 0.4583 - accuracy: 0.7903\n",
            "Epoch 2/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.7953\n",
            "Epoch 3/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7932\n",
            "Epoch 4/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7840\n",
            "Epoch 5/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7867\n",
            "Epoch 6/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4879 - accuracy: 0.7859\n",
            "Epoch 7/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5058 - accuracy: 0.7830\n",
            "Epoch 8/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7836\n",
            "Epoch 9/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7876\n",
            "Epoch 10/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5289 - accuracy: 0.7744\n",
            "Epoch 11/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7683\n",
            "Epoch 12/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7775\n",
            "Epoch 13/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5600 - accuracy: 0.7658\n",
            "Epoch 14/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7774\n",
            "Epoch 15/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5560 - accuracy: 0.7732\n",
            "Epoch 16/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.7666\n",
            "Epoch 17/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7750\n",
            "Epoch 18/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7417\n",
            "Epoch 19/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6099 - accuracy: 0.7572\n",
            "Epoch 20/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.7779\n",
            "Epoch 21/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7783\n",
            "Epoch 22/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6279 - accuracy: 0.7659\n",
            "Epoch 23/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.7740\n",
            "Epoch 24/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7760\n",
            "Epoch 25/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7762\n",
            "Epoch 26/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7744\n",
            "Epoch 27/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.7523\n",
            "Epoch 28/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5524 - accuracy: 0.7721\n",
            "Epoch 29/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7112 - accuracy: 0.7568\n",
            "Epoch 30/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5884 - accuracy: 0.7697\n",
            "Epoch 31/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8320 - accuracy: 0.7470\n",
            "Epoch 32/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6050 - accuracy: 0.7610\n",
            "Epoch 33/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7171 - accuracy: 0.7589\n",
            "Epoch 34/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6544 - accuracy: 0.7677\n",
            "Epoch 35/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.5643 - accuracy: 0.7668\n",
            "Epoch 36/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.7607\n",
            "Epoch 37/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.7618\n",
            "Epoch 38/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6121 - accuracy: 0.7628\n",
            "Epoch 39/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.7695\n",
            "Epoch 40/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6023 - accuracy: 0.7640\n",
            "Epoch 41/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7033 - accuracy: 0.7528\n",
            "Epoch 42/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.7583\n",
            "Epoch 43/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6352 - accuracy: 0.7583\n",
            "Epoch 44/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6127 - accuracy: 0.7622\n",
            "Epoch 45/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5327 - accuracy: 0.7765\n",
            "Epoch 46/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7339 - accuracy: 0.7434\n",
            "Epoch 47/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.7575\n",
            "Epoch 48/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.7611\n",
            "Epoch 49/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.1791 - accuracy: 0.7336\n",
            "Epoch 50/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.7106 - accuracy: 0.7554\n",
            "Epoch 51/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6046 - accuracy: 0.7635\n",
            "Epoch 52/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7677\n",
            "Epoch 53/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7540 - accuracy: 0.7508\n",
            "Epoch 54/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.7016 - accuracy: 0.7466\n",
            "Epoch 55/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.6738 - accuracy: 0.7623\n",
            "Epoch 56/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.5921 - accuracy: 0.7730\n",
            "Epoch 57/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7825 - accuracy: 0.7395\n",
            "Epoch 58/124\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 0.6414 - accuracy: 0.7618\n",
            "Epoch 59/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7335 - accuracy: 0.7504\n",
            "Epoch 60/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.8055 - accuracy: 0.7564\n",
            "Epoch 61/124\n",
            "66/66 [==============================] - 0s 8ms/step - loss: 0.8123 - accuracy: 0.7521\n",
            "Epoch 62/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.7612 - accuracy: 0.7492\n",
            "Epoch 63/124\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.7525\n",
            "Epoch 64/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.7632\n",
            "Epoch 65/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6989 - accuracy: 0.7606\n",
            "Epoch 66/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8324 - accuracy: 0.7508\n",
            "Epoch 67/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7233 - accuracy: 0.7589\n",
            "Epoch 68/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6569 - accuracy: 0.7593\n",
            "Epoch 69/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6743 - accuracy: 0.7647\n",
            "Epoch 70/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7648 - accuracy: 0.7474\n",
            "Epoch 71/124\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 0.9118 - accuracy: 0.7467\n",
            "Epoch 72/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.7522 - accuracy: 0.7532\n",
            "Epoch 73/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7123 - accuracy: 0.7585\n",
            "Epoch 74/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7512 - accuracy: 0.7489\n",
            "Epoch 75/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.7609\n",
            "Epoch 76/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.1544 - accuracy: 0.7456\n",
            "Epoch 77/124\n",
            "66/66 [==============================] - 0s 8ms/step - loss: 0.6633 - accuracy: 0.7610\n",
            "Epoch 78/124\n",
            "66/66 [==============================] - 0s 8ms/step - loss: 0.7583 - accuracy: 0.7520\n",
            "Epoch 79/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.7358 - accuracy: 0.7568\n",
            "Epoch 80/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.8241 - accuracy: 0.7485\n",
            "Epoch 81/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7871 - accuracy: 0.7565\n",
            "Epoch 82/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.9286 - accuracy: 0.7508\n",
            "Epoch 83/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8190 - accuracy: 0.7491\n",
            "Epoch 84/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8746 - accuracy: 0.7381\n",
            "Epoch 85/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7728 - accuracy: 0.7523\n",
            "Epoch 86/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.8979 - accuracy: 0.7540\n",
            "Epoch 87/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.9313 - accuracy: 0.7492\n",
            "Epoch 88/124\n",
            "66/66 [==============================] - 0s 8ms/step - loss: 0.8175 - accuracy: 0.7485\n",
            "Epoch 89/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.7459 - accuracy: 0.7534\n",
            "Epoch 90/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.9649 - accuracy: 0.7386\n",
            "Epoch 91/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.1030 - accuracy: 0.7487\n",
            "Epoch 92/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8780 - accuracy: 0.7402\n",
            "Epoch 93/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.9166 - accuracy: 0.7360\n",
            "Epoch 94/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.7353 - accuracy: 0.7513\n",
            "Epoch 95/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.8353 - accuracy: 0.7454\n",
            "Epoch 96/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8178 - accuracy: 0.7528\n",
            "Epoch 97/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8725 - accuracy: 0.7444\n",
            "Epoch 98/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8997 - accuracy: 0.7411\n",
            "Epoch 99/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.7376 - accuracy: 0.7587\n",
            "Epoch 100/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.8768 - accuracy: 0.7419\n",
            "Epoch 101/124\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.8859 - accuracy: 0.7481\n",
            "Epoch 102/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.9283 - accuracy: 0.7398\n",
            "Epoch 103/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.8500 - accuracy: 0.7479\n",
            "Epoch 104/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.2386 - accuracy: 0.7374\n",
            "Epoch 105/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.1769 - accuracy: 0.7387\n",
            "Epoch 106/124\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 1.0724 - accuracy: 0.7304\n",
            "Epoch 107/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.0874 - accuracy: 0.7387\n",
            "Epoch 108/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.0393 - accuracy: 0.7357\n",
            "Epoch 109/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 0.9196 - accuracy: 0.7493\n",
            "Epoch 110/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.0904 - accuracy: 0.7357\n",
            "Epoch 111/124\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 1.0891 - accuracy: 0.7536\n",
            "Epoch 112/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.3832 - accuracy: 0.7325\n",
            "Epoch 113/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.6195 - accuracy: 0.7285\n",
            "Epoch 114/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.2529 - accuracy: 0.7394\n",
            "Epoch 115/124\n",
            "66/66 [==============================] - 1s 9ms/step - loss: 0.8991 - accuracy: 0.7463\n",
            "Epoch 116/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.1969 - accuracy: 0.7374\n",
            "Epoch 117/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.1269 - accuracy: 0.7333\n",
            "Epoch 118/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.1830 - accuracy: 0.7369\n",
            "Epoch 119/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.9052 - accuracy: 0.7509\n",
            "Epoch 120/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.2751 - accuracy: 0.7466\n",
            "Epoch 121/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.2754 - accuracy: 0.7413\n",
            "Epoch 122/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 1.4644 - accuracy: 0.7475\n",
            "Epoch 123/124\n",
            "66/66 [==============================] - 0s 7ms/step - loss: 0.9828 - accuracy: 0.7431\n",
            "Epoch 124/124\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 1.2308 - accuracy: 0.7376\n",
            "17/17 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:29:14,335] Trial 37 finished with value: 0.8373940677966102 and parameters: {'xgb__subsample': 0.782434742300623, 'xgb__scale_pos_weight': 1.7690841313301147, 'xgb__reg_lambda': 2.3285790032650233, 'xgb__n_estimators': 879, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.07850372079726693, 'xgb__gamma': 0.18789730190583614, 'xgb__colsample_bytree': 0.8602474274773837, 'rf__n_estimators': 563, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 7, 'rf__max_depth': 8, 'rf__bootstrap': True, 'ann__epochs': 124, 'ann__batch_size': 115, 'ann__learning_rate': 0.043265686049411944}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85/85 [==============================] - 6s 32ms/step - loss: 0.4446 - accuracy: 0.7989\n",
            "Epoch 2/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8053\n",
            "Epoch 3/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8040\n",
            "Epoch 4/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.8043\n",
            "Epoch 5/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8068\n",
            "Epoch 6/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.7999\n",
            "Epoch 7/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.8012\n",
            "Epoch 8/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4393 - accuracy: 0.7999\n",
            "Epoch 9/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.7987\n",
            "Epoch 10/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8003\n",
            "Epoch 11/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8036\n",
            "Epoch 12/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.7978\n",
            "Epoch 13/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8046\n",
            "Epoch 14/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.8031\n",
            "Epoch 15/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4476 - accuracy: 0.7969\n",
            "Epoch 16/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4448 - accuracy: 0.7990\n",
            "Epoch 17/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.7977\n",
            "Epoch 18/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4454 - accuracy: 0.7946\n",
            "Epoch 19/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4489 - accuracy: 0.7981\n",
            "Epoch 20/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4517 - accuracy: 0.7948\n",
            "Epoch 21/106\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 0.4422 - accuracy: 0.7994\n",
            "Epoch 22/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4660 - accuracy: 0.7867\n",
            "Epoch 23/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4774 - accuracy: 0.7881\n",
            "Epoch 24/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4404 - accuracy: 0.8001\n",
            "Epoch 25/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4731 - accuracy: 0.7827\n",
            "Epoch 26/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4559 - accuracy: 0.7958\n",
            "Epoch 27/106\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.4643 - accuracy: 0.7916\n",
            "Epoch 28/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4793 - accuracy: 0.7881\n",
            "Epoch 29/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4601 - accuracy: 0.7953\n",
            "Epoch 30/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.7916\n",
            "Epoch 31/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4639 - accuracy: 0.7957\n",
            "Epoch 32/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7962\n",
            "Epoch 33/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.7909\n",
            "Epoch 34/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4926 - accuracy: 0.7852\n",
            "Epoch 35/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4648 - accuracy: 0.7949\n",
            "Epoch 36/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4538 - accuracy: 0.7952\n",
            "Epoch 37/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4551 - accuracy: 0.8014\n",
            "Epoch 38/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4698 - accuracy: 0.7916\n",
            "Epoch 39/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.7940\n",
            "Epoch 40/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.7945\n",
            "Epoch 41/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.7783\n",
            "Epoch 42/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5038 - accuracy: 0.7828\n",
            "Epoch 43/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4716 - accuracy: 0.7899\n",
            "Epoch 44/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4835 - accuracy: 0.7865\n",
            "Epoch 45/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4844 - accuracy: 0.7831\n",
            "Epoch 46/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4759 - accuracy: 0.7903\n",
            "Epoch 47/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4823 - accuracy: 0.7871\n",
            "Epoch 48/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4795 - accuracy: 0.7860\n",
            "Epoch 49/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4983 - accuracy: 0.7794\n",
            "Epoch 50/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4811 - accuracy: 0.7847\n",
            "Epoch 51/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.7912\n",
            "Epoch 52/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5548 - accuracy: 0.7662\n",
            "Epoch 53/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.7832\n",
            "Epoch 54/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4768 - accuracy: 0.7921\n",
            "Epoch 55/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5622 - accuracy: 0.7634\n",
            "Epoch 56/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5071 - accuracy: 0.7856\n",
            "Epoch 57/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5045 - accuracy: 0.7795\n",
            "Epoch 58/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7745\n",
            "Epoch 59/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.7937\n",
            "Epoch 60/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4931 - accuracy: 0.7826\n",
            "Epoch 61/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.7888\n",
            "Epoch 62/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4659 - accuracy: 0.7916\n",
            "Epoch 63/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7920\n",
            "Epoch 64/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.7798\n",
            "Epoch 65/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5736 - accuracy: 0.7676\n",
            "Epoch 66/106\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.5278 - accuracy: 0.7798\n",
            "Epoch 67/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4922 - accuracy: 0.7912\n",
            "Epoch 68/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5206 - accuracy: 0.7766\n",
            "Epoch 69/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5465 - accuracy: 0.7672\n",
            "Epoch 70/106\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.4827 - accuracy: 0.7966\n",
            "Epoch 71/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5062 - accuracy: 0.7754\n",
            "Epoch 72/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5389 - accuracy: 0.7819\n",
            "Epoch 73/106\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.4909 - accuracy: 0.7839\n",
            "Epoch 74/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5084 - accuracy: 0.7798\n",
            "Epoch 75/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5040 - accuracy: 0.7807\n",
            "Epoch 76/106\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 0.4803 - accuracy: 0.7873\n",
            "Epoch 77/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5849 - accuracy: 0.7634\n",
            "Epoch 78/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5241 - accuracy: 0.7742\n",
            "Epoch 79/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5159 - accuracy: 0.7781\n",
            "Epoch 80/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5092 - accuracy: 0.7809\n",
            "Epoch 81/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5539 - accuracy: 0.7696\n",
            "Epoch 82/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.7925\n",
            "Epoch 83/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5142 - accuracy: 0.7805\n",
            "Epoch 84/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5535 - accuracy: 0.7721\n",
            "Epoch 85/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5160 - accuracy: 0.7790\n",
            "Epoch 86/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.4939 - accuracy: 0.7848\n",
            "Epoch 87/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4815 - accuracy: 0.7904\n",
            "Epoch 88/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5100 - accuracy: 0.7777\n",
            "Epoch 89/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.7794\n",
            "Epoch 90/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7740\n",
            "Epoch 91/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.4814 - accuracy: 0.7880\n",
            "Epoch 92/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5028 - accuracy: 0.7777\n",
            "Epoch 93/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5215 - accuracy: 0.7746\n",
            "Epoch 94/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5207 - accuracy: 0.7732\n",
            "Epoch 95/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5234 - accuracy: 0.7794\n",
            "Epoch 96/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.7826\n",
            "Epoch 97/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4933 - accuracy: 0.7834\n",
            "Epoch 98/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5520 - accuracy: 0.7765\n",
            "Epoch 99/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5037 - accuracy: 0.7877\n",
            "Epoch 100/106\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 0.5173 - accuracy: 0.7854\n",
            "Epoch 101/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4766 - accuracy: 0.7880\n",
            "Epoch 102/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5792 - accuracy: 0.7664\n",
            "Epoch 103/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5096 - accuracy: 0.7752\n",
            "Epoch 104/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.5714 - accuracy: 0.7724\n",
            "Epoch 105/106\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7871\n",
            "Epoch 106/106\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.7736\n",
            "22/22 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:30:28,183] Trial 38 finished with value: 0.864406779661017 and parameters: {'xgb__subsample': 0.8736963453625703, 'xgb__scale_pos_weight': 2.9980170191521185, 'xgb__reg_lambda': 0.8076171093521332, 'xgb__n_estimators': 578, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.05250060337895603, 'xgb__gamma': 0.259763891531886, 'xgb__colsample_bytree': 0.9393022848582111, 'rf__n_estimators': 752, 'rf__min_samples_split': 20, 'rf__min_samples_leaf': 2, 'rf__max_depth': 10, 'rf__bootstrap': True, 'ann__epochs': 106, 'ann__batch_size': 89, 'ann__learning_rate': 0.009099758177082352}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75/75 [==============================] - 6s 37ms/step - loss: 0.4569 - accuracy: 0.7881\n",
            "Epoch 2/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8064\n",
            "Epoch 3/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8093\n",
            "Epoch 4/159\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.4258 - accuracy: 0.8073\n",
            "Epoch 5/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.8084\n",
            "Epoch 6/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8073\n",
            "Epoch 7/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8072\n",
            "Epoch 8/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8087\n",
            "Epoch 9/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8077\n",
            "Epoch 10/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8011\n",
            "Epoch 11/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8076\n",
            "Epoch 12/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8055\n",
            "Epoch 13/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4401 - accuracy: 0.7985\n",
            "Epoch 14/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8012\n",
            "Epoch 15/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.8064\n",
            "Epoch 16/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8027\n",
            "Epoch 17/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8093\n",
            "Epoch 18/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8005\n",
            "Epoch 19/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8039\n",
            "Epoch 20/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.7998\n",
            "Epoch 21/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4575 - accuracy: 0.7953\n",
            "Epoch 22/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.8028\n",
            "Epoch 23/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.7959\n",
            "Epoch 24/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8060\n",
            "Epoch 25/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7998\n",
            "Epoch 26/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8007\n",
            "Epoch 27/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8018\n",
            "Epoch 28/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7974\n",
            "Epoch 29/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7961\n",
            "Epoch 30/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7959\n",
            "Epoch 31/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8008\n",
            "Epoch 32/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7979\n",
            "Epoch 33/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8043\n",
            "Epoch 34/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8069\n",
            "Epoch 35/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7985\n",
            "Epoch 36/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8024\n",
            "Epoch 37/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7930\n",
            "Epoch 38/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8064\n",
            "Epoch 39/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.7997\n",
            "Epoch 40/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8065\n",
            "Epoch 41/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4484 - accuracy: 0.7954\n",
            "Epoch 42/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8064\n",
            "Epoch 43/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8036\n",
            "Epoch 44/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.8014\n",
            "Epoch 45/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.8031\n",
            "Epoch 46/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.8019\n",
            "Epoch 47/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8057\n",
            "Epoch 48/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4484 - accuracy: 0.7953\n",
            "Epoch 49/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7876\n",
            "Epoch 50/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.7993\n",
            "Epoch 51/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.7989\n",
            "Epoch 52/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7987\n",
            "Epoch 53/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7908\n",
            "Epoch 54/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8024\n",
            "Epoch 55/159\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.4597 - accuracy: 0.7942\n",
            "Epoch 56/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.4398 - accuracy: 0.7995\n",
            "Epoch 57/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4402 - accuracy: 0.8010\n",
            "Epoch 58/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.7973\n",
            "Epoch 59/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7993\n",
            "Epoch 60/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.7953\n",
            "Epoch 61/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7952\n",
            "Epoch 62/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7974\n",
            "Epoch 63/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7940\n",
            "Epoch 64/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7917\n",
            "Epoch 65/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7938\n",
            "Epoch 66/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4732 - accuracy: 0.7917\n",
            "Epoch 67/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7993\n",
            "Epoch 68/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7912\n",
            "Epoch 69/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7961\n",
            "Epoch 70/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7953\n",
            "Epoch 71/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.8014\n",
            "Epoch 72/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7967\n",
            "Epoch 73/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4782 - accuracy: 0.7867\n",
            "Epoch 74/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4484 - accuracy: 0.7995\n",
            "Epoch 75/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7922\n",
            "Epoch 76/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.8005\n",
            "Epoch 77/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.8071\n",
            "Epoch 78/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.8027\n",
            "Epoch 79/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.7809\n",
            "Epoch 80/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4508 - accuracy: 0.7949\n",
            "Epoch 81/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.7961\n",
            "Epoch 82/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7938\n",
            "Epoch 83/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7954\n",
            "Epoch 84/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.7932\n",
            "Epoch 85/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7852\n",
            "Epoch 86/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4726 - accuracy: 0.7928\n",
            "Epoch 87/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4595 - accuracy: 0.7978\n",
            "Epoch 88/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7963\n",
            "Epoch 89/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4645 - accuracy: 0.7909\n",
            "Epoch 90/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7864\n",
            "Epoch 91/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7868\n",
            "Epoch 92/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7889\n",
            "Epoch 93/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.7914\n",
            "Epoch 94/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4524 - accuracy: 0.7986\n",
            "Epoch 95/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4553 - accuracy: 0.7941\n",
            "Epoch 96/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.7868\n",
            "Epoch 97/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.5037 - accuracy: 0.7793\n",
            "Epoch 98/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7904\n",
            "Epoch 99/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.7831\n",
            "Epoch 100/159\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.4704 - accuracy: 0.7934\n",
            "Epoch 101/159\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.4514 - accuracy: 0.7983\n",
            "Epoch 102/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4669 - accuracy: 0.7912\n",
            "Epoch 103/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7970\n",
            "Epoch 104/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7805\n",
            "Epoch 105/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7934\n",
            "Epoch 106/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7913\n",
            "Epoch 107/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7953\n",
            "Epoch 108/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7910\n",
            "Epoch 109/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7928\n",
            "Epoch 110/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7803\n",
            "Epoch 111/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7983\n",
            "Epoch 112/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7944\n",
            "Epoch 113/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.5168 - accuracy: 0.7775\n",
            "Epoch 114/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7877\n",
            "Epoch 115/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7863\n",
            "Epoch 116/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7855\n",
            "Epoch 117/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.5047 - accuracy: 0.7835\n",
            "Epoch 118/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.7967\n",
            "Epoch 119/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7949\n",
            "Epoch 120/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.7950\n",
            "Epoch 121/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.7828\n",
            "Epoch 122/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7876\n",
            "Epoch 123/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7835\n",
            "Epoch 124/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7920\n",
            "Epoch 125/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7908\n",
            "Epoch 126/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7924\n",
            "Epoch 127/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7934\n",
            "Epoch 128/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7997\n",
            "Epoch 129/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.7779\n",
            "Epoch 130/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4791 - accuracy: 0.7873\n",
            "Epoch 131/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7916\n",
            "Epoch 132/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7802\n",
            "Epoch 133/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7811\n",
            "Epoch 134/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.4959 - accuracy: 0.7863\n",
            "Epoch 135/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7897\n",
            "Epoch 136/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.7826\n",
            "Epoch 137/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7791\n",
            "Epoch 138/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7834\n",
            "Epoch 139/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7883\n",
            "Epoch 140/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7983\n",
            "Epoch 141/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7901\n",
            "Epoch 142/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7967\n",
            "Epoch 143/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7929\n",
            "Epoch 144/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7838\n",
            "Epoch 145/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7835\n",
            "Epoch 146/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7928\n",
            "Epoch 147/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7907\n",
            "Epoch 148/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4813 - accuracy: 0.7883\n",
            "Epoch 149/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.7938\n",
            "Epoch 150/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7867\n",
            "Epoch 151/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7983\n",
            "Epoch 152/159\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7879\n",
            "Epoch 153/159\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7711\n",
            "Epoch 154/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.5162 - accuracy: 0.7791\n",
            "Epoch 155/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.4692 - accuracy: 0.7880\n",
            "Epoch 156/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.4957 - accuracy: 0.7851\n",
            "Epoch 157/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.4612 - accuracy: 0.7986\n",
            "Epoch 158/159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4656 - accuracy: 0.7920\n",
            "Epoch 159/159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.5106 - accuracy: 0.7831\n",
            "19/19 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:31:58,217] Trial 39 finished with value: 0.850635593220339 and parameters: {'xgb__subsample': 0.936115066543636, 'xgb__scale_pos_weight': 5.114027462773313, 'xgb__reg_lambda': 1.4626651127265917, 'xgb__n_estimators': 947, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.12067325527325681, 'xgb__gamma': 0.3337123007016014, 'xgb__colsample_bytree': 0.7381650593672779, 'rf__n_estimators': 879, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 9, 'rf__max_depth': 9, 'rf__bootstrap': True, 'ann__epochs': 159, 'ann__batch_size': 101, 'ann__learning_rate': 0.005484491772600617}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 6s 41ms/step - loss: 0.4900 - accuracy: 0.7816\n",
            "Epoch 2/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.7884\n",
            "Epoch 3/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.5126 - accuracy: 0.7771\n",
            "Epoch 4/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.7699\n",
            "Epoch 5/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.5128 - accuracy: 0.7793\n",
            "Epoch 6/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.5391 - accuracy: 0.7773\n",
            "Epoch 7/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6051 - accuracy: 0.7609\n",
            "Epoch 8/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6884 - accuracy: 0.7589\n",
            "Epoch 9/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.5024 - accuracy: 0.7834\n",
            "Epoch 10/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6712 - accuracy: 0.7611\n",
            "Epoch 11/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.7705 - accuracy: 0.7426\n",
            "Epoch 12/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.7014 - accuracy: 0.7484\n",
            "Epoch 13/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6619 - accuracy: 0.7611\n",
            "Epoch 14/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.7184 - accuracy: 0.7474\n",
            "Epoch 15/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6362 - accuracy: 0.7689\n",
            "Epoch 16/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.8247 - accuracy: 0.7460\n",
            "Epoch 17/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.7142 - accuracy: 0.7519\n",
            "Epoch 18/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.7301 - accuracy: 0.7492\n",
            "Epoch 19/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.1493 - accuracy: 0.7353\n",
            "Epoch 20/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.9191 - accuracy: 0.7474\n",
            "Epoch 21/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.7326 - accuracy: 0.7291\n",
            "Epoch 22/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.0217 - accuracy: 0.7398\n",
            "Epoch 23/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.7562 - accuracy: 0.7509\n",
            "Epoch 24/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.0093 - accuracy: 0.7464\n",
            "Epoch 25/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.1914 - accuracy: 0.7268\n",
            "Epoch 26/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.8245 - accuracy: 0.7455\n",
            "Epoch 27/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.8143 - accuracy: 0.7483\n",
            "Epoch 28/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.1005 - accuracy: 0.7544\n",
            "Epoch 29/107\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 1.4088 - accuracy: 0.7345\n",
            "Epoch 30/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.1301 - accuracy: 0.7303\n",
            "Epoch 31/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.7211 - accuracy: 0.7373\n",
            "Epoch 32/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9032 - accuracy: 0.7443\n",
            "Epoch 33/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.8638 - accuracy: 0.7491\n",
            "Epoch 34/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9923 - accuracy: 0.7472\n",
            "Epoch 35/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9292 - accuracy: 0.7413\n",
            "Epoch 36/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.8692 - accuracy: 0.7520\n",
            "Epoch 37/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9092 - accuracy: 0.7497\n",
            "Epoch 38/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.4017 - accuracy: 0.7332\n",
            "Epoch 39/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0688 - accuracy: 0.7436\n",
            "Epoch 40/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.0457 - accuracy: 0.7459\n",
            "Epoch 41/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9293 - accuracy: 0.7410\n",
            "Epoch 42/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0095 - accuracy: 0.7436\n",
            "Epoch 43/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.7415\n",
            "Epoch 44/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.9283 - accuracy: 0.7481\n",
            "Epoch 45/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1544 - accuracy: 0.7438\n",
            "Epoch 46/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1450 - accuracy: 0.7468\n",
            "Epoch 47/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.3268 - accuracy: 0.7344\n",
            "Epoch 48/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0922 - accuracy: 0.7353\n",
            "Epoch 49/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0502 - accuracy: 0.7421\n",
            "Epoch 50/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1248 - accuracy: 0.7345\n",
            "Epoch 51/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0206 - accuracy: 0.7366\n",
            "Epoch 52/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1078 - accuracy: 0.7373\n",
            "Epoch 53/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.2240 - accuracy: 0.7464\n",
            "Epoch 54/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.1408 - accuracy: 0.7409\n",
            "Epoch 55/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.5322 - accuracy: 0.7401\n",
            "Epoch 56/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0189 - accuracy: 0.7399\n",
            "Epoch 57/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.4910 - accuracy: 0.7432\n",
            "Epoch 58/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.1235 - accuracy: 0.7436\n",
            "Epoch 59/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.4601 - accuracy: 0.7250\n",
            "Epoch 60/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.0918 - accuracy: 0.7519\n",
            "Epoch 61/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.8904 - accuracy: 0.7463\n",
            "Epoch 62/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1961 - accuracy: 0.7405\n",
            "Epoch 63/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.0757 - accuracy: 0.7312\n",
            "Epoch 64/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.4135 - accuracy: 0.7285\n",
            "Epoch 65/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.0820 - accuracy: 0.7312\n",
            "Epoch 66/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1947 - accuracy: 0.7499\n",
            "Epoch 67/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.4814 - accuracy: 0.7292\n",
            "Epoch 68/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.2049 - accuracy: 0.7423\n",
            "Epoch 69/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.7284 - accuracy: 0.7405\n",
            "Epoch 70/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.3088 - accuracy: 0.7411\n",
            "Epoch 71/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.5367 - accuracy: 0.7279\n",
            "Epoch 72/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.2831 - accuracy: 0.7378\n",
            "Epoch 73/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.3719 - accuracy: 0.7325\n",
            "Epoch 74/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.3645 - accuracy: 0.7372\n",
            "Epoch 75/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.4136 - accuracy: 0.7299\n",
            "Epoch 76/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.3265 - accuracy: 0.7219\n",
            "Epoch 77/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.7399\n",
            "Epoch 78/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.0297 - accuracy: 0.7444\n",
            "Epoch 79/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.4340 - accuracy: 0.7448\n",
            "Epoch 80/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1717 - accuracy: 0.7407\n",
            "Epoch 81/107\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 1.4892 - accuracy: 0.7300\n",
            "Epoch 82/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.4252 - accuracy: 0.7428\n",
            "Epoch 83/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.5316 - accuracy: 0.7462\n",
            "Epoch 84/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.2020 - accuracy: 0.7374\n",
            "Epoch 85/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.4593 - accuracy: 0.7394\n",
            "Epoch 86/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.7291 - accuracy: 0.7328\n",
            "Epoch 87/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 1.8514 - accuracy: 0.7391\n",
            "Epoch 88/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.5964 - accuracy: 0.7279\n",
            "Epoch 89/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.1862 - accuracy: 0.7466\n",
            "Epoch 90/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.9257 - accuracy: 0.7365\n",
            "Epoch 91/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.6331 - accuracy: 0.7360\n",
            "Epoch 92/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.4679 - accuracy: 0.7328\n",
            "Epoch 93/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.3796 - accuracy: 0.7361\n",
            "Epoch 94/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.5334 - accuracy: 0.7373\n",
            "Epoch 95/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.7441 - accuracy: 0.7365\n",
            "Epoch 96/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.9689 - accuracy: 0.7362\n",
            "Epoch 97/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.4445 - accuracy: 0.7426\n",
            "Epoch 98/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 3.0011 - accuracy: 0.7300\n",
            "Epoch 99/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.1375 - accuracy: 0.7414\n",
            "Epoch 100/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.2843 - accuracy: 0.7439\n",
            "Epoch 101/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.4383 - accuracy: 0.7358\n",
            "Epoch 102/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 2.2035 - accuracy: 0.7272\n",
            "Epoch 103/107\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 1.5110 - accuracy: 0.7419\n",
            "Epoch 104/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 2.8977 - accuracy: 0.7320\n",
            "Epoch 105/107\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 1.1510 - accuracy: 0.7438\n",
            "Epoch 106/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 2.3971 - accuracy: 0.7307\n",
            "Epoch 107/107\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 3.1982 - accuracy: 0.7374\n",
            "18/18 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:32:57,347] Trial 40 finished with value: 0.8050847457627118 and parameters: {'xgb__subsample': 0.8637339303987844, 'xgb__scale_pos_weight': 2.349899800222423, 'xgb__reg_lambda': 2.9676908951759815, 'xgb__n_estimators': 771, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.03787517325370347, 'xgb__gamma': 0.2141636759206879, 'xgb__colsample_bytree': 0.8104285788061776, 'rf__n_estimators': 651, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 12, 'rf__max_depth': 5, 'rf__bootstrap': True, 'ann__epochs': 107, 'ann__batch_size': 111, 'ann__learning_rate': 0.06861397501416495}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 6s 26ms/step - loss: 0.4486 - accuracy: 0.7922\n",
            "Epoch 2/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8106\n",
            "Epoch 3/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8116\n",
            "Epoch 4/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8095\n",
            "Epoch 5/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4213 - accuracy: 0.8100\n",
            "Epoch 6/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4225 - accuracy: 0.8106\n",
            "Epoch 7/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8102\n",
            "Epoch 8/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.8105\n",
            "Epoch 9/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8099\n",
            "Epoch 10/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4217 - accuracy: 0.8080\n",
            "Epoch 11/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4226 - accuracy: 0.8101\n",
            "Epoch 12/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4215 - accuracy: 0.8096\n",
            "Epoch 13/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4221 - accuracy: 0.8068\n",
            "Epoch 14/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.8083\n",
            "Epoch 15/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8097\n",
            "Epoch 16/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8048\n",
            "Epoch 17/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4241 - accuracy: 0.8087\n",
            "Epoch 18/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8100\n",
            "Epoch 19/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4241 - accuracy: 0.8079\n",
            "Epoch 20/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4247 - accuracy: 0.8093\n",
            "Epoch 21/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8088\n",
            "Epoch 22/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4244 - accuracy: 0.8093\n",
            "Epoch 23/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4257 - accuracy: 0.8071\n",
            "Epoch 24/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8061\n",
            "Epoch 25/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8104\n",
            "Epoch 26/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8085\n",
            "Epoch 27/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4253 - accuracy: 0.8081\n",
            "Epoch 28/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4253 - accuracy: 0.8079\n",
            "Epoch 29/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8060\n",
            "Epoch 30/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4255 - accuracy: 0.8059\n",
            "Epoch 31/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8079\n",
            "Epoch 32/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8065\n",
            "Epoch 33/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8059\n",
            "Epoch 34/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8046\n",
            "Epoch 35/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8061\n",
            "Epoch 36/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4324 - accuracy: 0.8027\n",
            "Epoch 37/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4272 - accuracy: 0.8068\n",
            "Epoch 38/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.8091\n",
            "Epoch 39/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8044\n",
            "Epoch 40/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4228 - accuracy: 0.8114\n",
            "Epoch 41/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4319 - accuracy: 0.8051\n",
            "Epoch 42/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4284 - accuracy: 0.8077\n",
            "Epoch 43/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8040\n",
            "Epoch 44/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.7999\n",
            "Epoch 45/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8099\n",
            "Epoch 46/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8056\n",
            "Epoch 47/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4261 - accuracy: 0.8079\n",
            "Epoch 48/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4307 - accuracy: 0.8050\n",
            "Epoch 49/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8001\n",
            "Epoch 50/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8008\n",
            "Epoch 51/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8083\n",
            "Epoch 52/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8053\n",
            "Epoch 53/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8068\n",
            "Epoch 54/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8068\n",
            "Epoch 55/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4252 - accuracy: 0.8043\n",
            "Epoch 56/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4287 - accuracy: 0.8055\n",
            "Epoch 57/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.8032\n",
            "Epoch 58/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8064\n",
            "Epoch 59/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4406 - accuracy: 0.7994\n",
            "Epoch 60/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4299 - accuracy: 0.8038\n",
            "Epoch 61/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8043\n",
            "Epoch 62/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8059\n",
            "Epoch 63/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4328 - accuracy: 0.8030\n",
            "Epoch 64/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.8042\n",
            "Epoch 65/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4304 - accuracy: 0.8027\n",
            "Epoch 66/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4270 - accuracy: 0.8061\n",
            "Epoch 67/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4320 - accuracy: 0.8030\n",
            "Epoch 68/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.7950\n",
            "Epoch 69/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8085\n",
            "Epoch 70/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4372 - accuracy: 0.7995\n",
            "Epoch 71/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4284 - accuracy: 0.8023\n",
            "Epoch 72/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4346 - accuracy: 0.8067\n",
            "Epoch 73/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8055\n",
            "Epoch 74/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8073\n",
            "Epoch 75/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8064\n",
            "Epoch 76/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4297 - accuracy: 0.8043\n",
            "Epoch 77/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8046\n",
            "Epoch 78/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.8028\n",
            "Epoch 79/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.8034\n",
            "Epoch 80/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4393 - accuracy: 0.7987\n",
            "Epoch 81/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8031\n",
            "Epoch 82/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.8067\n",
            "Epoch 83/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8030\n",
            "Epoch 84/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4345 - accuracy: 0.8038\n",
            "Epoch 85/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4327 - accuracy: 0.8052\n",
            "Epoch 86/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8060\n",
            "Epoch 87/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4321 - accuracy: 0.8001\n",
            "Epoch 88/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4369 - accuracy: 0.8031\n",
            "Epoch 89/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.8039\n",
            "Epoch 90/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4359 - accuracy: 0.8038\n",
            "Epoch 91/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4339 - accuracy: 0.8024\n",
            "Epoch 92/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4307 - accuracy: 0.8055\n",
            "Epoch 93/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4390 - accuracy: 0.8010\n",
            "Epoch 94/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8039\n",
            "Epoch 95/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8038\n",
            "Epoch 96/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8028\n",
            "Epoch 97/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.8018\n",
            "Epoch 98/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.7998\n",
            "Epoch 99/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4391 - accuracy: 0.8014\n",
            "Epoch 100/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.8020\n",
            "Epoch 101/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8047\n",
            "Epoch 102/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4333 - accuracy: 0.8023\n",
            "Epoch 103/139\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.4313 - accuracy: 0.8052\n",
            "Epoch 104/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4321 - accuracy: 0.8059\n",
            "Epoch 105/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4324 - accuracy: 0.8015\n",
            "Epoch 106/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.8006\n",
            "Epoch 107/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4560 - accuracy: 0.7957\n",
            "Epoch 108/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4328 - accuracy: 0.8055\n",
            "Epoch 109/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4300 - accuracy: 0.8016\n",
            "Epoch 110/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4326 - accuracy: 0.8007\n",
            "Epoch 111/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4290 - accuracy: 0.8096\n",
            "Epoch 112/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4372 - accuracy: 0.7994\n",
            "Epoch 113/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4344 - accuracy: 0.8030\n",
            "Epoch 114/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8052\n",
            "Epoch 115/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.8012\n",
            "Epoch 116/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.8028\n",
            "Epoch 117/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.8051\n",
            "Epoch 118/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4368 - accuracy: 0.8011\n",
            "Epoch 119/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.8028\n",
            "Epoch 120/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.8044\n",
            "Epoch 121/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4430 - accuracy: 0.7971\n",
            "Epoch 122/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.8039\n",
            "Epoch 123/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.8015\n",
            "Epoch 124/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8018\n",
            "Epoch 125/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8047\n",
            "Epoch 126/139\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.7997\n",
            "Epoch 127/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4324 - accuracy: 0.8063\n",
            "Epoch 128/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4413 - accuracy: 0.7990\n",
            "Epoch 129/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4523 - accuracy: 0.7929\n",
            "Epoch 130/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4317 - accuracy: 0.8038\n",
            "Epoch 131/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8010\n",
            "Epoch 132/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4373 - accuracy: 0.8030\n",
            "Epoch 133/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4367 - accuracy: 0.8019\n",
            "Epoch 134/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4454 - accuracy: 0.8020\n",
            "Epoch 135/139\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.7991\n",
            "Epoch 136/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4387 - accuracy: 0.8016\n",
            "Epoch 137/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4344 - accuracy: 0.8018\n",
            "Epoch 138/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4425 - accuracy: 0.8010\n",
            "Epoch 139/139\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.4410 - accuracy: 0.7995\n",
            "28/28 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:34:51,757] Trial 41 finished with value: 0.8569915254237288 and parameters: {'xgb__subsample': 0.9988187238684285, 'xgb__scale_pos_weight': 1.4920358835448504, 'xgb__reg_lambda': 0.7791872158184816, 'xgb__n_estimators': 840, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.09550074783965448, 'xgb__gamma': 0.05879147511466735, 'xgb__colsample_bytree': 0.9442233588426553, 'rf__n_estimators': 381, 'rf__min_samples_split': 9, 'rf__min_samples_leaf': 1, 'rf__max_depth': 2, 'rf__bootstrap': False, 'ann__epochs': 139, 'ann__batch_size': 69, 'ann__learning_rate': 0.002030431769181675}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96/96 [==============================] - 6s 29ms/step - loss: 0.4829 - accuracy: 0.7721\n",
            "Epoch 2/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8050\n",
            "Epoch 3/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4201 - accuracy: 0.8085\n",
            "Epoch 4/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8116\n",
            "Epoch 5/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.8105\n",
            "Epoch 6/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8112\n",
            "Epoch 7/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4192 - accuracy: 0.8118\n",
            "Epoch 8/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8113\n",
            "Epoch 9/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.8126\n",
            "Epoch 10/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.8096\n",
            "Epoch 11/122\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.4207 - accuracy: 0.8104\n",
            "Epoch 12/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4197 - accuracy: 0.8122\n",
            "Epoch 13/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4198 - accuracy: 0.8105\n",
            "Epoch 14/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4198 - accuracy: 0.8125\n",
            "Epoch 15/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4195 - accuracy: 0.8124\n",
            "Epoch 16/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4199 - accuracy: 0.8125\n",
            "Epoch 17/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4208 - accuracy: 0.8097\n",
            "Epoch 18/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4190 - accuracy: 0.8116\n",
            "Epoch 19/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8110\n",
            "Epoch 20/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4194 - accuracy: 0.8124\n",
            "Epoch 21/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4210 - accuracy: 0.8110\n",
            "Epoch 22/122\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.4228 - accuracy: 0.8095\n",
            "Epoch 23/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4203 - accuracy: 0.8130\n",
            "Epoch 24/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4212 - accuracy: 0.8137\n",
            "Epoch 25/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4207 - accuracy: 0.8126\n",
            "Epoch 26/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4211 - accuracy: 0.8080\n",
            "Epoch 27/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4200 - accuracy: 0.8097\n",
            "Epoch 28/122\n",
            "96/96 [==============================] - 1s 13ms/step - loss: 0.4212 - accuracy: 0.8096\n",
            "Epoch 29/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4208 - accuracy: 0.8085\n",
            "Epoch 30/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4196 - accuracy: 0.8097\n",
            "Epoch 31/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4209 - accuracy: 0.8116\n",
            "Epoch 32/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4204 - accuracy: 0.8106\n",
            "Epoch 33/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4218 - accuracy: 0.8126\n",
            "Epoch 34/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4204 - accuracy: 0.8101\n",
            "Epoch 35/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4205 - accuracy: 0.8099\n",
            "Epoch 36/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4206 - accuracy: 0.8095\n",
            "Epoch 37/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4222 - accuracy: 0.8121\n",
            "Epoch 38/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4208 - accuracy: 0.8114\n",
            "Epoch 39/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4239 - accuracy: 0.8067\n",
            "Epoch 40/122\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.4207 - accuracy: 0.8121\n",
            "Epoch 41/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4220 - accuracy: 0.8097\n",
            "Epoch 42/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4215 - accuracy: 0.8095\n",
            "Epoch 43/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4245 - accuracy: 0.8092\n",
            "Epoch 44/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4217 - accuracy: 0.8118\n",
            "Epoch 45/122\n",
            "96/96 [==============================] - 1s 11ms/step - loss: 0.4214 - accuracy: 0.8095\n",
            "Epoch 46/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4212 - accuracy: 0.8077\n",
            "Epoch 47/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8089\n",
            "Epoch 48/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8092\n",
            "Epoch 49/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8104\n",
            "Epoch 50/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8091\n",
            "Epoch 51/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8105\n",
            "Epoch 52/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.8096\n",
            "Epoch 53/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8097\n",
            "Epoch 54/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8121\n",
            "Epoch 55/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8080\n",
            "Epoch 56/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8057\n",
            "Epoch 57/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8092\n",
            "Epoch 58/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8105\n",
            "Epoch 59/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8084\n",
            "Epoch 60/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4216 - accuracy: 0.8056\n",
            "Epoch 61/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4224 - accuracy: 0.8116\n",
            "Epoch 62/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4227 - accuracy: 0.8077\n",
            "Epoch 63/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4216 - accuracy: 0.8102\n",
            "Epoch 64/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4223 - accuracy: 0.8080\n",
            "Epoch 65/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4228 - accuracy: 0.8072\n",
            "Epoch 66/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4241 - accuracy: 0.8100\n",
            "Epoch 67/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8079\n",
            "Epoch 68/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8102\n",
            "Epoch 69/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8069\n",
            "Epoch 70/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8083\n",
            "Epoch 71/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4249 - accuracy: 0.8105\n",
            "Epoch 72/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8101\n",
            "Epoch 73/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8064\n",
            "Epoch 74/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8126\n",
            "Epoch 75/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4220 - accuracy: 0.8080\n",
            "Epoch 76/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8087\n",
            "Epoch 77/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4232 - accuracy: 0.8095\n",
            "Epoch 78/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4242 - accuracy: 0.8051\n",
            "Epoch 79/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.8079\n",
            "Epoch 80/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4228 - accuracy: 0.8056\n",
            "Epoch 81/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8102\n",
            "Epoch 82/122\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.4241 - accuracy: 0.8081\n",
            "Epoch 83/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4222 - accuracy: 0.8089\n",
            "Epoch 84/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4253 - accuracy: 0.8100\n",
            "Epoch 85/122\n",
            "96/96 [==============================] - 1s 12ms/step - loss: 0.4237 - accuracy: 0.8089\n",
            "Epoch 86/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8085\n",
            "Epoch 87/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.8072\n",
            "Epoch 88/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4218 - accuracy: 0.8102\n",
            "Epoch 89/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4240 - accuracy: 0.8088\n",
            "Epoch 90/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4224 - accuracy: 0.8077\n",
            "Epoch 91/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4260 - accuracy: 0.8097\n",
            "Epoch 92/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4235 - accuracy: 0.8105\n",
            "Epoch 93/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4239 - accuracy: 0.8075\n",
            "Epoch 94/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8104\n",
            "Epoch 95/122\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.4237 - accuracy: 0.8093\n",
            "Epoch 96/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4224 - accuracy: 0.8087\n",
            "Epoch 97/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4213 - accuracy: 0.8104\n",
            "Epoch 98/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4217 - accuracy: 0.8101\n",
            "Epoch 99/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8061\n",
            "Epoch 100/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4236 - accuracy: 0.8100\n",
            "Epoch 101/122\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.4227 - accuracy: 0.8084\n",
            "Epoch 102/122\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.4238 - accuracy: 0.8080\n",
            "Epoch 103/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4232 - accuracy: 0.8099\n",
            "Epoch 104/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8084\n",
            "Epoch 105/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8095\n",
            "Epoch 106/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8084\n",
            "Epoch 107/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8080\n",
            "Epoch 108/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8083\n",
            "Epoch 109/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8092\n",
            "Epoch 110/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8071\n",
            "Epoch 111/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8063\n",
            "Epoch 112/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8073\n",
            "Epoch 113/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4259 - accuracy: 0.8088\n",
            "Epoch 114/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8076\n",
            "Epoch 115/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8056\n",
            "Epoch 116/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8042\n",
            "Epoch 117/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8108\n",
            "Epoch 118/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8088\n",
            "Epoch 119/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8073\n",
            "Epoch 120/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8044\n",
            "Epoch 121/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.8100\n",
            "Epoch 122/122\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8024\n",
            "24/24 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:36:43,977] Trial 42 finished with value: 0.8670550847457628 and parameters: {'xgb__subsample': 0.9537720216967774, 'xgb__scale_pos_weight': 1.893962027524307, 'xgb__reg_lambda': 0.11812345050766282, 'xgb__n_estimators': 929, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.06443091340762537, 'xgb__gamma': 0.1341221015786161, 'xgb__colsample_bytree': 0.9925768449363798, 'rf__n_estimators': 582, 'rf__min_samples_split': 8, 'rf__min_samples_leaf': 2, 'rf__max_depth': 1, 'rf__bootstrap': False, 'ann__epochs': 122, 'ann__batch_size': 79, 'ann__learning_rate': 0.0010673693196561731}. Best is trial 26 with value: 0.8734110169491526.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "107/107 [==============================] - 6s 27ms/step - loss: 0.4412 - accuracy: 0.7916\n",
            "Epoch 2/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8069\n",
            "Epoch 3/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8105\n",
            "Epoch 4/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8087\n",
            "Epoch 5/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8079\n",
            "Epoch 6/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8085\n",
            "Epoch 7/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.8079\n",
            "Epoch 8/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8067\n",
            "Epoch 9/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8042\n",
            "Epoch 10/10\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8112\n",
            "27/27 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:36:58,714] Trial 43 finished with value: 0.8771186440677966 and parameters: {'xgb__subsample': 0.9427629804456301, 'xgb__scale_pos_weight': 1.0320900158332558, 'xgb__reg_lambda': 0.7010703016048032, 'xgb__n_estimators': 651, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.13680927343211416, 'xgb__gamma': 0.04500991430601001, 'xgb__colsample_bytree': 0.8770206411553205, 'rf__n_estimators': 166, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10, 'rf__bootstrap': False, 'ann__epochs': 10, 'ann__batch_size': 71, 'ann__learning_rate': 0.003320651213411407}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 3s 8ms/step - loss: 0.4835 - accuracy: 0.7693\n",
            "Epoch 2/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8099\n",
            "Epoch 3/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8073\n",
            "Epoch 4/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8118\n",
            "Epoch 5/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8069\n",
            "Epoch 6/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8089\n",
            "Epoch 7/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8081\n",
            "Epoch 8/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8081\n",
            "Epoch 9/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8087\n",
            "Epoch 10/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8114\n",
            "Epoch 11/51\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.8057\n",
            "Epoch 12/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8069\n",
            "Epoch 13/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8076\n",
            "Epoch 14/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8081\n",
            "Epoch 15/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8079\n",
            "Epoch 16/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8077\n",
            "Epoch 17/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8043\n",
            "Epoch 18/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8073\n",
            "Epoch 19/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8089\n",
            "Epoch 20/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8063\n",
            "Epoch 21/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.8047\n",
            "Epoch 22/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8089\n",
            "Epoch 23/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8061\n",
            "Epoch 24/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8065\n",
            "Epoch 25/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8060\n",
            "Epoch 26/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8053\n",
            "Epoch 27/51\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8023\n",
            "Epoch 28/51\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8064\n",
            "Epoch 29/51\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7998\n",
            "Epoch 30/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8067\n",
            "Epoch 31/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8061\n",
            "Epoch 32/51\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.8027\n",
            "Epoch 33/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.8001\n",
            "Epoch 34/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8093\n",
            "Epoch 35/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8044\n",
            "Epoch 36/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8028\n",
            "Epoch 37/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8040\n",
            "Epoch 38/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8001\n",
            "Epoch 39/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7994\n",
            "Epoch 40/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8076\n",
            "Epoch 41/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8038\n",
            "Epoch 42/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8002\n",
            "Epoch 43/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8087\n",
            "Epoch 44/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8019\n",
            "Epoch 45/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8047\n",
            "Epoch 46/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8030\n",
            "Epoch 47/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8069\n",
            "Epoch 48/51\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8063\n",
            "Epoch 49/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8030\n",
            "Epoch 50/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8063\n",
            "Epoch 51/51\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8015\n",
            "15/15 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:37:21,063] Trial 44 finished with value: 0.868114406779661 and parameters: {'xgb__subsample': 0.9466858330992202, 'xgb__scale_pos_weight': 1.4145208018299442, 'xgb__reg_lambda': 1.9440570442484735, 'xgb__n_estimators': 631, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.12157099320568164, 'xgb__gamma': 0.044170850346446355, 'xgb__colsample_bytree': 0.8888465067324391, 'rf__n_estimators': 423, 'rf__min_samples_split': 11, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10, 'rf__bootstrap': False, 'ann__epochs': 51, 'ann__batch_size': 128, 'ann__learning_rate': 0.0043661581218059145}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "87/87 [==============================] - 6s 31ms/step - loss: 0.4566 - accuracy: 0.7873\n",
            "Epoch 2/151\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.4224 - accuracy: 0.8085\n",
            "Epoch 3/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.8124\n",
            "Epoch 4/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8059\n",
            "Epoch 5/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8072\n",
            "Epoch 6/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8069\n",
            "Epoch 7/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8060\n",
            "Epoch 8/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8063\n",
            "Epoch 9/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8048\n",
            "Epoch 10/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8101\n",
            "Epoch 11/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8053\n",
            "Epoch 12/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.8080\n",
            "Epoch 13/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8085\n",
            "Epoch 14/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4266 - accuracy: 0.8080\n",
            "Epoch 15/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4258 - accuracy: 0.8080\n",
            "Epoch 16/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8069\n",
            "Epoch 17/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.8001\n",
            "Epoch 18/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8043\n",
            "Epoch 19/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8061\n",
            "Epoch 20/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8095\n",
            "Epoch 21/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4275 - accuracy: 0.8035\n",
            "Epoch 22/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.8100\n",
            "Epoch 23/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8069\n",
            "Epoch 24/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8059\n",
            "Epoch 25/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8052\n",
            "Epoch 26/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8039\n",
            "Epoch 27/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4270 - accuracy: 0.8053\n",
            "Epoch 28/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8085\n",
            "Epoch 29/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8018\n",
            "Epoch 30/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4309 - accuracy: 0.8042\n",
            "Epoch 31/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.8040\n",
            "Epoch 32/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8007\n",
            "Epoch 33/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.8023\n",
            "Epoch 34/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4275 - accuracy: 0.8079\n",
            "Epoch 35/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8001\n",
            "Epoch 36/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4317 - accuracy: 0.8034\n",
            "Epoch 37/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4339 - accuracy: 0.8048\n",
            "Epoch 38/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.8040\n",
            "Epoch 39/151\n",
            "87/87 [==============================] - 1s 10ms/step - loss: 0.4345 - accuracy: 0.8063\n",
            "Epoch 40/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4331 - accuracy: 0.8043\n",
            "Epoch 41/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4338 - accuracy: 0.7997\n",
            "Epoch 42/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8032\n",
            "Epoch 43/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4337 - accuracy: 0.8035\n",
            "Epoch 44/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4372 - accuracy: 0.8064\n",
            "Epoch 45/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4337 - accuracy: 0.8069\n",
            "Epoch 46/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8068\n",
            "Epoch 47/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4429 - accuracy: 0.7953\n",
            "Epoch 48/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4426 - accuracy: 0.8014\n",
            "Epoch 49/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4330 - accuracy: 0.8051\n",
            "Epoch 50/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.7979\n",
            "Epoch 51/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.8057\n",
            "Epoch 52/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4374 - accuracy: 0.8014\n",
            "Epoch 53/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.7981\n",
            "Epoch 54/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8010\n",
            "Epoch 55/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4406 - accuracy: 0.8026\n",
            "Epoch 56/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4412 - accuracy: 0.7966\n",
            "Epoch 57/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.7936\n",
            "Epoch 58/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.7982\n",
            "Epoch 59/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8027\n",
            "Epoch 60/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4406 - accuracy: 0.8002\n",
            "Epoch 61/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.7995\n",
            "Epoch 62/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.7993\n",
            "Epoch 63/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4391 - accuracy: 0.7978\n",
            "Epoch 64/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4439 - accuracy: 0.7997\n",
            "Epoch 65/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8001\n",
            "Epoch 66/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.7998\n",
            "Epoch 67/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4529 - accuracy: 0.7928\n",
            "Epoch 68/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.8044\n",
            "Epoch 69/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4471 - accuracy: 0.7959\n",
            "Epoch 70/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4562 - accuracy: 0.7948\n",
            "Epoch 71/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.8027\n",
            "Epoch 72/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.7961\n",
            "Epoch 73/151\n",
            "87/87 [==============================] - 1s 9ms/step - loss: 0.4597 - accuracy: 0.7885\n",
            "Epoch 74/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.8006\n",
            "Epoch 75/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4548 - accuracy: 0.7910\n",
            "Epoch 76/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4422 - accuracy: 0.7998\n",
            "Epoch 77/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4386 - accuracy: 0.7982\n",
            "Epoch 78/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4355 - accuracy: 0.8002\n",
            "Epoch 79/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4400 - accuracy: 0.8016\n",
            "Epoch 80/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.8026\n",
            "Epoch 81/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8006\n",
            "Epoch 82/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4509 - accuracy: 0.7962\n",
            "Epoch 83/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4419 - accuracy: 0.7994\n",
            "Epoch 84/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.8032\n",
            "Epoch 85/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7858\n",
            "Epoch 86/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8036\n",
            "Epoch 87/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.8024\n",
            "Epoch 88/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4456 - accuracy: 0.7977\n",
            "Epoch 89/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4465 - accuracy: 0.7949\n",
            "Epoch 90/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8015\n",
            "Epoch 91/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.7970\n",
            "Epoch 92/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4451 - accuracy: 0.8022\n",
            "Epoch 93/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7956\n",
            "Epoch 94/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4543 - accuracy: 0.7997\n",
            "Epoch 95/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4447 - accuracy: 0.7999\n",
            "Epoch 96/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.7932\n",
            "Epoch 97/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4389 - accuracy: 0.8068\n",
            "Epoch 98/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4592 - accuracy: 0.7957\n",
            "Epoch 99/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4620 - accuracy: 0.7908\n",
            "Epoch 100/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4633 - accuracy: 0.7880\n",
            "Epoch 101/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4558 - accuracy: 0.7954\n",
            "Epoch 102/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4392 - accuracy: 0.8011\n",
            "Epoch 103/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4401 - accuracy: 0.8016\n",
            "Epoch 104/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4420 - accuracy: 0.7957\n",
            "Epoch 105/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4538 - accuracy: 0.7961\n",
            "Epoch 106/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8022\n",
            "Epoch 107/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4399 - accuracy: 0.8018\n",
            "Epoch 108/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7949\n",
            "Epoch 109/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4539 - accuracy: 0.7930\n",
            "Epoch 110/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.7978\n",
            "Epoch 111/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.7917\n",
            "Epoch 112/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.7957\n",
            "Epoch 113/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4452 - accuracy: 0.7946\n",
            "Epoch 114/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4597 - accuracy: 0.7940\n",
            "Epoch 115/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4466 - accuracy: 0.7981\n",
            "Epoch 116/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4551 - accuracy: 0.7936\n",
            "Epoch 117/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.7954\n",
            "Epoch 118/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.7973\n",
            "Epoch 119/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.7798\n",
            "Epoch 120/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.7908\n",
            "Epoch 121/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.8030\n",
            "Epoch 122/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.8010\n",
            "Epoch 123/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4706 - accuracy: 0.7873\n",
            "Epoch 124/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4713 - accuracy: 0.7884\n",
            "Epoch 125/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.7922\n",
            "Epoch 126/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4541 - accuracy: 0.7959\n",
            "Epoch 127/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4542 - accuracy: 0.7963\n",
            "Epoch 128/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4517 - accuracy: 0.7979\n",
            "Epoch 129/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4537 - accuracy: 0.7974\n",
            "Epoch 130/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4477 - accuracy: 0.7989\n",
            "Epoch 131/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.7942\n",
            "Epoch 132/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.7883\n",
            "Epoch 133/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4692 - accuracy: 0.7893\n",
            "Epoch 134/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4448 - accuracy: 0.8012\n",
            "Epoch 135/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4679 - accuracy: 0.7913\n",
            "Epoch 136/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.7938\n",
            "Epoch 137/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.7805\n",
            "Epoch 138/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4512 - accuracy: 0.8002\n",
            "Epoch 139/151\n",
            "87/87 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.7891\n",
            "Epoch 140/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7905\n",
            "Epoch 141/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4636 - accuracy: 0.7912\n",
            "Epoch 142/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4630 - accuracy: 0.7907\n",
            "Epoch 143/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4773 - accuracy: 0.7865\n",
            "Epoch 144/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4743 - accuracy: 0.7876\n",
            "Epoch 145/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4652 - accuracy: 0.7907\n",
            "Epoch 146/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4624 - accuracy: 0.7963\n",
            "Epoch 147/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4668 - accuracy: 0.7889\n",
            "Epoch 148/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4601 - accuracy: 0.7965\n",
            "Epoch 149/151\n",
            "87/87 [==============================] - 1s 8ms/step - loss: 0.4575 - accuracy: 0.7944\n",
            "Epoch 150/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4611 - accuracy: 0.7900\n",
            "Epoch 151/151\n",
            "87/87 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.8002\n",
            "22/22 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:39:03,623] Trial 45 finished with value: 0.8734110169491526 and parameters: {'xgb__subsample': 0.7998834010114673, 'xgb__scale_pos_weight': 1.6075006060356172, 'xgb__reg_lambda': 1.3212389402344278, 'xgb__n_estimators': 684, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.09279330776936595, 'xgb__gamma': 0.11591527935293984, 'xgb__colsample_bytree': 0.8442439399774153, 'rf__n_estimators': 319, 'rf__min_samples_split': 12, 'rf__min_samples_leaf': 6, 'rf__max_depth': 9, 'rf__bootstrap': False, 'ann__epochs': 151, 'ann__batch_size': 87, 'ann__learning_rate': 0.003600840883573659}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "103/103 [==============================] - 6s 29ms/step - loss: 0.4533 - accuracy: 0.7827\n",
            "Epoch 2/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8128\n",
            "Epoch 3/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8083\n",
            "Epoch 4/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8100\n",
            "Epoch 5/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8114\n",
            "Epoch 6/12\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.8093\n",
            "Epoch 7/12\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 0.4271 - accuracy: 0.8072\n",
            "Epoch 8/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.8068\n",
            "Epoch 9/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.8063\n",
            "Epoch 10/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.8087\n",
            "Epoch 11/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8064\n",
            "Epoch 12/12\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8038\n",
            "26/26 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:39:19,822] Trial 46 finished with value: 0.8670550847457628 and parameters: {'xgb__subsample': 0.8601900971320702, 'xgb__scale_pos_weight': 1.4835315662936321, 'xgb__reg_lambda': 0.6752210611854902, 'xgb__n_estimators': 529, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.0699367869311258, 'xgb__gamma': 0.12494807213160974, 'xgb__colsample_bytree': 0.7859937277675346, 'rf__n_estimators': 333, 'rf__min_samples_split': 14, 'rf__min_samples_leaf': 6, 'rf__max_depth': 9, 'rf__bootstrap': False, 'ann__epochs': 12, 'ann__batch_size': 74, 'ann__learning_rate': 0.003294033383953659}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 26ms/step - loss: 0.4626 - accuracy: 0.7835\n",
            "Epoch 2/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4212 - accuracy: 0.8085\n",
            "Epoch 3/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8084\n",
            "Epoch 4/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4208 - accuracy: 0.8095\n",
            "Epoch 5/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.8072\n",
            "Epoch 6/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8097\n",
            "Epoch 7/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8100\n",
            "Epoch 8/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8064\n",
            "Epoch 9/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4222 - accuracy: 0.8097\n",
            "Epoch 10/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8112\n",
            "Epoch 11/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4215 - accuracy: 0.8101\n",
            "Epoch 12/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8102\n",
            "Epoch 13/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8117\n",
            "Epoch 14/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8088\n",
            "Epoch 15/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4230 - accuracy: 0.8073\n",
            "Epoch 16/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4245 - accuracy: 0.8092\n",
            "Epoch 17/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4230 - accuracy: 0.8067\n",
            "Epoch 18/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4230 - accuracy: 0.8097\n",
            "Epoch 19/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4345 - accuracy: 0.8011\n",
            "Epoch 20/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8080\n",
            "Epoch 21/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4275 - accuracy: 0.8073\n",
            "Epoch 22/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.8076\n",
            "Epoch 23/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4256 - accuracy: 0.8061\n",
            "Epoch 24/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.8102\n",
            "Epoch 25/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8116\n",
            "Epoch 26/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4245 - accuracy: 0.8093\n",
            "Epoch 27/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4352 - accuracy: 0.8024\n",
            "Epoch 28/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.8067\n",
            "Epoch 29/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8071\n",
            "Epoch 30/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4243 - accuracy: 0.8081\n",
            "Epoch 31/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4259 - accuracy: 0.8048\n",
            "Epoch 32/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8083\n",
            "Epoch 33/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4312 - accuracy: 0.8026\n",
            "Epoch 34/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8104\n",
            "Epoch 35/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8073\n",
            "Epoch 36/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8071\n",
            "Epoch 37/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.8046\n",
            "Epoch 38/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4365 - accuracy: 0.8048\n",
            "Epoch 39/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8084\n",
            "Epoch 40/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.8035\n",
            "Epoch 41/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.8055\n",
            "Epoch 42/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8035\n",
            "Epoch 43/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4265 - accuracy: 0.8057\n",
            "Epoch 44/170\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4276 - accuracy: 0.8080\n",
            "Epoch 45/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4360 - accuracy: 0.8031\n",
            "Epoch 46/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8101\n",
            "Epoch 47/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4300 - accuracy: 0.8075\n",
            "Epoch 48/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8014\n",
            "Epoch 49/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8030\n",
            "Epoch 50/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4412 - accuracy: 0.7999\n",
            "Epoch 51/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4290 - accuracy: 0.8055\n",
            "Epoch 52/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8071\n",
            "Epoch 53/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8040\n",
            "Epoch 54/170\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4293 - accuracy: 0.8085\n",
            "Epoch 55/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8067\n",
            "Epoch 56/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.7989\n",
            "Epoch 57/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8063\n",
            "Epoch 58/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4470 - accuracy: 0.7969\n",
            "Epoch 59/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8012\n",
            "Epoch 60/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4342 - accuracy: 0.8026\n",
            "Epoch 61/170\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4318 - accuracy: 0.8040\n",
            "Epoch 62/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.8076\n",
            "Epoch 63/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.8067\n",
            "Epoch 64/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8022\n",
            "Epoch 65/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4360 - accuracy: 0.7999\n",
            "Epoch 66/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8026\n",
            "Epoch 67/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.8015\n",
            "Epoch 68/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8030\n",
            "Epoch 69/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.8008\n",
            "Epoch 70/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8057\n",
            "Epoch 71/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4297 - accuracy: 0.8069\n",
            "Epoch 72/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.7975\n",
            "Epoch 73/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4301 - accuracy: 0.8067\n",
            "Epoch 74/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8052\n",
            "Epoch 75/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8022\n",
            "Epoch 76/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.7974\n",
            "Epoch 77/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4310 - accuracy: 0.8010\n",
            "Epoch 78/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4370 - accuracy: 0.8003\n",
            "Epoch 79/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8048\n",
            "Epoch 80/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7979\n",
            "Epoch 81/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.8069\n",
            "Epoch 82/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4369 - accuracy: 0.8014\n",
            "Epoch 83/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8019\n",
            "Epoch 84/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.7991\n",
            "Epoch 85/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8075\n",
            "Epoch 86/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4385 - accuracy: 0.8007\n",
            "Epoch 87/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4274 - accuracy: 0.8056\n",
            "Epoch 88/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8088\n",
            "Epoch 89/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.8003\n",
            "Epoch 90/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.7981\n",
            "Epoch 91/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8057\n",
            "Epoch 92/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4442 - accuracy: 0.8012\n",
            "Epoch 93/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.7998\n",
            "Epoch 94/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8028\n",
            "Epoch 95/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8043\n",
            "Epoch 96/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.8018\n",
            "Epoch 97/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8031\n",
            "Epoch 98/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.8019\n",
            "Epoch 99/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.7998\n",
            "Epoch 100/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8044\n",
            "Epoch 101/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.7998\n",
            "Epoch 102/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.8015\n",
            "Epoch 103/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.8042\n",
            "Epoch 104/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8085\n",
            "Epoch 105/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.8011\n",
            "Epoch 106/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8040\n",
            "Epoch 107/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8034\n",
            "Epoch 108/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8023\n",
            "Epoch 109/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.7942\n",
            "Epoch 110/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.7969\n",
            "Epoch 111/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.8020\n",
            "Epoch 112/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.8022\n",
            "Epoch 113/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.7958\n",
            "Epoch 114/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4397 - accuracy: 0.8010\n",
            "Epoch 115/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.7999\n",
            "Epoch 116/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4392 - accuracy: 0.7997\n",
            "Epoch 117/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4349 - accuracy: 0.8065\n",
            "Epoch 118/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4382 - accuracy: 0.8047\n",
            "Epoch 119/170\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4394 - accuracy: 0.8030\n",
            "Epoch 120/170\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4426 - accuracy: 0.8001\n",
            "Epoch 121/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.8002\n",
            "Epoch 122/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.7997\n",
            "Epoch 123/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8051\n",
            "Epoch 124/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8024\n",
            "Epoch 125/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8036\n",
            "Epoch 126/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4503 - accuracy: 0.7962\n",
            "Epoch 127/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.7994\n",
            "Epoch 128/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4509 - accuracy: 0.7995\n",
            "Epoch 129/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.8006\n",
            "Epoch 130/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8032\n",
            "Epoch 131/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8043\n",
            "Epoch 132/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4442 - accuracy: 0.7975\n",
            "Epoch 133/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4345 - accuracy: 0.8032\n",
            "Epoch 134/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.7965\n",
            "Epoch 135/170\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4506 - accuracy: 0.7975\n",
            "Epoch 136/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4355 - accuracy: 0.7993\n",
            "Epoch 137/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4420 - accuracy: 0.7989\n",
            "Epoch 138/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.7998\n",
            "Epoch 139/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4476 - accuracy: 0.7932\n",
            "Epoch 140/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4590 - accuracy: 0.7969\n",
            "Epoch 141/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.8019\n",
            "Epoch 142/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.8022\n",
            "Epoch 143/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.7989\n",
            "Epoch 144/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.7975\n",
            "Epoch 145/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8002\n",
            "Epoch 146/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4320 - accuracy: 0.8027\n",
            "Epoch 147/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.8016\n",
            "Epoch 148/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.7965\n",
            "Epoch 149/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.8005\n",
            "Epoch 150/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.8038\n",
            "Epoch 151/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4397 - accuracy: 0.8042\n",
            "Epoch 152/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4426 - accuracy: 0.8006\n",
            "Epoch 153/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.7969\n",
            "Epoch 154/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4376 - accuracy: 0.7994\n",
            "Epoch 155/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.7985\n",
            "Epoch 156/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4663 - accuracy: 0.7901\n",
            "Epoch 157/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4456 - accuracy: 0.8026\n",
            "Epoch 158/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8030\n",
            "Epoch 159/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4415 - accuracy: 0.8005\n",
            "Epoch 160/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8019\n",
            "Epoch 161/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.8035\n",
            "Epoch 162/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.8001\n",
            "Epoch 163/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8023\n",
            "Epoch 164/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.7993\n",
            "Epoch 165/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.8042\n",
            "Epoch 166/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.7993\n",
            "Epoch 167/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4387 - accuracy: 0.8024\n",
            "Epoch 168/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.7990\n",
            "Epoch 169/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.7991\n",
            "Epoch 170/170\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.7991\n",
            "29/29 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:41:41,674] Trial 47 finished with value: 0.8638771186440678 and parameters: {'xgb__subsample': 0.8065774696077469, 'xgb__scale_pos_weight': 1.7620500249017643, 'xgb__reg_lambda': 1.329908696938048, 'xgb__n_estimators': 640, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.20531837695919078, 'xgb__gamma': 0.050045142381393126, 'xgb__colsample_bytree': 0.947525906778037, 'rf__n_estimators': 256, 'rf__min_samples_split': 12, 'rf__min_samples_leaf': 3, 'rf__max_depth': 8, 'rf__bootstrap': False, 'ann__epochs': 170, 'ann__batch_size': 67, 'ann__learning_rate': 0.002110061397633246}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88/88 [==============================] - 7s 36ms/step - loss: 0.4436 - accuracy: 0.7966\n",
            "Epoch 2/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8084\n",
            "Epoch 3/25\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4213 - accuracy: 0.8104\n",
            "Epoch 4/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8091\n",
            "Epoch 5/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8122\n",
            "Epoch 6/25\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8073\n",
            "Epoch 7/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.8084\n",
            "Epoch 8/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8099\n",
            "Epoch 9/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8071\n",
            "Epoch 10/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.8095\n",
            "Epoch 11/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.8096\n",
            "Epoch 12/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8064\n",
            "Epoch 13/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.8072\n",
            "Epoch 14/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8077\n",
            "Epoch 15/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4246 - accuracy: 0.8055\n",
            "Epoch 16/25\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.8088\n",
            "Epoch 17/25\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4248 - accuracy: 0.8089\n",
            "Epoch 18/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8042\n",
            "Epoch 19/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8114\n",
            "Epoch 20/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8116\n",
            "Epoch 21/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4247 - accuracy: 0.8104\n",
            "Epoch 22/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8085\n",
            "Epoch 23/25\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8081\n",
            "Epoch 24/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4260 - accuracy: 0.8065\n",
            "Epoch 25/25\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8099\n",
            "22/22 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:42:06,239] Trial 48 finished with value: 0.8633474576271186 and parameters: {'xgb__subsample': 0.9529449419655435, 'xgb__scale_pos_weight': 1.0194859102921712, 'xgb__reg_lambda': 1.2932335572101175, 'xgb__n_estimators': 756, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.05437731849549477, 'xgb__gamma': 0.10884958520831875, 'xgb__colsample_bytree': 0.8978112063238842, 'rf__n_estimators': 163, 'rf__min_samples_split': 13, 'rf__min_samples_leaf': 5, 'rf__max_depth': 7, 'rf__bootstrap': False, 'ann__epochs': 25, 'ann__batch_size': 86, 'ann__learning_rate': 0.0029003646879504213}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 10s 22ms/step - loss: 0.4461 - accuracy: 0.8008\n",
            "Epoch 2/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8020\n",
            "Epoch 3/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.8003\n",
            "Epoch 4/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8036\n",
            "Epoch 5/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.7990\n",
            "Epoch 6/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.8011\n",
            "Epoch 7/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4473 - accuracy: 0.7950\n",
            "Epoch 8/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.8008\n",
            "Epoch 9/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.7929\n",
            "Epoch 10/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4636 - accuracy: 0.7917\n",
            "Epoch 11/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4659 - accuracy: 0.7913\n",
            "Epoch 12/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4696 - accuracy: 0.7917\n",
            "Epoch 13/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4731 - accuracy: 0.7854\n",
            "Epoch 14/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4772 - accuracy: 0.7828\n",
            "Epoch 15/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4680 - accuracy: 0.7891\n",
            "Epoch 16/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.7912\n",
            "Epoch 17/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.7844\n",
            "Epoch 18/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.7839\n",
            "Epoch 19/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4727 - accuracy: 0.7900\n",
            "Epoch 20/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4768 - accuracy: 0.7901\n",
            "Epoch 21/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7707\n",
            "Epoch 22/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4778 - accuracy: 0.7918\n",
            "Epoch 23/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.7843\n",
            "Epoch 24/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7885\n",
            "Epoch 25/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.7847\n",
            "Epoch 26/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4781 - accuracy: 0.7876\n",
            "Epoch 27/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.7840\n",
            "Epoch 28/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.7811\n",
            "Epoch 29/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5069 - accuracy: 0.7773\n",
            "Epoch 30/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.7864\n",
            "Epoch 31/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4956 - accuracy: 0.7842\n",
            "Epoch 32/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.7852\n",
            "Epoch 33/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.7815\n",
            "Epoch 34/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4921 - accuracy: 0.7818\n",
            "Epoch 35/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.7828\n",
            "Epoch 36/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5405 - accuracy: 0.7760\n",
            "Epoch 37/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7774\n",
            "Epoch 38/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7823\n",
            "Epoch 39/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.7856\n",
            "Epoch 40/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.7783\n",
            "Epoch 41/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5077 - accuracy: 0.7809\n",
            "Epoch 42/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5468 - accuracy: 0.7765\n",
            "Epoch 43/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5174 - accuracy: 0.7846\n",
            "Epoch 44/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5340 - accuracy: 0.7717\n",
            "Epoch 45/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.7745\n",
            "Epoch 46/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5471 - accuracy: 0.7803\n",
            "Epoch 47/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.7826\n",
            "Epoch 48/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5366 - accuracy: 0.7756\n",
            "Epoch 49/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5934 - accuracy: 0.7704\n",
            "Epoch 50/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.7704\n",
            "Epoch 51/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5729 - accuracy: 0.7708\n",
            "Epoch 52/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5614 - accuracy: 0.7691\n",
            "Epoch 53/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7775\n",
            "Epoch 54/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6377 - accuracy: 0.7598\n",
            "Epoch 55/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.7777\n",
            "Epoch 56/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5111 - accuracy: 0.7852\n",
            "Epoch 57/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7794\n",
            "Epoch 58/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6265 - accuracy: 0.7648\n",
            "Epoch 59/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5486 - accuracy: 0.7737\n",
            "Epoch 60/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5888 - accuracy: 0.7628\n",
            "Epoch 61/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5283 - accuracy: 0.7770\n",
            "Epoch 62/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5812 - accuracy: 0.7651\n",
            "Epoch 63/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5964 - accuracy: 0.7656\n",
            "Epoch 64/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5799 - accuracy: 0.7666\n",
            "Epoch 65/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5950 - accuracy: 0.7668\n",
            "Epoch 66/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.7178 - accuracy: 0.7546\n",
            "Epoch 67/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7775\n",
            "Epoch 68/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6823 - accuracy: 0.7561\n",
            "Epoch 69/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5807 - accuracy: 0.7781\n",
            "Epoch 70/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6918 - accuracy: 0.7558\n",
            "Epoch 71/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5912 - accuracy: 0.7688\n",
            "Epoch 72/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5601 - accuracy: 0.7729\n",
            "Epoch 73/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5899 - accuracy: 0.7733\n",
            "Epoch 74/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5307 - accuracy: 0.7823\n",
            "Epoch 75/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6376 - accuracy: 0.7620\n",
            "Epoch 76/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5624 - accuracy: 0.7790\n",
            "Epoch 77/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5724 - accuracy: 0.7658\n",
            "Epoch 78/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5422 - accuracy: 0.7744\n",
            "Epoch 79/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6412 - accuracy: 0.7617\n",
            "Epoch 80/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5632 - accuracy: 0.7691\n",
            "Epoch 81/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5899 - accuracy: 0.7602\n",
            "Epoch 82/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5486 - accuracy: 0.7730\n",
            "Epoch 83/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.7757\n",
            "Epoch 84/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5900 - accuracy: 0.7663\n",
            "Epoch 85/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6188 - accuracy: 0.7594\n",
            "Epoch 86/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8423 - accuracy: 0.7472\n",
            "Epoch 87/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.5738 - accuracy: 0.7783\n",
            "Epoch 88/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.7506 - accuracy: 0.7504\n",
            "Epoch 89/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.6130 - accuracy: 0.7748\n",
            "Epoch 90/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5485 - accuracy: 0.7738\n",
            "Epoch 91/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.5700 - accuracy: 0.7683\n",
            "Epoch 92/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6508 - accuracy: 0.7638\n",
            "Epoch 93/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.7448 - accuracy: 0.7519\n",
            "Epoch 94/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.8684 - accuracy: 0.7557\n",
            "Epoch 95/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6240 - accuracy: 0.7680\n",
            "Epoch 96/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6238 - accuracy: 0.7681\n",
            "Epoch 97/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7199 - accuracy: 0.7572\n",
            "Epoch 98/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6749 - accuracy: 0.7570\n",
            "Epoch 99/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.7798\n",
            "Epoch 100/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6511 - accuracy: 0.7613\n",
            "Epoch 101/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6681 - accuracy: 0.7602\n",
            "Epoch 102/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.7585\n",
            "Epoch 103/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6601 - accuracy: 0.7639\n",
            "Epoch 104/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6493 - accuracy: 0.7610\n",
            "Epoch 105/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7508 - accuracy: 0.7534\n",
            "Epoch 106/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6348 - accuracy: 0.7578\n",
            "Epoch 107/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8253 - accuracy: 0.7425\n",
            "Epoch 108/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5704 - accuracy: 0.7757\n",
            "Epoch 109/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7090 - accuracy: 0.7598\n",
            "Epoch 110/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6406 - accuracy: 0.7617\n",
            "Epoch 111/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7601 - accuracy: 0.7508\n",
            "Epoch 112/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6679 - accuracy: 0.7603\n",
            "Epoch 113/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6723 - accuracy: 0.7610\n",
            "Epoch 114/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7812 - accuracy: 0.7556\n",
            "Epoch 115/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7133 - accuracy: 0.7589\n",
            "Epoch 116/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7133 - accuracy: 0.7528\n",
            "Epoch 117/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6439 - accuracy: 0.7611\n",
            "Epoch 118/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7711 - accuracy: 0.7560\n",
            "Epoch 119/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6849 - accuracy: 0.7556\n",
            "Epoch 120/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.7095 - accuracy: 0.7577\n",
            "Epoch 121/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6891 - accuracy: 0.7581\n",
            "Epoch 122/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.5629 - accuracy: 0.7752\n",
            "Epoch 123/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6654 - accuracy: 0.7573\n",
            "Epoch 124/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6518 - accuracy: 0.7705\n",
            "Epoch 125/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7529 - accuracy: 0.7540\n",
            "Epoch 126/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7227 - accuracy: 0.7503\n",
            "Epoch 127/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7380 - accuracy: 0.7549\n",
            "Epoch 128/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6843 - accuracy: 0.7573\n",
            "Epoch 129/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6544 - accuracy: 0.7589\n",
            "Epoch 130/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6702 - accuracy: 0.7620\n",
            "Epoch 131/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.6593 - accuracy: 0.7597\n",
            "Epoch 132/154\n",
            "149/149 [==============================] - 1s 9ms/step - loss: 0.6870 - accuracy: 0.7583\n",
            "Epoch 133/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6678 - accuracy: 0.7504\n",
            "Epoch 134/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7203 - accuracy: 0.7526\n",
            "Epoch 135/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.9149 - accuracy: 0.7477\n",
            "Epoch 136/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6448 - accuracy: 0.7638\n",
            "Epoch 137/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7608 - accuracy: 0.7508\n",
            "Epoch 138/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7929 - accuracy: 0.7549\n",
            "Epoch 139/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8648 - accuracy: 0.7544\n",
            "Epoch 140/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8621 - accuracy: 0.7496\n",
            "Epoch 141/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6971 - accuracy: 0.7585\n",
            "Epoch 142/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 1.0135 - accuracy: 0.7485\n",
            "Epoch 143/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6607 - accuracy: 0.7642\n",
            "Epoch 144/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6544 - accuracy: 0.7615\n",
            "Epoch 145/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8691 - accuracy: 0.7427\n",
            "Epoch 146/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7509 - accuracy: 0.7620\n",
            "Epoch 147/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7209 - accuracy: 0.7545\n",
            "Epoch 148/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6657 - accuracy: 0.7656\n",
            "Epoch 149/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7418 - accuracy: 0.7561\n",
            "Epoch 150/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6466 - accuracy: 0.7654\n",
            "Epoch 151/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.8597 - accuracy: 0.7524\n",
            "Epoch 152/154\n",
            "149/149 [==============================] - 1s 8ms/step - loss: 0.7555 - accuracy: 0.7557\n",
            "Epoch 153/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.7494 - accuracy: 0.7528\n",
            "Epoch 154/154\n",
            "149/149 [==============================] - 1s 7ms/step - loss: 0.6893 - accuracy: 0.7575\n",
            "38/38 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-05 17:45:03,650] Trial 49 finished with value: 0.8564618644067796 and parameters: {'xgb__subsample': 0.8697819748857176, 'xgb__scale_pos_weight': 2.552277583854223, 'xgb__reg_lambda': 0.7439533616823871, 'xgb__n_estimators': 806, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.13829380355221646, 'xgb__gamma': 0.1850665688808874, 'xgb__colsample_bytree': 0.8584072666600364, 'rf__n_estimators': 201, 'rf__min_samples_split': 17, 'rf__min_samples_leaf': 2, 'rf__max_depth': 9, 'rf__bootstrap': False, 'ann__epochs': 154, 'ann__batch_size': 51, 'ann__learning_rate': 0.01161114811176908}. Best is trial 43 with value: 0.8771186440677966.\n"
          ]
        }
      ],
      "source": [
        "# 7. Creación del estudio Optuna\n",
        "initial_params = {\n",
        "    'xgb__subsample': 1.0,\n",
        "    'xgb__scale_pos_weight': 1,\n",
        "    'xgb__reg_lambda': 1.0,\n",
        "    'xgb__n_estimators': 1000,\n",
        "    'xgb__max_depth': 6,\n",
        "    'xgb__learning_rate': 0.1,\n",
        "    'xgb__gamma': 0,\n",
        "    'xgb__colsample_bytree': 0.9,\n",
        "    'rf__n_estimators': 300,\n",
        "    'rf__min_samples_split': 2,\n",
        "    'rf__min_samples_leaf': 1,\n",
        "    'rf__max_depth': 8,\n",
        "    'rf__bootstrap': False,\n",
        "    'ann__epochs': 100,\n",
        "    'ann__batch_size': 32,\n",
        "    'ann__learning_rate': 0.001\n",
        "}\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
        "study.enqueue_trial(initial_params)\n",
        "study.optimize(objective, n_trials=50, timeout=None)  # Puede ajustar n_trials y timeout según sus necesidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtención de los mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Obtención de los mejores hiperparámetros\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuuaC5amVQU"
      },
      "source": [
        "Evaluar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        }
      ],
      "source": [
        "# 9. Entrenamiento del modelo con los mejores hiperparámetros\n",
        "xgb_best = XGBClassifier(**{k[5:]: v for k, v in best_params.items() if k.startswith('xgb__')})\n",
        "rf_best = RandomForestClassifier(**{k[4:]: v for k, v in best_params.items() if k.startswith('rf__')})\n",
        "ann_best = KerasClassifier(\n",
        "    build_fn=lambda: create_ann_model(learning_rate=best_params['ann__learning_rate']),\n",
        "    epochs=best_params['ann__epochs'],\n",
        "    batch_size=best_params['ann__batch_size'],\n",
        "    verbose=0  # Asumiendo que quieres mantener el verbose en 0 como en tu código anterior\n",
        ")\n",
        "\n",
        "voting_clf_best = VotingClassifier(\n",
        "    estimators=[('xgb', xgb_best), ('ann', ann_best), ('rf', rf_best)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf_best.fit(X_train, y_train)\n",
        "y_pred_best = voting_clf_best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Evaluación del modelo\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
        "report_best = classification_report(y_test, y_pred_best)\n",
        "acc_best = accuracy_score(y_test, y_pred_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualización de la Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 11. Visualización de la Curva ROC\n",
        "y_pred_proba_best = voting_clf_best.predict_proba(X_test)[:,1]\n",
        "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, y_pred_proba_best)\n",
        "roc_auc_best = auc(fpr_best, tpr_best)\n",
        "plt.figure()\n",
        "plt.plot(fpr_best, tpr_best, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_best)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj8qFfB9b0t1"
      },
      "source": [
        "Imprimir los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNJzas7gb1ND",
        "outputId": "89d1b5bf-f368-43c9-e735-73a6be8d09ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros:  {'xgb__subsample': 0.9427629804456301, 'xgb__scale_pos_weight': 1.0320900158332558, 'xgb__reg_lambda': 0.7010703016048032, 'xgb__n_estimators': 651, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.13680927343211416, 'xgb__gamma': 0.04500991430601001, 'xgb__colsample_bytree': 0.8770206411553205, 'rf__n_estimators': 166, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 4, 'rf__max_depth': 10, 'rf__bootstrap': False, 'ann__epochs': 10, 'ann__batch_size': 71, 'ann__learning_rate': 0.003320651213411407}\n",
            "Matriz de Confusión:\n",
            "[[815 139]\n",
            " [110 824]]\n",
            "\n",
            "Informe de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87       954\n",
            "           1       0.86      0.88      0.87       934\n",
            "\n",
            "    accuracy                           0.87      1888\n",
            "   macro avg       0.87      0.87      0.87      1888\n",
            "weighted avg       0.87      0.87      0.87      1888\n",
            "\n",
            "\n",
            "Precisión del modelo híbrido: 0.868114406779661\n"
          ]
        }
      ],
      "source": [
        "# 12. Imprimir los resultados\n",
        "print('Mejores hiperparámetros: ', best_params)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(conf_matrix_best)\n",
        "print(\"\\nInforme de Clasificación:\")\n",
        "print(report_best)\n",
        "print(\"\\nPrecisión del modelo híbrido:\", acc_best)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
