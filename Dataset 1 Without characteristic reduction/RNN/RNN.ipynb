{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJyg8xgbBD2"
      },
      "source": [
        "Importación y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tJA_xfxpbAlp"
      },
      "outputs": [],
      "source": [
        "# Importaciones\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from keras_tuner import Hyperband\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "df = pd.read_csv('telecom_customer_churn.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3B405XRbMm_"
      },
      "source": [
        "Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuTS-4Da1iq",
        "outputId": "64269792-651b-47fc-a2aa-3a22c056507f"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocesamiento\n",
        "# a. Eliminar entradas con el estado \"Joined\"\n",
        "df = df[df['Customer Status'] != 'Joined']\n",
        "\n",
        "# b. Crear la columna 'Churn' y asignar 1 si 'Customer Status' es 'Churned', de lo contrario 0\n",
        "df['Churn'] = df['Customer Status'].apply(lambda x: 1 if x == 'Churned' else 0)\n",
        "\n",
        "# c. Eliminar columnas con más del 50% de datos faltantes\n",
        "threshold = int(0.5 * len(df))\n",
        "df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "# d. Reemplazar valores atípicos por la media\n",
        "for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df[col] = df[col].apply(lambda x: df[col].mean() if (x < (Q1 - 1.5 * IQR)) or (x > (Q3 + 1.5 * IQR)) else x)\n",
        "\n",
        "# e. Convertir variables categóricas a numéricas y llenar valores faltantes\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object' and column != 'Customer Status':\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "    elif df[column].dtype in ['int64', 'float64']:\n",
        "        df[column].fillna(df[column].median(), inplace=True)\n",
        "\n",
        "# Eliminar la columna 'Customer Status' antes de normalizar\n",
        "df = df.drop(columns=['Customer Status'])\n",
        "\n",
        "# f. Normalización\n",
        "cols_to_scale = df.columns.difference(['Churn'])\n",
        "scaler = StandardScaler()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed-WLhQ4bPiM"
      },
      "source": [
        "Selección de características - Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Balanceo con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Balanceo con SMOTE\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiFgAaybheu"
      },
      "source": [
        "División de Conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. División de Conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparación de Datos para RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Preparación de Datos para RNN\n",
        "X_train_rnn = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_rnn = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGkhCSKbZAy"
      },
      "source": [
        "Entrenamiento de RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pHoztCgybaO5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 24 Complete [00h 00m 09s]\n",
            "val_accuracy: 0.806750476360321\n",
            "\n",
            "Best val_accuracy So Far: 0.8590337634086609\n",
            "Total elapsed time: 00h 03m 30s\n",
            "\n",
            "Los mejores hiperparámetros encontrados:\n",
            "Número de unidades: 48\n",
            "Tasa de aprendizaje: 0.01\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# 6. Entrenamiento de RNN con búsqueda de hiperparámetros usando Keras Tuner\n",
        "def build_rnn_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=8, max_value=64, step=8), \n",
        "                   input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), \n",
        "                   return_sequences=True))\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=8, max_value=64, step=8), return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Utilizar Adam sin el prefijo legacy\n",
        "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.01, 0.1]))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Continúa con la configuración de Hyperband y la búsqueda de hiperparámetros\n",
        "tuner_rnn = Hyperband(\n",
        "    build_rnn_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=100,\n",
        "    hyperband_iterations=2,\n",
        "    directory='my_dir',\n",
        "    project_name='keras_tuner_rnn_example'\n",
        ")\n",
        "\n",
        "callbacks_rnn = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
        "    tf.keras.callbacks.ModelCheckpoint('best_rnn_model.keras', save_best_only=True)  # Cambiado de .h5 a .keras\n",
        "]\n",
        "\n",
        "tuner_rnn.search(X_train_rnn, y_train, epochs=100, validation_split=0.2, callbacks=callbacks_rnn)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_hps_rnn = tuner_rnn.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Los mejores hiperparámetros encontrados:\n",
        "Número de unidades: {best_hps_rnn.get('units')}\n",
        "Tasa de aprendizaje: {best_hps_rnn.get('learning_rate')}\n",
        "\"\"\")\n",
        "\n",
        "# Obtener el mejor modelo RNN\n",
        "best_rnn_model = tuner_rnn.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuuaC5amVQU"
      },
      "source": [
        "Selección de Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyGhE6ygmYrG",
        "outputId": "1e0e50c0-ba48-4424-f724-6675dfddcaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3633\n",
            "Loss: 0.3365612328052521, Accuracy: 0.8559321761131287\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "[[797 157]\n",
            " [115 819]]\n",
            "Reporte de clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.85       954\n",
            "           1       0.84      0.88      0.86       934\n",
            "\n",
            "    accuracy                           0.86      1888\n",
            "   macro avg       0.86      0.86      0.86      1888\n",
            "weighted avg       0.86      0.86      0.86      1888\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Evaluación del modelo con los mejores hiperparámetros\n",
        "loss_rnn, accuracy_rnn = best_rnn_model.evaluate(X_test_rnn, y_test)\n",
        "print(f'Loss: {loss_rnn}, Accuracy: {accuracy_rnn}')\n",
        "\n",
        "# Obtener las predicciones en forma de clases\n",
        "y_pred_rnn = (best_rnn_model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calcular la matriz de confusión, y generar el reporte de clasificación\n",
        "conf_matrix_rnn = confusion_matrix(y_test, y_pred_rnn)\n",
        "report_rnn = classification_report(y_test, y_pred_rnn)\n",
        "\n",
        "# Imprimir las métricas\n",
        "print(conf_matrix_rnn)\n",
        "print(\"Reporte de clasificación:\\n\", report_rnn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
