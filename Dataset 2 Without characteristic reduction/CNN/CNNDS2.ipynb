{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJyg8xgbBD2"
      },
      "source": [
        "Importación y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tJA_xfxpbAlp"
      },
      "outputs": [],
      "source": [
        "# Importaciones correctas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from keras_tuner import Hyperband\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras_tuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Carga de datos\n",
        "df = pd.read_csv('Telco Churn dataset 2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3B405XRbMm_"
      },
      "source": [
        "Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuTS-4Da1iq",
        "outputId": "64269792-651b-47fc-a2aa-3a22c056507f"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocesamiento\n",
        "# a. Crear la columna 'Churn' y asignar 1 si 'Churn' es 'Yes', de lo contrario 0\n",
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# b. Eliminar columnas con más del 50% de datos faltantes\n",
        "threshold = int(0.5 * len(df))\n",
        "df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "# c. Reemplazar valores atípicos por la media\n",
        "for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "    if col != 'Churn':  # Asegurarse de no modificar la columna 'Churn'\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df[col] = df[col].apply(lambda x: df[col].mean() if (x < (Q1 - 1.5 * IQR)) or (x > (Q3 + 1.5 * IQR)) else x)\n",
        "\n",
        "# d. Convertir variables categóricas a numéricas y llenar valores faltantes\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object' and column != 'Churn':\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "    elif df[column].dtype in ['int64', 'float64']:\n",
        "        df[column].fillna(df[column].median(), inplace=True)\n",
        "\n",
        "# e. Normalización\n",
        "cols_to_scale = df.columns.tolist()\n",
        "cols_to_scale.remove('Churn')\n",
        "scaler = StandardScaler()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# f. Asegurarse de que 'Churn' sea int\n",
        "df['Churn'] = df['Churn'].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed-WLhQ4bPiM"
      },
      "source": [
        "Selección de características - Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiFgAaybheu"
      },
      "source": [
        "Balanceo con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Balanceo con SMOTE\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGkhCSKbZAy"
      },
      "source": [
        "División de ConjuntoBalanceo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pHoztCgybaO5"
      },
      "outputs": [],
      "source": [
        "# 4. División de Conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
        "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 11s]\n",
            "val_accuracy: 0.8881579041481018\n",
            "\n",
            "Best val_accuracy So Far: 0.9232456088066101\n",
            "Total elapsed time: 00h 02m 34s\n",
            "\n",
            "La búsqueda de hiperparámetros está completa. El número óptimo de unidades en la primera capa densamente conectada\n",
            "es 96 y la tasa de aprendizaje óptima para el optimizador\n",
            "es 0.001.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Construcción del Modelo CNN para GridSearch\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(\n",
        "        filters=hp.Int('conv_filters', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Int('conv_kernel_size', min_value=2, max_value=5),\n",
        "        activation='relu',\n",
        "        input_shape=(X_train_cnn.shape[1], 1)\n",
        "    ))\n",
        "    model.add(MaxPooling1D(pool_size=hp.Int('max_pool_size', min_value=2, max_value=4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=hp.Int('dense_units', min_value=32, max_value=128, step=32), activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    directory='hyperband',\n",
        "    project_name='cnn'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuner.search(X_train_cnn, y_train, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "La búsqueda de hiperparámetros está completa. El número óptimo de unidades en la primera capa densamente conectada\n",
        "es {best_hps.get('dense_units')} y la tasa de aprendizaje óptima para el optimizador\n",
        "es {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj8qFfB9b0t1"
      },
      "source": [
        "Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNJzas7gb1ND",
        "outputId": "89d1b5bf-f368-43c9-e735-73a6be8d09ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9252 - loss: 0.2024\n",
            "Loss: 0.20321500301361084, Accuracy: 0.9271929860115051\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "[[520  55]\n",
            " [ 28 537]]\n",
            "Reporte de clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.93       575\n",
            "           1       0.91      0.95      0.93       565\n",
            "\n",
            "    accuracy                           0.93      1140\n",
            "   macro avg       0.93      0.93      0.93      1140\n",
            "weighted avg       0.93      0.93      0.93      1140\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6. Evaluación del modelo con los mejores hiperparámetros\n",
        "# Obtén el mejor modelo\n",
        "best_cnn_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evalúa el modelo en el conjunto de test\n",
        "loss_cnn, accuracy_cnn = best_cnn_model.evaluate(X_test_cnn, y_test)\n",
        "print(f'Loss: {loss_cnn}, Accuracy: {accuracy_cnn}')\n",
        "\n",
        "# Haz predicciones en el conjunto de test\n",
        "y_pred_cnn = (best_cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calcula la matriz de confusión y el reporte de clasificación\n",
        "conf_matrix_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "report_cnn = classification_report(y_test, y_pred_cnn)\n",
        "\n",
        "# Imprime las métricas\n",
        "print(conf_matrix_cnn)\n",
        "print(\"Reporte de clasificación:\\n\", report_cnn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
